
[Editorial - contest/2055]
Look at the distance between the frogs.
Notice that regardless of how the players move, the difference between the numbers of the lilypads the two players are standing on always alternates even and odd, depending on the starting configuration. Then, the key observation is that exactly one player has the following winning strategy:  Walk towards the other player, and do not stop until they are forced onto lilypad 11 or nn. For instance, if Alice and Bob start on lilypads with the same parity, Bob cannot stop Alice from advancing towards him. This is because at the start of Alice's turn, she will always be able to move towards Bob due to their distance being even and therefore at least 22, implying that there is a free lilypad for her to jump to. This eventually forces Bob into one of the lilypads 1,n1,n, causing him to lose.In the case that they start on lilypads with different parity, analogous logic shows that Bob wins. Therefore, for each case, we only need to check the parity of the lilypads for a constant time solution.
#include <bits/stdc++.h>

using namespace std;

int main()
{
    ios_base::sync_with_stdio(false);
    cin.tie(0);

    int T; cin >> T;
    while (T--) {
        int N, A, B; cin >> N >> A >> B;
        if ((A ^ B) & 1) cout << "NO\n";
        else cout << "YES\n";
    }
    cout.flush();
    return 0;
}
The order of the moves is pretty much irrelevant. What happens if we try to make two different materials?
The key observation is that we will never use the operation to craft two different types of materials i,ji,j. This is because if we were to combine the net change in resources from these two operations, we would lose two units each of every material k≠i,jk≠i,j, and receive a net zero change in our amounts of materials i,ji,j. Therefore, we will only ever use the operation on one type of material ii.An immediate corollary of this observation is that we can only be deficient in at most one type of material, i.e. at most one index ii at which ai<biai<bi. If no such index exists, the material is craftable using our starting resources. Otherwise, applying the operation xx times transforms our array to aj:={aj+xaj−xif i=jif i≠jaj:={aj+xif i=jaj−xif i≠ji.e. increasing element aiai by xx and decreasing all other elements by xx. We must have x≥bi−aix≥bi−ai to satisfy the requirement on material type ii. However, there is also no point in making xx any larger, as by then we already have enough of type ii, and further operations cause us to start losing materials from other types that we could potentially need to craft the artifact. Therefore, our condition in this case is just to check that bi−ai≤minj≠iaj−bj,bi−ai≤minj≠iaj−bj,i.e. we are deficient in type ii by at most as many units as our smallest surplus in all other material types j≠ij≠i. This gives an O(n)O(n) solution.
// #include <ext/pb_ds/assoc_container.hpp>
// #include <ext/pb_ds/tree_policy.hpp>
// using namespace __gnu_pbds;
// typedef tree<int, null_type, std::less<int>, rb_tree_tag, tree_order_statistics_node_update> ordered_set;

#include <bits/stdc++.h>

#define f first
#define s second
#define pb push_back

typedef long long int ll;
typedef unsigned long long int ull;
using namespace std;
typedef pair<int,int> pii;
typedef pair<ll,ll> pll;

template<typename T> int die(T x) { cout << x << endl; return 0; }

#define mod_fft 998244353
#define mod_nfft 1000000007
#define INF 100000000000000
#define LNF 1e15
#define LOL 12345678912345719ll

struct LL {

    static const ll m = mod_fft;
    long long int val;

    LL(ll v) {val=reduce(v);};
    LL() {val=0;};
    ~LL(){};
    LL(const LL& l) {val=l.val;};
    LL& operator=(int l) {val=l; return *this;}
    LL& operator=(ll l) {val=l; return *this;}
    LL& operator=(LL l) {val=l.val; return *this;}

    static long long int reduce(ll x, ll md = m) {
        x %= md;
        while (x >= md) x-=md;
        while (x < 0) x+=md;
        return x;
    }

    bool operator<(const LL& b) { return val<b.val; }
    bool operator<=(const LL& b) { return val<=b.val; }
    bool operator==(const LL& b) { return val==b.val; }
    bool operator>=(const LL& b) { return val>=b.val; }
    bool operator>(const LL& b) { return val>b.val; }

    LL operator+(const LL& b) { return LL(val+b.val); }
    LL operator+(const ll& b) { return (*this+LL(b)); }
    LL& operator+=(const LL& b) { return (*this=*this+b); }
    LL& operator+=(const ll& b) { return (*this=*this+b); }

    LL operator-(const LL& b) { return LL(val-b.val); }
    LL operator-(const ll& b) { return (*this-LL(b)); }
    LL& operator-=(const LL& b) { return (*this=*this-b); }
    LL& operator-=(const ll& b) { return (*this=*this-b); }

    LL operator*(const LL& b) { return LL(val*b.val); }
    LL operator*(const ll& b) { return (*this*LL(b)); }
    LL& operator*=(const LL& b) { return (*this=*this*b); }
    LL& operator*=(const ll& b) { return (*this=*this*b); }

    static LL exp(const LL& x, const ll& y){
        ll z = y;
        z = reduce(z,m-1);
        LL ret = 1;
        LL w = x;
        while (z) {
            if (z&1) ret *= w;
            z >>= 1; w *= w;
        }
        return ret;
    }
    LL& operator^=(ll y) { return (*this=LL(val^y)); }

    LL operator/(const LL& b) { return ((*this)*exp(b,-1)); }
    LL operator/(const ll& b) { return (*this/LL(b)); }
    LL operator/=(const LL& b) { return ((*this)*=exp(b,-1)); }
    LL& operator/=(const ll& b) { return (*this=*this/LL(b)); }

}; ostream& operator<<(ostream& os, const LL& obj) { return os << obj.val; }

int N;
vector<ll> segtree;

void pull(int t) {
    segtree[t] = max(segtree[2*t], segtree[2*t+1]);
}

void point_set(int idx, ll val, int L = 1, int R = N, int t = 1) {
    if (L == R)  segtree[t] = val;
    else {
        int M = (L + R) / 2;
        if (idx <= M) point_set(idx, val, L, M, 2*t);
        else point_set(idx, val, M+1, R, 2*t+1);
        pull(t);
    }
}

ll range_add(int left, int right, int L = 1, int R = N, int t = 1) {
    if (left <= L && R <= right) return segtree[t];
    else {
        int M = (L + R) / 2;
        ll ret = 0;
        if (left <= M) ret = max(ret, range_add(left, right, L, M, 2*t));
        if (right > M) ret = max(ret, range_add(left, right, M+1, R, 2*t+1));
        return ret;
    }
}

void build(vector<ll>& arr, int L = 1, int R = N, int t = 1) {
    if (L == R)  segtree[t] = arr[L-1];
    else {
        int M = (L + R) / 2;
        build(arr, L, M, 2*t);
        build(arr, M+1, R, 2*t+1);
        pull(t);
    }
}

int main() {
    ios_base::sync_with_stdio(false);
    cin.tie(0);
    int T = 1; cin >> T;
    while (T--) {
        int N; cin >> N;
        vector<int> A(N), B(N);
        for (int i = 0; i < N; i++) cin >> A[i];
        int bad = -1, margin = 1e9, need = 0;
        bool reject = 0;
        for (int i = 0; i < N; i++) {
            cin >> B[i];
            if (A[i] < B[i]) {
                if (bad != -1) reject = 1;
                bad = i;
                need = B[i] - A[i];
            } else {
                margin = min(margin, A[i] - B[i]);
            }
        }
        if (reject) {
            cout << "NO" << endl;
            continue;
        } else {
            cout << ((margin >= need) ? "YES" : "NO") << endl;
        }
    }
}
Pick xx, and find the sum of the whole grid. What does this tell you?
Once you know xx, the top left cell is fixed.
What about the next cell on the trail?
The naive solution of writing out a linear system and solving them will take O((n+m)3)O((n+m)3) time, which is too slow, so we will need a faster algorithm.We begin by selecting a target sum SS for each row and column. If we calculate the sum of all numbers in the completed grid, summing over rows gives a total of S⋅nS⋅n while summing over columns gives a total of S⋅mS⋅m. Therefore, in order for our choice of SS to be possible, we require S⋅n=S⋅mS⋅n=S⋅m, and since it is possible for n≠mn≠m, we will pick S=0S=0 for our choice to be possible in all cases of n,mn,m. Notice that all choices S≠0S≠0 will fail on n≠mn≠m, as the condition S⋅n=S⋅mS⋅n=S⋅m no longer holds. As such, S=0S=0 is the only one that will work in all cases.Now, we aim to make each row and column sum to SS. The crux of the problem is the following observation:  Denote x1,x2,…,xn+m−1x1,x2,…,xn+m−1 to be the variables along the path. Let's say variables x1,…,xi−1x1,…,xi−1 have their values set for some 1≤i<n+m−11≤i<n+m−1. Then, either the row or column corresponding to variable xixi has all of its values set besides xixi, and therefore we may determine exactly one possible value of xixi to make its row or column sum to 00. The proof of this claim is simple. At variable xixi, we look at the corresponding path move sisi. If si=Rsi=R, then the path will never revisit the column of variable xixi, and its column will have no remaining unset variables since x1,…,xi−1x1,…,xi−1 are already set. Likewise, if si=Dsi=D, then the path will never revisit the row of variable xixi, which can then be used to determine the value of xixi.Repeating this process will cause every row and column except for row nn and column mm to have a sum of zero, with xn+m−1xn+m−1 being the final variable. However, we will show that we can use either the row or column to determine it, and it will give a sum of zero for both row nn and column mm. WLOG we use row nn. Indeed, if the sum of all rows and columns except for column mm are zero, we know that the sum of all entries of the grid is zero by summing over rows. However, we may then subtract all columns except column mm from this total to arrive at the conclusion that column mm also has zero sum. Therefore, we may determine the value of xn+m−1xn+m−1 using either its row or column to finish our construction, giving a solution in O(n⋅m)O(n⋅m).
#include <bits/stdc++.h>

#define f first
#define s second
#define pb push_back

typedef long long int ll;
typedef unsigned long long int ull;
using namespace std;
typedef pair<int,int> pii;
typedef pair<ll,ll> pll;

template<typename T> int die(T x) { cout << x << endl; return 0; }

#define mod 1000000007
#define INF 1000000000
#define LNF 1e15
#define LOL 12345678912345719ll

using namespace std;

int main()
{
    ios_base::sync_with_stdio(false);
    cin.tie(0);

    int T; cin >> T;
    while (T--) {
        int N, M; cin >> N >> M;
        string S; cin >> S;
        vector<vector<ll>> A;
        for (int i = 0; i < N; i++) {
            A.push_back(vector<ll>(M));
            for (int j = 0; j < M; j++) {
                cin >> A[i][j];
            }
        }
        int x = 0, y = 0;
        for (char c : S) {
            if (c == 'D') {
                long long su = 0;
                for (int i = 0; i < M; i++) {
                    su += A[x][i];
                }
                A[x][y] = -su;
                ++x;
            } else {
                long long su = 0;
                for (int i = 0; i < N; i++) {
                    su += A[i][y];
                }
                A[x][y] = -su;
                ++y;
            }
        }
        long long su = 0;
        for (int i = 0; i < M; i++) {
            su += A[N-1][i];
        }
        A[N-1][M-1] = -su;
        for (int i = 0; i < N; i++) {
            for (int j = 0; j < M; j++) {
                cout << A[i][j] << " ";
            }
            cout << endl;
        }

    }
    return 0;
}

Should you ever change the order of scarecrows?
What's the first thing that the leftmost scarecrow should do?
What's the only way to save time? Think in terms of distances and not times.
Look at the points where the crow "switches over" between scarecrows.
Greedy.
We make a few preliminary observations:  (1) The order of scarecrows should never change, i.e no two scarecrows should cross each other while moving along the interval. (2) Scarecrow 11 should spend the first a1a1 seconds moving to position zero, as this move is required for the crow to make any progress and there is no point in delaying it. (3) Let's say that a scarecrow at position pp `has' the crow if the crow is at position p+kp+k, and there are no other scarecrows in the interval [p,p+k][p,p+k]. A scarecrow that has the crow should always move to the right; in other words, all scarecrows that find themselves located to the left of the crow should spend all their remaining time moving to the right, as it is the only way they will be useful. (4) Let there be a scenario where at time TT, scarecrow ii has the crow and is at position xx, and another scenario at time TT where scarecrow ii also has the crow, but is at position y≥xy≥x. Then, the latter scenario is at least as good as the former scenario, assuming scarecrows numbered higher than ii are not fixed. (5) The only way to save time is to maximize the distance dd teleported by the crow. The second and fifth observations imply that the time spent to move the crow across the interval is a1+ℓ−da1+ℓ−d.Now, for each scarecrow ii, define bibi to be the position along the interval at which it begins to have the crow, i.e. the crow is transferred from scarecrow i−1i−1 to ii. For instance, in the second sample case the values of bibi are (b1,b2,b3)=(0,2.5,4.5)(b1,b2,b3)=(0,2.5,4.5)The second observation above implies that b1=0b1=0, and the first observation implies that b1≤⋯≤bnb1≤⋯≤bn. Notice that we may express the distance teleported as  d=∑ni=1min(k,bi+1−bi)d=∑i=1nmin(k,bi+1−bi)with the extra definition that bn+1=ℓbn+1=ℓ. For instance, in the second sample case the distance teleported is d=min(k,b2−b1)+min(k,b3−b2)+min(k,ℓ−b3)=2+2+0.5=4.5d=min(k,b2−b1)+min(k,b3−b2)+min(k,ℓ−b3)=2+2+0.5=4.5and the total time is a1+ℓ−d=2+5−4.5=2.5a1+ℓ−d=2+5−4.5=2.5.Now, suppose that b1,…,bi−1b1,…,bi−1 have been selected for some 2≤i≤n2≤i≤n, and that time TT has elapsed upon scarecrow i−1i−1 receiving the crow. We will argue the optimal choice of bibi. At time TT when scarecrow i−1i−1 first receives the crow, scarecrow ii may be at any position in the interval [ai−T,min(ai+T,ℓ)][ai−T,min(ai+T,ℓ)]. Now, we have three cases.Case 1. bi−1+k≤ai−T.bi−1+k≤ai−T. In this case, scarecrow ii will need to move some nonnegative amount to the left in order to meet with scarecrow i−1i−1. They will meet at the midpoint of the crow position bi−1+kbi−1+k and the leftmost possible position ai−Tai−T of scarecrow ii at time TT. This gives  bi:=ai−T+bi−1+k2.bi:=ai−T+bi−1+k2.Case 2. ai−T≤bi−1+k≤ai+T.ai−T≤bi−1+k≤ai+T. Notice that if our choice of bibi has bi<bi−1+kbi<bi−1+k, it benefits us to increase our choice of bibi (if possible) as a consequence of our fourth observation, since all such bibi will cause an immediate transfer of the crow to scarecrow ii at time TT. However, if we choose bi>bi−1+kbi>bi−1+k, lowering our choice of bibi is now better as it loses less potential teleported distance min(k,bi−bi−1)min(k,bi−bi−1), while leaving more space for teleported distance after position bibi. Therefore, we will choose bi:=bi−1+kbi:=bi−1+k in this case.Case 3. ai+T≤bi−1+k.ai+T≤bi−1+k. In this case, regardless of how we choose bibi, the crow will immediately transfer to scarecrow ii from scarecrow i−1i−1 at time TT. We might as well pick bi:=ai+Tbi:=ai+T.Therefore, the optimal selection of bibi may be calculated iteratively as  bi:=min⎛⎝⎜⎜ℓ,ai+Tcase 3,max⎛⎝⎜⎜bi−1+kcase 2,ai−T+bi−1+k2case 1⎞⎠⎟⎟⎞⎠⎟⎟.bi:=min(ℓ,ai+T⏞case 3,max(bi−1+k⏞case 2,ai−T+bi−1+k2⏞case 1)).It is now easy to implement the above approach to yield an O(n)O(n) solution. Note that the constraints for k,ℓk,ℓ were deliberately set to 108108 instead of 109109 to make two times the maximum answer 4⋅ℓ4⋅ℓ fit within 3232-bit integer types. It is not difficult to show that the values of bibi as well as the answer are always integers or half-integers.
#include <bits/stdc++.h>

#define f first
#define s second
#define pb push_back

typedef long long int ll;
typedef unsigned long long int ull;
using namespace std;
typedef pair<int,int> pii;
typedef pair<ll,ll> pll;

int main()
{
    ios_base::sync_with_stdio(false);
    cin.tie(0);

    int T; cin >> T;
    while (T--) {
        int N, k, l;
        cin >> N >> k >> l;
        double K = k;
        double L = l;
        vector<int> A(N);
        for (int i = 0; i < N; i++) cin >> A[i];
        double T = A[0];
        double last_pt = 0;
        double S = 0;
        for (int i = 1; i < N; i++) {
            double this_pt = min(L, min(A[i] + T,
                                max(last_pt + K,
                                    (A[i] - T + last_pt + K)/2.0)));
            T += max(0.0, this_pt - last_pt - K);
            S += min(K, this_pt - last_pt);
            last_pt = this_pt;
        }
        S += min(K, L - last_pt);
        cout << (int)round(2*(L - S + A[0])) << endl;
    }
    return 0;
}

Let's say you have to empty the haystacks in a fixed order. What's the best way to do it?
Write the expression for the number of moves for a given order.
In an optimal ordering, you should not gain anything by swapping two entries of the order. Using this, describe the optimal order.
The constraint only limits what you can empty last. How can you efficiently compute the expression in Hint 2?
Let's say we fixed some permutation σσ of 1,…,n1,…,n such that we empty haystacks in the order σ1,…,σnσ1,…,σn. Notice that a choice of σσ is possible if and only if the final stack σnσn can be cleared, which is equivalent to the constraint  aσ1+⋯+aσn≤bσ1+⋯+bσn−1.aσ1+⋯+aσn≤bσ1+⋯+bσn−1.With this added constraint, the optimal sequence of moves is as follows:  Iterate ii through 1,…,n−11,…,n−1. For each ii, try to move its haybales to haystacks 1,…,i−11,…,i−1, and if they are all full then move haybales to haystack nn. Once this process terminates, move all haystacks from nn back onto arbitrary haystacks 1,…,n−11,…,n−1, being careful to not overflow the height limits. The key observation is that the number of extra haybales that must be moved onto haystack nn is  max1≤i≤n−1{∑ij=1aσj−∑i−1j=1bσj}.max1≤i≤n−1{∑j=1iaσj−∑j=1i−1bσj}.To show this, consider the last time ii that a haybale is moved onto haystack nn. At this time, all haybales from haystacks 1,…,i1,…,i have found a home, either on the height limited haystacks 1,…,i−11,…,i−1 or on haystack nn, from which the identity immediately follows. Now, every haystack that wasn't moved onto haystack nn will get moved once, and every haystack that did gets moved twice. Therefore, our task becomes the following: Compute ∑ni=1ai+minσmax1≤i≤n−1{∑ij=1aσj−∑i−1j=1bσj}∑i=1nai+minσmax1≤i≤n−1{∑j=1iaσj−∑j=1i−1bσj}for σσ satisfying aσ1+⋯+aσn≤bσ1+⋯+bσn−1.aσ1+⋯+aσn≤bσ1+⋯+bσn−1.Notice that the ∑ni=1ai∑i=1nai term is constant, and we will omit it for the rest of this tutorial. We will first solve the task with no restriction on σσ to gain some intuition. Denote <σ<σ the ordering of pairs (a,b)(a,b) corresponding to σσ. Consider adjacent pairs (ai,bi)<σ(aj,bj)(ai,bi)<σ(aj,bj). Then, if the choice of σσ is optimal, it must not be better to swap their ordering, i.e. (ai,bi)<σ(aj,bj)optimal⟹⟺⟺max(ai,ai+aj−bi)≤max(aj,ai+aj−bj)max(−aj,−bi)≤max(−ai,−bj)min(aj,bi)≥min(ai,bj).(ai,bi)<σ(aj,bj)⏞optimal⟹max(ai,ai+aj−bi)≤max(aj,ai+aj−bj)⟺max(−aj,−bi)≤max(−ai,−bj)⟺min(aj,bi)≥min(ai,bj).As a corollary, there exists an optimal σσ satisfying the following properties:Claim [Optimality conditions of $\sigma$].  All pairs with ai<biai<bi come first. Then, all pairs with ai=biai=bi come next. Then, all pairs with ai>biai>bi. The pairs with ai<biai<bi are in ascending order of aiai. The pairs with ai>biai>bi are in descending order of bibi. It is not hard to show that all such σσ satisfying these properties are optimal by following similar logic as above. We leave it as an exercise for the reader.Now, we add in the constraint on the final term σnσn of the ordering. We will perform casework on this final haystack. Notice that for any fixed an,bnan,bn, if max1≤i≤n−1{∑ij=1aσj−∑i−1j=1bσj}max1≤i≤n−1{∑j=1iaσj−∑j=1i−1bσj}is maximized, then so is  max1≤i≤n{∑ij=1aσj−∑i−1j=1bσj}.max1≤i≤n{∑j=1iaσj−∑j=1i−1bσj}.So, if we were to fix any last haystack σnσn, the optimality conditions tell us that we should still order the remaining n−1n−1 haystacks as before. Now, we may iterate over all valid σnσn and compute the answer efficiently as follows: maintain a segment tree with leaves representing pairs (ai,bi)(ai,bi) and range queries for  max1≤i≤n{∑ij=1aσj−∑i−1j=1bσj}.max1≤i≤n{∑j=1iaσj−∑j=1i−1bσj}.This gives an O(nlogn)O(nlog⁡n) solution.Note that it is possible to implement this final step using prefix and suffix sums to yield an O(n)O(n) solution, but it is not necessary to do so.
#include <bits/stdc++.h>

#define f first
#define s second
#define pb push_back

typedef long long int ll;
typedef unsigned long long int ull;
using namespace std;
typedef pair<int,int> pii;
typedef pair<ll,ll> pll;

template<typename T> int die(T x) { cout << x << endl; return 0; }

#define LNF 1e15

int N;
vector<pll> segtree;

pll f(pll a, pll b) {
    return {max(a.first, a.second + b.first), a.second + b.second};
}

void pull(int t) {
    segtree[t] = f(segtree[2*t], segtree[2*t+1]);
}

void point_set(int idx, pll val, int L = 1, int R = N, int t = 1) {
    if (L == R) segtree[t] = val;
    else {
        int M = (L + R) / 2;
        if (idx <= M) point_set(idx, val, L, M, 2*t);
        else point_set(idx, val, M+1, R, 2*t+1);
        pull(t);
    }
}

pll range_add(int left, int right, int L = 1, int R = N, int t = 1) {
    if (left <= L && R <= right) return segtree[t];
    else {
        int M = (L + R) / 2;
        pll ret = {0, 0};
        if (left <= M) ret = f(ret, range_add(left, right, L, M, 2*t));
        if (right > M) ret = f(ret, range_add(left, right, M+1, R, 2*t+1));
        return ret;
    }
}

void build(vector<pll>& arr, int L = 1, int R = N, int t = 1) {
    if (L == R) segtree[t] = arr[L-1];
    else {
        int M = (L + R) / 2;
        build(arr, L, M, 2*t);
        build(arr, M+1, R, 2*t+1);
        pull(t);
    }
}

vector<int> theoretical(const vector<pii>& arr) {
    vector<int> idx(arr.size());
    for (int i = 0; i < arr.size(); ++i) {
        idx[i] = i;
    }

    vector<int> ut, eq, lt;
    for (int i = 0; i < arr.size(); ++i) {
        if (arr[i].first < arr[i].second) {
            ut.push_back(i);
        } else if (arr[i].first == arr[i].second) {
            eq.push_back(i);
        } else {
            lt.push_back(i);
        }
    }

    sort(ut.begin(), ut.end(), [&arr](int i, int j) {
        return arr[i].first < arr[j].first;
    });

    sort(eq.begin(), eq.end(), [&arr](int i, int j) {
        return arr[i].first > arr[j].first;
    });

    sort(lt.begin(), lt.end(), [&arr](int i, int j) {
        return arr[i].second > arr[j].second;
    });

    vector<int> result;
    result.insert(result.end(), ut.begin(), ut.end());
    result.insert(result.end(), eq.begin(), eq.end());
    result.insert(result.end(), lt.begin(), lt.end());

    return result;
}

int main() {
    ios_base::sync_with_stdio(false);
    cin.tie(0);
    int T = 1; cin >> T;
    while (T--) {
        cin >> N;
        vector<pll> data(N);
        ll sum_a = 0;
        ll sum_b = 0;
        for (int i = 0; i < N; i++) {
            cin >> data[i].f >> data[i].s;
            sum_a += data[i].f;
            sum_b += data[i].s;
        }
        vector<int> order = theoretical(vector<pii>(data.begin(), data.end()));

        vector<pll> data_sorted;
        for (int i : order) data_sorted.push_back({data[i].first, data[i].first - data[i].second});
        data_sorted.push_back({0, 0});

        ++N;

        segtree = vector<pll>(4*N);
        build(data_sorted);

        ll ans = LNF;
        for (int i = 0; i < N-1; i++) {
            if (sum_b - (data_sorted[i].first - data_sorted[i].second) >= sum_a) {
                point_set(i+1, data_sorted[N-1]);
                point_set(N, data_sorted[i]);

                ans = min(ans, range_add(1, N).first);

                point_set(i+1, data_sorted[i]);
                point_set(N, data_sorted[N-1]);
            }
        }
        if (ans == LNF) cout << -1 << endl;
        else cout << ans + sum_a << endl;
    }
}



The results of the partition must be convex. Can you see why?
The easier cases are when the polyomino must be cut vertically or horizontally. Let's discard those for now, and consider the "diagonal cuts". I.e. let one polyomino start from the top row, and another starting from some row cc. WLOG the one starting on row cc is on the left side, we will check the other side by just duplicating the rest of the solution.
Both sub-polyominoes are fixed if you choose cc. But, it takes O(n)O(n) time to check each one.
Can you get rid of most cc with a quick check?
Look at perimeters shapes, or area. Both will work.
Assume there exists a valid partition of the polyomino. Note that the resulting congruent polyominoes must be convex, as it is not possible to join two non-overlapping non-convex polyominoes to create a convex one. Then, there are two cases: either the two resulting polyominoes are separated by a perfectly vertical or horizontal cut, or they share some rows. The first case is easy to check in linear time. The remainder of the solution will focus on the second case.Consider the structure of a valid partition. We will focus on the perimeter: Notice that the cut separating the two polyominoes must only ever move down and right, or up and right, as otherwise one of the formed polyominoes will not be convex. Without loss of generality, say it only goes down and right.In order for our cut to be valid, it must partition the perimeter into six segments as shown, such that the marked segments are congruent in the indicated orientations (aa with aa, bb with bb, cc with cc.) If we label the horizontal lines of the grid to be 0,…,n0,…,n where line ii is located after row ii, we notice that the division points along the left side of the original polyomino are located at lines 0,k,2k0,k,2k for some 1≤k≤n/21≤k≤n/2. Notice that if we were to fix a given kk, we can uniquely determine the lower polyomino from the first few rows of the upper polyomino. Indeed, if ai=ri−ℓi+1ai=ri−ℓi+1 denotes the width of the ii-th row of the original polyomino, we can show that the resulting polyomino for a particular choice of kk has  bi=ai−ai−k+ai−2k−…bi=ai−ai−k+ai−2k−…cells in its ii-th row, for 1≤i≤n−k1≤i≤n−k. Therefore, iterating over all possible kk and checking them individually gives an O(n2)O(n2) solution.To speed this up, we will develop a constant-time check that will prune ``most'' choices of kk. Indeed, we may use prefix sums and hashing to verify the perimeter properties outlined above, so that we can find all kk that pass this check in O(n)O(n) time. If there are at most f(n)f(n) choices of kk afterwards, we can check them all for a solution in O(n⋅(f(n)+hashing errors))O(n⋅(f(n)+hashing errors)).It can actually be shown that for our hashing protocol, f(n)≤9f(n)≤9, so that this algorithm has linear time complexity. While the proof is not difficult, it is rather long and will be left as an exercise. Instead, we will give a simpler argument to bound f(n)f(n). Fix some choice of kk, and consider the generating functions A(x)=a0+a1x+⋯+anxn,A(x)=a0+a1x+⋯+anxn, B(x)=b0+b1x+⋯+bn−kxn−k.B(x)=b0+b1x+⋯+bn−kxn−k.The perimeter conditions imply that (1+xk)B(x)=A(x)(1+xk)B(x)=A(x). In other words, kk may only be valid if (1+xk)(1+xk) divides A(x)A(x). Therefore, we can use cyclotomic polynomials for 1+xk∣x2k−11+xk∣x2k−1 to determine that f(n)≤maximum number of cyclotomic polynomials that can divide a degree n polynomial.f(n)≤maximum number of cyclotomic polynomials that can divide a degree n polynomial.As the degree of the kk-th cyclotomic polynomial is ϕ(k)ϕ(k) for the Euler totient function ϕϕ, we can see that f(n)f(n) is also at most the maximum number of ki≤nki≤n we can select with ∑iϕ(ki)≤n∑iϕ(ki)≤n. Since ϕ(n)≥nloglognϕ(n)≥nlog⁡log⁡n, this tells us that f(n)=O(n−−√⋅loglogn)f(n)=O(n⋅log⁡log⁡n)and this looser bound already yields a time complexity of at most O(nn−−√⋅loglogn).O(nn⋅log⁡log⁡n). While this concludes the official solution, there exist many other heuristics with different f(n)f(n) that also work. It is in the spirit of the problem to admit many alternate heuristics that give small enough f(n)f(n) ``in practice'', as the official solution uses hashing. One such heuristic found by testers is as follows:We take as our pruning criteria that the area of the subdivided polyomino ∑n−ki=1bi∑i=1n−kbi is exactly half of the area of the original polyomino, which is ∑ni=1ai∑i=1nai. Algebraically manipulating ∑n−ki=1bi∑i=1n−kbi to be a linear function of aiai shows it to be equal to (a1+⋯+ak)−(ak+1+⋯+a2k)+….(a1+⋯+ak)−(ak+1+⋯+a2k)+….The calculation of all these sums may be sped up with prefix sums, and therefore pruning of kk, can be done in amortized O(nlogn)O(nlog⁡n) time since any fixed choice of kk has nknk segments.However, for this choice of pruning, it can actually be shown that f(n)≥Ω(d(n))f(n)≥Ω(d(n)), where d(n)d(n) is the number of divisors of nn. This lower bound is obtained at an even-sized diamond polyomino, e.g. (a1,…,an)=(2,4,…,n,n,…,4,2).(a1,…,an)=(2,4,…,n,n,…,4,2).Despite our efforts, we could not find an upper bound on f(n)f(n) in this case, though we suspect that if it were not for the integrality and bounding constraints ai∈1,…,109ai∈1,…,109, then f(n)=Θ(n)f(n)=Θ(n), with suitable choices of aiai being found using linear programs. Nevertheless, the solution passes our tests, and we suspect that no countertest exists (though hacking attempts on such solutions would be interesting to see!).
#include <bits/stdc++.h>

#define f first
#define s second

typedef long long int ll;
typedef unsigned long long int ull;
using namespace std;
typedef pair<int,int> pii;
typedef pair<ll,ll> pll;

void print_set(vector<int> x) {
    for (auto i : x) {
        cout << i << " ";
    }
    cout << endl;
}

void print_set(vector<ll> x) {
    for (auto i : x) {
        cout << i << " ";
    }
    cout << endl;
}

bool connected(vector<ll> &U, vector<ll> &D) {
    if (U[0] > D[0]) return 0;
    for (int i = 1; i < U.size(); i++) {
        if (U[i] > D[i]) return 0;
        if (D[i] < U[i-1]) return 0;
        if (U[i] > D[i-1]) return 0;
    }
    return 1;
}

bool compare(vector<ll> &U1, vector<ll> &D1, vector<ll> &U2, vector<ll> &D2) {
    if (U1.size() != U2.size()) return 0;
    if (!connected(U1, D1)) return 0;
    for (int i = 0; i < U1.size(); i++) {
        if (U1[i] - D1[i] != U2[i] - D2[i]) return 0;
        if (U1[i] - U1[0] != U2[i] - U2[0]) return 0;
    }
    return 1;
}

bool horizontal_check(vector<ll>& U, vector<ll>& D) {
    if (U.size() % 2) return 0;
    int N = U.size() / 2;
    auto U1 = vector<ll>(U.begin(), U.begin() + N);
    auto D1 = vector<ll>(D.begin(), D.begin() + N);
    auto U2 = vector<ll>(U.begin() + N, U.end());
    auto D2 = vector<ll>(D.begin() + N, D.end());
    return compare(U1, D1, U2, D2);
}

bool vertical_check(vector<ll>& U, vector<ll>& D) {
    vector<ll> M1, M2;
    for (int i = 0; i < U.size(); i++) {
        if ((U[i] + D[i]) % 2 == 0) return 0;
        M1.push_back((U[i] + D[i]) / 2);
        M2.push_back((U[i] + D[i]) / 2 + 1);
    }
    return compare(U, M1, M2, D);
}

ll base = 2;
ll inv = 1000000006;
ll mod = 2000000011;

vector<ll> base_pows;
vector<ll> inv_pows;
void precompute_powers() {
    base_pows.push_back(1);
    inv_pows.push_back(1);
    for (int i = 1; i <= 300000; i++) {
        base_pows.push_back(base_pows.back() * base % mod);
        inv_pows.push_back(inv_pows.back() * inv % mod);
    }
}

ll sub(vector<ll> &hash_prefix, int a1, int b1) {
    return ((mod + hash_prefix[b1] - hash_prefix[a1]) * inv_pows[a1]) % mod;
}

int main()
{
    ios_base::sync_with_stdio(false);
    cin.tie(0);

    precompute_powers();

    int T; cin >> T;
    while (T--) {
        int N; cin >> N;
        vector<ll> U(N), D(N), H(N);
        vector<pii> col_UL(N), col_DR(N+1);
        vector<ll> hash_prefix_U(N), hash_prefix_D(N);
        for (int i = 0; i < N; i++) {
            cin >> U[i] >> D[i];
            H[i] = D[i] - U[i] + 1;
            col_UL[i] = {i,U[i]};
            col_DR[i] = {i+1,D[i]+1};
        }

        // hashing
        for (int i = 1; i < N; i++) {
            hash_prefix_U[i] = (((mod + U[i] - U[i-1]) * base_pows[i-1])
                                + hash_prefix_U[i-1]) % mod;
        }

        for (int i = 1; i < N; i++) {
            hash_prefix_D[i] = (((mod + D[i] - D[i-1]) * base_pows[i-1])
                                + hash_prefix_D[i-1]) % mod;
        }

        // horizontal split
        if (horizontal_check(U, D)) {
            cout << "YES" << endl;
            goto next;
        }

        // vertical split
        if (vertical_check(U, D)) {
            cout << "YES" << endl;
            goto next;
        }

        for (int _ = 0; _ < 2; _++) {
            // down-right split
            for (int c = 1; c <= N/2; c++) {
                // check upper portion
                if (sub(hash_prefix_U, 0, c-1) != sub(hash_prefix_U, c, 2*c-1)) continue;
                if (H[0] - U[2*c] + U[2*c-1] != U[c-1] - U[c]) continue;

                // check lower portion
                if (sub(hash_prefix_D, N-c, N-1) != sub(hash_prefix_D, N-2*c, N-c-1)) continue;
                if (H[N-1] + D[N-2*c-1] - D[N-2*c] != D[N-c-1] - D[N-c]) continue;

                // check main portion
                if (sub(hash_prefix_U, 2*c, N-1) != sub(hash_prefix_D, 0, N-2*c-1)) continue;

                // brute force section
                // polynomial division
                bool ok = 1;
                vector<ll> H_copy(H.begin(), H.end());
                vector<ll> quotient(N);

                // calculate quotient
                for (int i = 0; i < N-c; i++) {
                    quotient[i] = H_copy[i];
                    H_copy[i+c] -= H_copy[i];
                    if (quotient[i] < 0) ok = 0;
                }

                // check for no remainder
                for (int i = N-c; i < N; i++) if (H_copy[i]) ok = 0;
                if (!ok) continue;

                // construct subdivision
                vector<ll> U1, D1, U2, D2;
                for (int i = c; i < N; i++) {
                    int ref_height = quotient[i-c];
                    U1.push_back(D[i-c] - ref_height + 1);
                    D1.push_back(D[i-c]);
                    U2.push_back(U[i]);
                    D2.push_back(U[i] + ref_height - 1);
                }

                if (compare(U1, D1, U2, D2)) {
                    cout << "YES" << endl;
                    goto next;
                }
            }

            // flip and go again!
            swap(hash_prefix_U, hash_prefix_D);
            swap(U, D);
            for (int i = 0; i < N; i++) {
                U[i] = -U[i];
                D[i] = -D[i];
            }
        }
        cout << "NO" << endl;
        next:;
    }
    return 0;
}

//~ mail ID : neernpatel@gmail.com
//~ Author : DrexDelta
//~ codechef : drexdelta , hackerRank : drexdelta , codeforces : drexdelta1
//~ Contact Info : neernpatel@gmail.com

#include <iostream>
#include <cctype>
#include <cerrno>
#include <cfloat>
#include <ciso646>
#include <climits>
#include <clocale>
#include <cmath>
#include <csetjmp>
#include <csignal>
#include <cstdarg>
#include <cstddef>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <ctime>
#include <ccomplex>
#include <cfenv>
#include <cinttypes>
#include <cstdbool>
#include <cstdint>
#include <ctgmath>
#include <cwchar>
#include <cwctype>
#include <algorithm>
#include <bitset>
#include <deque>
#include <iterator>
#include <list>
#include <map>
#include <queue>
#include <set>
#include <stack>
#include <string>
#include <vector>
#include <array>
#include <unordered_map>
#include <unordered_set>
#include <iomanip>

#include <ext/pb_ds/assoc_container.hpp>
#include <ext/pb_ds/tree_policy.hpp>

using namespace std;
using namespace __gnu_pbds;

#define F first
#define S second
#define MP make_pair
#define PB push_back
#define UB upper_bound
#define LB lower_bound
#define ER erase
#define EN end()
#define B begin()
#define I insert
#define OPTIMIZE ios_base::sync_with_stdio(0);cin.tie(0);cout.tie(0);
#define int ll
#define endl "\n"
#define CO cout <<
#define CI cin >>
#define NL cout << endl;
#define DBG {int debug ; cin >> debug;}
#define AND &&
#define OR ||
#define XOR ^
#define OFLUSH fflush(stdout);
#define IFLUSH fflush(stdin);
#define LEN(x) ((int)x.length())

#define rep(i,x) for(int i = 0 ; i < x ; i++)
#define rep1(i,x) for(int i = 1 ; i <= x ; i++)

#define repl(var,start_val,limit_val) for(int var = start_val ; var <= limit_val ; var++)
#define perl(var,start_val,limit_val) for(int var = start_val ; var >= limit_val ; var--)

#define y1 qwert
#define y2 trewq
#define x1 asdfg
#define x2 gfdsa

typedef long long ll;
typedef pair<int,int> ii;
typedef vector<int> vi;
typedef vector< ii > vii;
typedef set<int> si;
typedef multiset<int> msi;
typedef long double ld;


const ll maxn = 5e5+6 ;

int n , m, k, H, a[maxn], ans[maxn];
int fact[1], ifact[1];

string s;
vi g[maxn];

void getInput() {
    cin >> n >> m >> k;
	m *= 2;
	k *= 2;
    repl(i,1,n) cin >> a[i];
	repl(i,1,n) a[i] *= 2;
	sort(a + 1 , a + n + 1);
}

bool isPossible(int at) {
	int ut = a[1];
	int maxReach = m;

	at -= ut;

	if(at < 0) return false;
	repl(i,2,n) {

		if(at < 0) return false;
		int mn = a[i] - ut;
		int mx = a[i] + ut;

		if(mn <= maxReach && maxReach <= mx) {
			maxReach += m;
		} else if(mn > maxReach) {
			int nt = (mn - maxReach) / 2;
			if(at >= nt) {
				at -= nt;
				ut += nt;
				maxReach = (mn-nt) + m;
			} else {
				maxReach += at;
				return maxReach >= k;
			}
		} else {
			maxReach = mx + m;
		}

	}
	maxReach += at;

	return maxReach >= k;
}

void solve() {
	int l = 0 , r = k*4;
	while(l < r) {
		int m = (l + r) / 2;
		bool flag = isPossible(m);
		if(flag) {
			r = m;
		} else {
			l = m+1;
		}
	}
	cout << l << endl;
}

signed main() {

    // factinit();
    // generatePrimes();

    // OPTIMIZE
    //freopen("in.txt" , "r" , stdin) ;
    //freopen("out.txt" , "w" , stdout) ;

    int t=1;
    cin >> t;
    while(t--)
        getInput() , solve();

	return 0;
}



[Editorial - contest/2057]
2057A - MEX TableNote that 0 appears in exactly one row and exactly one column. As for 1, if it exists, it can only be placed in one of the rows or columns that contain 0, so the answer does not exceed operatorname{max}(n, m) + 1, since only one column or row can have an answer greater than one, and in another one there can be an answer of 1. It is not difficult to provide an example where the answer is achieved: if n > m, we place the numbers from 0 to n - 1 in the first column; otherwise, we place the numbers from 0 to m - 1 in the first row. The remaining elements can be placed arbitrarily.
#include <bits/stdc++.h>
 
using i64 = long long;
 
void solve() {
    int n, m;
    std::cin >> n >> m;
    std::cout << std::max(n, m) + 1 << "\n";
}
 
signed main() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);
 
    int t = 1;
    std::cin >> t;
    
    while (t--) {
        solve();
    }
}
2057B - Gorilla and the ExamNote that f(a) is the number of distinct numbers in the array. Since it is beneficial for us to always choose the entire array as the segment, because we will eventually remove the minimum element, it is advantageous to remove it from the entire array at once.Therefore, our task has been reduced to changing no more than k elements in order to minimize the number of distinct elements. To achieve this, we observe that it is always beneficial to change all the numbers that occur the least in the array and change them to the number that occurs the most frequently. This process can be easily accomplished in O(n log n) .
#include <bits/stdc++.h>

using i64 = long long;

void solve() {
    int n, k;
    std::cin >> n >> k;
    std::vector<int> a(n);
    for (int i = 0; i < n; i++) {
        std::cin >> a[i];
    }
    std::sort(a.begin(), a.end());
    std::vector<int> cnt = {1};
    for (int i = 1; i < n; i++) {
        if (a[i] == a[i - 1]) {
            cnt.back()++;
        } else {
            cnt.emplace_back(1);
        }
    }
    std::sort(cnt.begin(), cnt.end());
    int m = cnt.size();
    for (int i = 0; i < m - 1; i++) {
        if (cnt[i] > k) {
            std::cout << m - i << "\n";
            return;
        }
        k -= cnt[i];
    }
    std::cout << 1 << "\n";
}

signed main() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);

    int t = 1;
    std::cin >> t;

    while (t--) {
        solve();
    }
}
2057C - Trip to the OlympiadLet's take a look at the i-th bit. If it appears in all numbers or in none, it contributes nothing to the answer; however, if it appears in one or two numbers, it adds 2^{i + 1} to the answer.Therefore, let's examine the most significant bit, let's say the k-th bit, which differs in the numbers l and r, and note that the more significant bits do not affect the outcome, so the answer cannot exceed T = 2 cdot (1 + 2 + ldots + 2^k).Thus, let x be the only number that is divisible by 2^k in the range [l, r]. Take y = x - 1 and z as any number in the range [l, r] that is neither x nor y. Notice that by choosing such a triplet of numbers, the value of the expression (x oplus y) + (x oplus z) + (y oplus z) is exactly equal to T.
#include <bits/stdc++.h>
 
using i64 = long long;
 
void solve() {
    int l, r;
    std::cin >> l >> r;
    int k = 31 - __builtin_clz(l ^ r);
    int a = l | ((1 << k) - 1), b = a + 1, c = (a == l ? r : l);
    std::cout << a << " " << b << " " << c << "\n";
}
 
signed main() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);
 
    int t = 1;
    std::cin >> t;
 
    while (t--) {
        solve();
    }
}

2057D - Gifts OrderTo begin with, let's take a look at what an optimal segment of coats looks like. I claim that in the optimal answer, the maximum and minimum are located at the edges of the segment. Suppose this is not the case; then we can narrow the segment (from the side where the extreme element is neither the minimum nor the maximum), and the answer will improve since the length will decrease, while the minimum and maximum will remain unchanged.Okay, there are two scenarios: when the minimum is at l and the maximum is at r, and vice versa. These two cases are analogous, so let's consider the solution when the minimum is at l. Let's express what the value of the segment actually is: it is a_r - a_l - (r - l) = (a_r - r) - (a_l - l), meaning there is a part that depends only on r and a part that depends only on l. Let's create a segment tree where we will store the answer, as well as the maximum of all a_i - i and the minimum of all a_i - i (for the segment that corresponds to the current node of the segment tree, of course). Now, let's see how to recalculate the values at the node. First, the minimum/maximum of a_i - i can be easily recalculated by taking the minimum/maximum from the two children of the node in the segment tree. Now, how do we recalculate the answer? In fact, it is simply the maximum of the two answers for the children, plus (the maximum in the right child) minus (the minimum in the left child), which is the case when the maximum is in the right child and the minimum is in the left. Since we maintain this in the segment tree, we can easily handle update queries.For greater clarity, I recommend looking at the code.
#include <bits/stdc++.h>

using i64 = long long;

template<class Info>
struct SegmentTree {
    int n;
    std::vector<Info> info;

    SegmentTree() : n(0) {}

    SegmentTree(int n_, Info v_ = Info()) {
        init(n_, v_);
    }

    template<class T>
    SegmentTree(std::vector<T> init_) {
        init(init_);
    }

    void init(int n_, Info v_ = Info()) {
        init(std::vector<Info>(n_, v_));
    }

    template<class T>
    void init(std::vector<T> init_) {
        n = init_.size();
        int sz = (1 << (std::__lg(n - 1) + 1));
        info.assign(sz * 2, Info());
        std::function<void(int, int, int)> build = [&](int v, int l, int r) {
            if (l == r) {
                info[v] = init_[l];
                return;
            }
            int m = (l + r) / 2;
            build(v + v, l, m);
            build(v + v + 1, m + 1, r);
            info[v] = info[v + v] + info[v + v + 1];
        };
        build(1, 0, n - 1);
    }

    Info rangeQuery(int v, int l, int r, int tl, int tr) {
        if (r < tl || l > tr) {
            return Info();
        }
        if (l >= tl && r <= tr) {
            return info[v];
        }
        int m = (l + r) / 2;
        return rangeQuery(v + v, l, m, tl, tr) + rangeQuery(v + v + 1, m + 1, r, tl, tr);
    }

    Info rangeQuery(int l, int r) {
        return rangeQuery(1, 0, n - 1, l, r);
    }

    void modify(int v, int l, int r, int i, const Info &x) {
        if (l == r) {
            info[v] = x;
            return;
        }
        int m = (l + r) / 2;
        if (i <= m) {
            modify(v + v, l, m, i, x);
        } else {
            modify(v + v + 1, m + 1, r, i, x);
        }
        info[v] = info[v + v] + info[v + v + 1];
    }

    void modify(int i, const Info &x) {
        modify(1, 0, n - 1, i, x);
    }

    Info query(int v, int l, int r, int i) {
        if (l == r) {
            return info[v];
        }
        int m = (l + r) / 2;
        if (i <= m) {
            return query(v + v, l, m, i);
        } else {
            return query(v + v + 1, m + 1, r, i);
        }
    }

    Info query(int i) {
        return query(1, 0, n - 1, i);
    }
};

const int INF = 1E9;

struct Info {
    int min1, min2, max1, max2, ans1, ans2;

    Info() : min1(INF), min2(INF), max1(-INF), max2(-INF), ans1(0), ans2(0) {}

    Info(std::pair<int, int> x) : min1(x.first), min2(x.second), max1(x.first), max2(x.second), ans1(0), ans2(0) {}
};

Info operator+(const Info &a, const Info &b) {
    Info res;
    res.min1 = std::min(a.min1, b.min1);
    res.min2 = std::min(a.min2, b.min2);
    res.max1 = std::max(a.max1, b.max1);
    res.max2 = std::max(a.max2, b.max2);
    res.ans1 = std::max({a.ans1, b.ans1, b.max1 - a.min1});
    res.ans2 = std::max({a.ans2, b.ans2, a.max2 - b.min2});
    return res;
}

void solve() {
    int n, q;
    std::cin >> n >> q;
    std::vector<int> a(n);
    std::vector<std::pair<int, int>> t(n);
    for (int i = 0; i < n; i++) {
        std::cin >> a[i];
        t[i] = {a[i] - i, a[i] + i - n + 1};
    }
    SegmentTree<Info> st(t);
    auto query = [&]() {
        return std::max(st.info[1].ans1, st.info[1].ans2);
    };
    std::cout << query() << "\n";
    for (int i = 0; i < q; i++) {
        int p, x;
        std::cin >> p >> x;
        p--;
        t[p] = {x - p, x + p - n + 1};
        st.modify(p, t[p]);
        std::cout << query() << "\n";
    }
}

signed main() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);

    int t;
    std::cin >> t;

    while (t--) {
        solve();
    }
}
2057E1 - Another Exercise on Graphs (Easy Version)We will learn how to check if there exists a path from a to b such that the k-th maximum on this path is less than or equal to x. For a fixed x, the edges are divided into two types: light (weight less than or equal to x) and heavy (weight strictly greater than x). We assign a weight of 0 to all light edges and a weight of 1 to all heavy edges. Then, the desired path exists if and only if the shortest path between a and b (considering the assigned weights) is strictly less than k.Now, let's consider that we have many queries.Initially, we assign a weight of 1 to all edges and compute the length of the shortest path between each pair of vertices. Then, we will process the edges in increasing order of weight and replace their weights with 0. After each such change, we need to be able to recalculate the shortest paths between each pair of vertices. Let textrm{d}[i][j] be the shortest paths before changing the weight of the edge (a, b); then the lengths of the new paths textrm{d}' can be computed using the formula:$$$ textrm{d}'[i][j] = min { textrm{d}[i][j], textrm{d}[a][i] + textrm{d}[b][j], textrm{d}[b][i] + textrm{d}[a][j], } Thus, each recalculation of the lengths of the shortest paths can be performed in O(n^2). Let \textrm{dp}[k][i][j] be the length of the shortest path between the pair of vertices i and j$$$, if the weights of the minimum k edges are 0, and the weights of the remaining edges are 1. We have just learned how to recalculate this dynamic programming in $$$O(n^2 \cdot m) time.Using the criterion, we can answer each of the queries in O(\log m) time using the binary search method and the computed array \textrm{dp}[k][i][j]$$$.On simple and non-simple paths. If there is a cycle in the path, it can be removed from this path, and the k-th maximum will not increase. Thus, if we restrict the set of considered paths to only simple paths (i.e., those that do not contain cycles in any form), the answer will not change.
#include <bits/stdc++.h>
 
using i64 = long long;
 
void solve() {
    int n, m, q;
    std::cin >> n >> m >> q;
    std::vector<std::array<int, 3>> edges(m);
    for (int i = 0; i < m; i++) {
        int v, u, w;
        std::cin >> v >> u >> w;
        v--, u--;
        edges[i] = {v, u, w};
    }
    std::sort(edges.begin(), edges.end(), [&](const std::array<int, 3> &a, const std::array<int, 3> &b) {
        return a[2] < b[2];
    });
    constexpr int INF = 1e9;
    std::vector<int> value(m + 1);
    std::vector<std::vector<std::vector<int>>> dis(m + 1, std::vector<std::vector<int>>(n, std::vector<int>(n, INF)));
    for (int i = 0; i < n; i++) {
        dis[0][i][i] = 0;
    }
    for (auto edge : edges) {
        int v = edge[0], u = edge[1];
        dis[0][v][u] = dis[0][u][v] = 1;
    }
    for (int k = 0; k < n; k++) {
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                dis[0][i][j] = std::min(dis[0][i][j], dis[0][i][k] + dis[0][k][j]);
            }
        }
    }
    int p = 1;
    for (auto edge : edges) {
        int v = edge[0], u = edge[1], w = edge[2];
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                dis[p][i][j] = std::min({dis[p - 1][i][j], dis[p - 1][i][v] + dis[p - 1][u][j], dis[p - 1][i][u] + dis[p - 1][v][j]});
            }
        }
        value[p++] = w;
    }
    for (int i = 0; i < q; i++) {
        int v, u, k;
        std::cin >> v >> u >> k;
        v--, u--;
        int low = 0, high = m;
        while (high - low > 1) {
            int mid = (low + high) / 2;
            if (dis[mid][v][u] < k) {
                high = mid;
            } else {
                low = mid;
            }
        }
        std::cout << value[high] << " \n"[i == q - 1];
    }
}
 
signed main() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);
 
    int t = 1;
    std::cin >> t;
 
    while (t--) {
        solve();
    }
}
2057E2 - Another Exercise on Graphs (hard version)Please read the solution to problem E1.Let's return to the process where we sequentially changed the weights of the edges from 1 to 0. If we replace the weight of another edge with 0 and it connects vertices that are at a distance of 0, it means that the shortest paths between each pair of vertices will not change at all, so we will not recalculate the shortest paths in this case.We also will not store useless layers in the array textrm{dp}[k][i][j]. This allows us to improve the asymptotic complexity of our solution to O(n^3 + q log n).Proof. We will consider a graph that consists only of edges with weight 0. We have m consecutive requests to add an edge. Notice that we compute a new layer of textrm{dp} only if, after adding the edge, some two components of this graph are merged, but this will happen exactly n-1 times.
#include <bits/stdc++.h>

using i64 = long long;

struct DSU {
    std::vector<int> p, sz, h;
    
    DSU(int n = 0) : p(n), sz(n, 1), h(n) { 
        std::iota(p.begin(), p.end(), 0); 
    }

    int leader(int x) {
        if (x == p[x]) {
            return x;
        }
        return leader(p[x]);
    }

    bool same(int x, int y) {
        return leader(x) == leader(y);
    }

    bool merge(int x, int y) {
        x = leader(x);
        y = leader(y);
        if (x == y) return false;
        if (h[x] < h[y]) {
            std::swap(x, y);
        }
        if (h[x] == h[y]) {
            ++h[x];
        }
        sz[x] += sz[y];
        p[y] = x;
        return true;
    }

    int size(int x) { 
        return sz[leader(x)]; 
    }
};

void solve() {
    int n, m, q;
    std::cin >> n >> m >> q;
    std::vector<std::array<int, 3>> edges(m);
    for (int i = 0; i < m; i++) {
        int v, u, w;
        std::cin >> v >> u >> w;
        v--, u--;
        edges[i] = {v, u, w};
    }
    std::sort(edges.begin(), edges.end(), [&](const std::array<int, 3> &a, const std::array<int, 3> &b) {
        return a[2] < b[2];
    });
    constexpr int INF = 1e9;
    std::vector<int> value(n);
    std::vector<std::vector<std::vector<int>>> dis(n, std::vector<std::vector<int>>(n, std::vector<int>(n, INF)));
    for (int i = 0; i < n; i++) {
        dis[0][i][i] = 0;
    }
    for (auto edge : edges) {
        int v = edge[0], u = edge[1];
        dis[0][v][u] = dis[0][u][v] = 1;
    }
    for (int k = 0; k < n; k++) {
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                dis[0][i][j] = std::min(dis[0][i][j], dis[0][i][k] + dis[0][k][j]);
            }
        }
    }
    int p = 1;
    DSU dsu(n);
    for (auto edge : edges) {
        int v = edge[0], u = edge[1], w = edge[2];
        if (dsu.merge(v, u)) {
            for (int i = 0; i < n; i++) {
                for (int j = 0; j < n; j++) {
                    dis[p][i][j] = std::min({dis[p - 1][i][j], dis[p - 1][i][v] + dis[p - 1][u][j], dis[p - 1][i][u] + dis[p - 1][v][j]});
                }
            }
            value[p++] = w;
        }
    }
    for (int i = 0; i < q; i++) {
        int v, u, k;
        std::cin >> v >> u >> k;
        v--, u--;
        int low = 0, high = n - 1;
        while (high - low > 1) {
            int mid = (low + high) / 2;
            if (dis[mid][v][u] < k) {
                high = mid;
            } else {
                low = mid;
            }
        }
        std::cout << value[high] << " \n"[i == q - 1];
    }
}

signed main() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);

    int t = 1;
    std::cin >> t;

    while (t--) {
        solve();
    }
}
2057F - FormationHint 1: how much does a single index affect those before him?Hint 2: try looking at the formula for making an index a maximum differentlyHint 3: do you need to answer all queries online?Hint 4: do you need to consider all indexes?Solution: Let's fix the index that we want our maximum to be on — let it be i. Then, due to k_i being le 10^9 in each test case, and every number in our array a also being le 10^9, we do not need to consider any indexes before i - 30 — they are also valid as they were part of the previous good array, and we do not need to make them bigger as 2^{31} ge 2 * 10^9.Now let's try doing binary search on the answer for each query (let our current query be with the number M). When we fix our possible answer as X at index i, what does that mean? It means that we need a_i ge X, a_{i-1} ge lceil{frac{X}{2}} rceil, and so on, calculating every index through the next one (i from i + 1). Let us call this auxiliary array c ( c_0 = X, c_i = lceilfrac{c_{i - 1}}{2} rceil). So, if we need to change exactly k indexes before i (i, i - 1, ..., i - k) , our condition for checking whether we could do that is as followed:1. a_{i - j} le c_j for each 0 le j le k2. sum_{j = 0}^{k} c_j - a_{i - j} le M.Now, we can see that for each fixed k from 0 to log MAX = 30, we should choose such an index i, that its previous indexes satisfy condition 1 from above, and sum_{j = 0}^{k} a_{i - j} is minimal.Let's consider solving this via scanline. For each index i and each k from 0 to 30, let's consider the possible values of M such that if we want our maximum to be on index i, it will affect exactly (a_i, a_{i - 1}, ldots, a_{i - k}). We can notice that such values form a segment [L_{ik}, R_{ik}], which is possiblyinvalid (L_{ik} > R_{ik}). We can find these segments in O(N log MAX).Now let's go through the request offline in ascending order, maintaining currently active indexes. We maintain log MAX + 1 multisets with the minimum possible sums on valid segments of each length, and update them on each opening/closing of a segment ( this is done in O(N log ^ 2 MAX) ). On each request, we do binary search on the answer, and check all log MAX length candidates.
#include <bits/stdc++.h>
 
using i64 = long long;
 
void solve() {
    int n, q;
    std::cin >> n >> q;
    std::vector<int> a(n);
    for (int i = 0; i < n; i++) {
        std::cin >> a[i];
    }
    constexpr int LG = 30;
    std::vector<std::array<i64, 4>> events;
    for (int i = 0; i < n; i++) {
        i64 pow = 1, sum = 0;
        i64 dop = 0;
        for (int j = 0; j < LG; j++) {
            if (i - j < 0) {
                break;
            }
            sum += a[i - j];
            i64 L = dop, R;
            if (i - j == 0) {
                R = 2E18;
            } else {
                i64 x = (pow * 4 - 2) * a[i - j - 1] - sum;
                R = x;
                dop = x;
            }
            pow *= 2;
            events.push_back({L, -1, j, sum});
            events.push_back({R, 1, j, sum});
        }
    }
    for (int i = 0; i < q; i++) {
        int x;
        std::cin >> x;
        events.push_back({x, 0, i, 0});
    }
    std::sort(events.begin(), events.end());
    std::vector<int> ans(q); 
    std::vector<std::multiset<i64>> st(LG);
    for (auto item : events) {
        int h = item[0];
        int o = item[1];
        if (o == -1) {
            int j = item[2];
            i64 sum = item[3];
            st[j].insert(sum);
        } else if (o == 1) {
            int j = item[2];
            i64 sum = item[3];
            st[j].erase(st[j].find(sum));
        } else {
            int i = item[2];
            int low = 0, high = 2E9 + 1;
            while (high - low > 1) {
                int mid = (0LL + low + high) / 2;
                int cur = mid;
                i64 pos = 0;
                bool ok = false;
                for (int cnt = 0; cnt < LG; cnt++) {
                    if (st[cnt].empty()) {
                        continue;
                    }
                    i64 neg = *st[cnt].rbegin();
                    pos += cur;
                    cur = (cur + 1) / 2;
                    if (pos - neg <= h) {
                        ok = true;
                        break;
                    }
                }
                if (ok) {
                    low = mid;
                } else {
                    high = mid;
                }
            }
            ans[i] = low;
        }
    }
    for (int i = 0; i < q; i++) {
        std::cout << ans[i] << " \n"[i == q - 1];
    }
}
 
signed main() {
    std::ios::sync_with_stdio(false);
    std::cin.tie(nullptr);
 
    int t = 1;
    std::cin >> t;
 
    while (t--) {
        solve();
    }
}

// Parallel binary search technique optimizes log^3 => log^2
// SegmentTree might be faster then std::multiset
// sl[i] should equals max(a) at the begining cause IDK how to explain but it's obviously important
 
#include <bits/stdc++.h>
#include <algorithm>
 
using namespace std;
using ll = long long;
 
constexpr int W = 31;
constexpr int C = 1'000'000'000;
 
struct Event {
    int x;
    int ind;
    ll s;
 
    bool operator<(const Event& rhs) const { return x < rhs.x; }
};
 
struct SegmentTree {
    int n;
    vector<ll> sgt;
 
    SegmentTree(int n) : n(n), sgt(2 * n, -1) {}
 
    void Change(int i, ll x) {
        for (sgt[i += n] = x; i != 1; i >>= 1) {
            sgt[i >> 1] = max(sgt[i], sgt[i ^ 1]);
        }
    }
 
    int GlobalMax() const { return sgt[1]; }
};
 
vector<int> solve(const vector<int>& a, const vector<int>& q) {
    const int n = a.size(), m = q.size();
 
    vector<ll> ps(n + 1);
    for (int i = 0; i < n; ++i)
        ps[i + 1] = ps[i] + a[i];
 
    vector<ll> min_x(n, 0);
    vector<vector<pair<int, ll>>> change_sum(W);
 
    vector<Event> events;
    events.reserve(2 * n);
    for (int j = 1; j <= W && j <= n; ++j) {
        events.clear();
 
        for (int i = j - 1; i < n; ++i) {
            min_x[i] = max(min_x[i], 1 + ((a[i - j + 1] - 1ll) << (j - 1)));
            ll max_x = i == j - 1 ? 2ll * C : ((ll)a[i - j] << j);
            max_x = min<ll>(max_x, a[i] + C);
 
            if (min_x[i] > max_x) {
                continue;
            }
            const ll xsum = ps[i + 1] - ps[i + 1 - j];
            events.push_back(Event{(int)min_x[i], i, xsum});
            events.push_back(Event{(int)max_x + 1, i, -1});
        }
        sort(events.begin(), events.end());
 
        SegmentTree sgt(n);
        const int k = events.size();
        ll was_max = -1;
 
        for (int i = 0; i < k;) {
            int s = i;
            while (i < k && events[i].x == events[s].x) {
                sgt.Change(events[i].ind, events[i].s);
                ++i;
            }
            ll cur_max = sgt.GlobalMax();
            if (cur_max != was_max) {
                change_sum[j - 1].emplace_back(events[s].x, cur_max);
                was_max = cur_max;
            }
        }
    }
 
    vector<int> sl(m, *max_element(a.begin(), a.end())), sr(m, 2 * C + 1);
 
    vector<int> ord_to_check(m);
    iota(ord_to_check.begin(), ord_to_check.end(), 0);
    for (int iter = 32; iter--;) {
        vector<int> sm(m);
        for (int i = 0; i < m; ++i) {
            sm[i] = sl[i] + (sr[i] - sl[i]) / 2;
        }
        sort(ord_to_check.begin(), ord_to_check.end(), [&](int lhs, int rhs) {
            return sm[lhs] < sm[rhs];
        });
 
        vector<int> ptr(W);
        vector<ll> actual_sum(W, -1);
        for (int i : ord_to_check) {
            const int x = sm[i];
 
 
            ll upper_sum = 0;
            bool nice = false;
            for (int w = 0; w < W; ++w) {
                int& j = ptr[w];
                while (j < change_sum[w].size() && change_sum[w][j].first <= x) {
                    actual_sum[w] = change_sum[w][j++].second;
                }
                upper_sum += 1 + ((x - 1) >> w);
                if (upper_sum - actual_sum[w] <= q[i]) {
                    nice = true;
                }
            }
 
            if (nice) {
                sl[i] = sm[i];
            } else {
                sr[i] = sm[i];
            }
        }
    }
 
    return sl;
}
 
int main() {
    ios::sync_with_stdio(0);
    cin.tie(0);
 
    int t = 1;
    cin >> t;
    while (t--) {
        int n, q;
        cin >> n >> q;
        vector<int> a(n), k(q);
        for (int& x : a)
            cin >> x;
        for (int& x : k)
            cin >> x;
 
        auto ans = solve(a, k);
        for (int x : ans)
            cout << x << ' ';
        cout << '\n';
    }
}

2057G - Secret MessageWe will divide the infinite grid into 5 sets of cells L_1, L_2, L_3, L_4, and L_5, where L_i = { (x, y) in mathbb{Z}^2 space | space (x + 2 y) equiv i pmod{5} }. Note that for any pair (x,y), all 5 cells (x,y), (x-1, y), (x+1, y), (x, y-1), (x, y+1) belong to different sets L_1, ldots, L_5.If we try to consider the sets T_i = L_i cap A, it is not guaranteed that each of them will satisfy the property: "For each cell in the set A, either it or one of its neighboring cells shares a side belongs to the set S." Therefore, we denote D_i subseteq A as the set of cells from A that do not belong to T_i and all four neighbors of each of them also do not belong to T_i.Now we need to verify the correctness of two statements:  |T_1| + |T_2| + |T_3| + |T_4| + |T_5| = s;  |D_1| + |D_2| + |D_3| + |D_4| + |D_5| = p; The first statement is obvious since T_1 cup ldots cup T_5 = A. The second statement is true because if some cell (x, y) does not belong to T_i and all its neighbors do not belong to T_i, it means that it has a neighbor (x', y') such that (x' + 2y') bmod 5 = i. But we know that (x', y') not in A, which means we can mark the shared side of (x,y) and (x', y'). If we process T_1, ldots, T_5 sequentially, then after this process, each segment of the boundary will be marked exactly once, and thus the number of such segments coincides with |D_1| + ldots + |D_5|.Now let S_i = T_i cup D_i and note that |S_1| + ldots + |S_5| = s + p, which means, by the pigeonhole principle, there exists a j such that |S_j| le frac{1}{5} cdot (s + p), and then S_j will be suitable as the desired set.
#include <bits/stdc++.h>

using namespace std;
using pi = pair<int, int>;

void solve() {
    int n, m; cin >> n >> m;
    vector<string> v(n);
    for (auto& w : v) cin >> w;

    auto col = [](int x, int y) {
        int c = (x+2*y)%5;
        if (c < 0) c += 5;
        return c;
    };
    auto cell = [&](int x, int y) {
        if (x < 0 || y < 0 || x >= n || y >= m) return false;
        return v[x][y] == '#';
    };

    array<vector<pi>, 5> colorings;
    for (int i = 0; i < n; ++i)
    for (int j = 0; j < m; ++j) {
        if (!cell(i, j)) continue;
        colorings[col(i, j)].emplace_back(i, j);

        for (int di = -1; di <= 1; ++di)
        for (int dj = -1; dj <= 1; ++dj) {
            if (abs(di) + abs(dj) != 1) continue;
            if (!cell(i+di, j+dj)) {
                colorings[col(i+di, j+dj)].emplace_back(i, j);
            }
        }
    }

    auto coloring = colorings[0];
    for (const auto& w : colorings)
        if (w.size() < coloring.size()) coloring = w;
    for (auto [x, y] : coloring) v[x][y] = 'S';
    for (auto line : v) cout << line << '\n';
}

int main() {
    ios::sync_with_stdio(0); cin.tie(0);

    int t; cin >> t;
    while (t--)
        solve();
}
2057H - Coffee BreakLet's call the elementary action E_j the operation after which a_j decreases by 2, and the values a_{j-1} and a_{j+1} increase by 1. Let A be some set of actions that can be performed in some order; then this same set of actions can be performed greedily, each time performing any available elementary action. Our solution will be based on two facts:  If we want to maximize a_k, then actions E_1, ldots E_{k-1}, E_{k+1}, ldots E_n can be performed at any time, as long as it is possible.  In this case, action E_k cannot be performed at all. The proof of the first fact is obvious. Suppose at some moment we can perform action E_j (j neq k); then if we do not apply it in the optimal algorithm, its application at that moment will not spoil anything. And if we do apply it, then let's apply this action right now instead of postponing it; this will also change nothing.The proof of the second fact is slightly less obvious, so we will postpone it for later. For now, let's figure out how to emulate the application of elementary actions on the prefix a_1, ldots, a_{k-1} and on the suffix a_{k+1}, ldots, a_n.Without loss of generality, let's assume we are considering the prefix of the array a of length p. Additionally, assume that a_1, ldots, a_{p-1} le 1, i.e., we cannot apply any of the actions E_1, ldots, E_{p-1}. If a_p le 1, then nothing can happen with this prefix for now. Otherwise, the only thing we can do is action E_p; after that, we may be able to apply action E_{p-1}, E_{p-2}, and so on. Let's see what happens if a_p = 2:$$$ [ldots, 0, 1, 1, 1, 2] to [ldots, 0, 1, 1, 2, 0] to ldots to [ldots, 0, 2, 0, 1, 1] to [ldots, 1, 0, 1, 1, 1] Thus, the position of the last zero in the prefix increases by one, and the value of a_{p+1} also increases by one. We introduce a second elementary action I_j$$$ — increasing a_j by one if we previously decreased it by one. This action does not affect the answer, as it can be perceived as "reserving" a_j for the future.To understand what happens to the array $$$[a_1, \ldots, a_p] with an arbitrary value of a_p, we will assume that a_p = 0, but we will consider that we can apply action I_p x times, which increases a_p by one. After each action I_p, we will emulate the greedy application of actions E_1, \ldots, E_p. This can be done as follows:  In the stack S, we store the positions of zeros in the array [a_1, \ldots, a_p] (the other values are equal to one).  Let l be the position of the last zero; then:  If l=p, then this zero simply disappears from the stack.  If l<p, then it is easy to emulate the next p-l actions I_p: after each of them, the array looks like [\ldots, 0, 1, 1, \ldots, 1, 2], and thus after the greedy application of actions E_1, \ldots, E_p, the value of l$$$ increases by 1.  If the stack $$$S is empty, then after one action, a_{p+1}$$$ increases by one, and the only element with index 1 becomes zero. If we repeat actions after this point, the cases will break down identically with a period of $$$p+1. Thus, we have learned to understand what happens with each prefix of the array a_1, \ldots, a_n$$$ if we greedily apply elementary actions E_j ($$$1 \le j \le p). In total, we can emulate these actions in O(n)$$$ time.Now let's return to the second point of the statement: if we want to maximize a_k, then we cannot perform actions E_k. Without loss of generality, let's assume that we first performed actions E_j (j neq k) greedily, and now we have $$$a_j \le 1$$$ (j neq k). Suppose we performed action E_k at least once; then after that, we will greedily perform elementary actions to the left and right, for which the stack scheme we considered above works. Notice that after this, the value of a_k will increase by no more than 2 (no more than 1 after actions on the prefix and no more than 1 after actions on the suffix). Thus, action E_k after application did not lead to an increase in a_k, nor will it lead to an increase if we apply E_k later, which means that it is useless—there is no need to perform it.Thus, we have proven that by using elementary actions $$$E_1, \ldots, E_{k-1}, E_{k+1}, \ldots E_n$$$ based on the principle of "do while we can", we can easily maximize a_k. But in the original problem, we could not apply elementary actions. The operation in the problem, i.e., $$$a_{i-1} += \lfloor \frac12 a_i\ \rfloor, a_{i+1} += \lfloor \frac12 a_i\ \rfloor, a_i = a_i \bmod 2, can be perceived as applying elementary actions E_i consecutively while they are applicable. Fortunately, we just proved that actions can be performed in any order, which means that if we apply the operation from the problem for all indices i \neq k$$$, we will eventually reach the same result, and the value of a_k will reach its maximum.
#include <bits/stdc++.h>

using namespace std;
using vi = vector<int>;
using ll = long long;

vector<ll> a, lhs, rhs;
vector<int> st;

vector<ll> get_right_out(const vector<ll>& a, vector<ll>& res) {
    const int n = a.size();
    st.clear();
    res.assign(n+1, 0);

    for (int i = 0; i < n; ++i) {
        ll x = a[i] + res[i];
        st.push_back(i);

        while (x != 0) {
            if (st.empty()) {
                const int len = i + 1;
                const ll cnt = x / (len + 1);
                res[i+1] += cnt * len;
                x -= cnt * (len + 1);

                if (x != 0) {
                    res[i+1] += x;
                    st.push_back(x-1);
                    x = 0;
                }
            } else {
                const int j = st.back();
                if (x > i - j) {
                    res[i+1] += i - j;
                    st.pop_back();
                    x -= i - j + 1;
                } else {
                    res[i+1] += x;
                    st.back() += x;
                    x = 0;
                }
            }
        }
    }

    return res;
}

vector<ll> get_left_out(vector<ll>& a, vector<ll>& b) {
    reverse(a.begin(), a.end());
    get_right_out(a, b);
    reverse(b.begin(), b.end());
    reverse(a.begin(), a.end());
    return b;
}

void solve() {
    int n; cin >> n;
    
    a.resize(n);
    for (ll& x : a) cin >> x;

    get_right_out(a, lhs);
    get_left_out(a, rhs);

    ll ans = 0;
    for (int i = 0; i < n; ++i)
        cout << lhs[i] + a[i] + rhs[i+1] << ' ';
    cout << '\n';
}

int main() {
    ios::sync_with_stdio(0); cin.tie(0);

    int t = 1;
    cin >> t;
    while (t--) solve();
}


[Editorial - contest/2053]
     A  B  C  D  E  F  G  H  I      _istil  800  1200  1400  1700  1900  2500  [2800, 3300]  3200  [800, 3000]    Cocoly1990  800  1300          3000        TheScrasse  800  1200  ?  1800    2500  3000  3000  3500    LMydd0225  800  1300  1600  1900  2100  2400  2800  2900  [2500, 3200]    Error_Yuan  900  1200  1400  2000  2100  2500  3000    3200    Caylex  800  1300  1500  1900  2200  2600  [2500, 3100]        tzl_Dedicatus545  800  1000  1100  1400    2300          PaciukZvichainyi  800  1200  1500  1800  2100  2500          doujinshi_master  800  1200  1500  1800              juan_123  800  [800, 1100]  1000  1700    2400  2800    [2700, 3500]    StarSilk  800  1300  1400  1700    2500  3100  2700      SkyWave2022  800  1200  1600  [1600, 1900]              ABitVeryScaredOfWomen  800  1200  1500  1800  2100            FFTotoro  800  1200  1400  1900  1900  2400  2900      
Can you find a partition that is always valid?
Suppose you are given a set S. How do you judge whether S is stable in O(|S|)?
Are sets that are very large really necessary?
Note that: we always have a partition like [a1],[a2],…,[an], since (x,x,x) always forms a non-degenerate (equilateral) triangle.We focus on the second partition scheme in which not all continuous subsegments have a length of 1. One can also note that if a set S is stable then for all T⊊S (T≠∅), T is also stable.  Short proof: If ∃u,v,w∈T such that (u,v,w) doesn't form a non-degenerate triangle, therefore u,v,w∈S so it is concluded that S is not stable. Contradiction! If such a partition exists, we can always split long continuous subsegments into shorter parts, while the partition remains valid. Therefore, it's enough to check the case in which there is one subsegment of length 2 and the rest of length 1. So, we should output NO if and only if for all 1≤i<n, 2min(ai,ai+1)≤max(ai,ai+1).
#include <bits/stdc++.h>
 
#define MAXN 1001
int a[MAXN];
void solve() {
	int n; std::cin >> n;
	for (int i = 1; i <= n; ++i) std::cin >> a[i];
	for (int i = 1; i < n; ++i) if (2 * std::min(a[i], a[i + 1]) > std::max(a[i], a[i + 1])) 
		{ std::cout << "YES\n"; return; }
	std::cout << "NO\n";
}
 
int main() {
	std::ios::sync_with_stdio(false);
	std::cin.tie(nullptr), std::cout.tie(nullptr);
	int t; std::cin >> t; while (t--) solve(); return 0;
}
 Amazing problem: 




86





 Good problem: 

    


295



 Average problem: 

    


111



 Bad problem: 

    


39



 Didn't solve: 

    


18



 
What if for all 1≤i≤n, li≠ri holds? How do you prove it?
Use prefix sums or similar to optimize your solution.
For each 1≤i≤n, for each li≤x≤ri, we want to check if it is okay for impression i being unique at the value of x. Note that: for each j≠i, we can always switch wj to a value different from x if lj≠rj, since there are at least two options. Therefore, it is impossible if and only if there exists a 1≤j≤n with j≠i such that lj=rj=x.Let's record ai as the number of different k satisfying 1≤k≤n and lk=rk=i. If li≠ri, then we say impression i cannot be made unique if and only if for all li≤k≤ri, ak≥1; otherwise (li=ri), it cannot be unique if and only if ali≥2.This can all be checked quickly within a prefix sum, so the overall time complexity is O(∑n).
#include <bits/stdc++.h>
 
#define MAXN 400001
int l[MAXN], r[MAXN], sum[MAXN], cnt[MAXN];
void solve() {
	int n; std::cin >> n;
	for (int i = 1; i <= 2 * n; ++i) sum[i] = cnt[i] = 0;
	for (int i = 1; i <= n; ++i) {
		std::cin >> l[i] >> r[i];
		if (l[i] == r[i]) sum[l[i]] = 1, ++cnt[l[i]];
	}
	for (int i = 2; i <= 2 * n; ++i) sum[i] += sum[i - 1];
	for (int i = 1; i <= n; ++i) 
		std::cout << ((l[i] == r[i] ? cnt[l[i]] <= 1 : sum[r[i]] - sum[l[i] - 1] < r[i] - l[i] + 1) ? "1" : "0");
	std::cout << '\n';
}
int main() {
	std::ios::sync_with_stdio(false);
	std::cin.tie(nullptr), std::cout.tie(nullptr);
	int t; std::cin >> t; while (t--) solve(); return 0;
}
 Amazing problem: 

    


328



 Good problem: 

    


149



 Average problem: 

    


56



 Bad problem: 

    


136



 Didn't solve: 

    


51



 
Process many segments simultaneously. What kind of segments do we process at a time?
The length.
The point that must be noted is: that if we call the process of splitting a large segment into two smaller segments a round, then all segments are of the same length when the i-th round of the observation is conducted; and, the number of rounds does not exceed O(logn). The k restriction is equivalent to specifying that only a certain prefix of rounds is computed.Here are some different approaches:  (Most succinctly) Note that the distribution of segments after round 1 is centrally symmetric; Also, x and y being centrally symmetric implies that x+y=n+1, so it is simple to calculate by simulating the number of segments and the length directly. If a segment [l,r] is split into [l,m−1] and [m+1,r], its left endpoint sum changes from l to 2l+r−l2+1, and since (r−l) is fixed, the sum of the left endpoints of all segments can be maintained similarly. The following recursive method also works: the answer to n can be recovered by the answer to ⌊n2⌋. The time complexity is O(tlogn). 
This is written by _TernaryTree_. #include <bits/stdc++.h>
#define int long long
 
using namespace std;
 
int T;
int n, k;
 
signed main() {
	cin >> T;
	while (T--) {
		cin >> n >> k;
		int mul = n + 1, sum = 0, cur = 1;
		while (n >= k) {
			if (n & 1) sum += cur;
			n >>= 1;
			cur <<= 1;
		}
		cout << mul * sum / 2 << endl;
	}
	return 0;
}
 Amazing problem: 

    


380



 Good problem: 

    


130



 Average problem: 

    


37



 Bad problem: 

    


224



 Didn't solve: 

    


100



 
What if q=0?
How do you keep the array sorted?
The problem makes no difference when both a and b can be rearranged. Let the rearranged arrays of a and b be c and d respectively.If q=0, we can write c as SORTED(a1,a2…,an) and d as SORTED(b1,b2…,bn). It can be proved that this reaches the maximum value: if not so, then  There must be some pair (i,j) such that ci<cj,di>dj. Since min(ci,di)⋅min(cj,dj)=ci⋅min(cj,dj)≤ci⋅min(cj,di)=min(ci,dj)⋅min(cj,di), we can swap di and dj, and the product does not decrease. Consider the modification, which is a single element increment by 1. Without loss of generality, let cx be increased by 1 (and the processing method for d is the same). If cx<cx+1, then after the modification cx≤cx+1, which would be fine. Otherwise, we can modify the array c in the form of a single round of "Insertion Sort": We continuously swap cx and cx+1, x←x+1, until cx<cx+1 (or x=n), and thus the array remains sorted after the increment.In fact, the swap operation does nothing in the above process: in these cases, cx=cx+1 holds! So we can just set x′ as the maximum k such that ck=cx, and then increase cx′ by 1, after which c is still sorted. The k can be found with a naive binary search, so the problem is solved in O(nlogn+q(logp+logn)) per test case.
#include <bits/stdc++.h>
 
constexpr int MOD = 998244353;
int qpow(int a, int x = MOD - 2) {
	int res = 1;
	for (; x; x >>= 1, a = 1ll * a * a % MOD) if (x & 1) res = 1ll * res * a % MOD;
	return res;
}
 
#define MAXN 200001
int a[MAXN], b[MAXN], c[MAXN], d[MAXN];
void solve() {
	int n, q, res = 1; std::cin >> n >> q;
	for (int i = 1; i <= n; ++i) std::cin >> a[i], c[i] = a[i];
	for (int i = 1; i <= n; ++i) std::cin >> b[i], d[i] = b[i];
	std::sort(c + 1, c + n + 1), std::sort(d + 1, d + n + 1);
	for (int i = 1; i <= n; ++i) res = 1ll * res * std::min(c[i], d[i]) % MOD;
	std::cout << res << " \n"[q == 0];
	for (int i = 1, op, x; i <= q; ++i) {
		std::cin >> op >> x;
		if (op == 1) {
			int p = std::upper_bound(c + 1, c + n + 1, a[x]) - c - 1;
			if (c[p] < d[p]) res = 1ll * res * qpow(c[p]) % MOD * (c[p] + 1) % MOD;
			++a[x], ++c[p];
		} else {
			int p = std::upper_bound(d + 1, d + n + 1, b[x]) - d - 1;
			if (d[p] < c[p]) res = 1ll * res * qpow(d[p]) % MOD * (d[p] + 1) % MOD;
			++b[x], ++d[p];
		}
		std::cout << res << " \n"[i == q];
	}
}
 
int main() {
	std::ios::sync_with_stdio(false);
	std::cin.tie(nullptr), std::cout.tie(nullptr);
	int t; std::cin >> t; while (t--) solve(); return 0;
}
 Amazing problem: 

    


203



 Good problem: 

    


92



 Average problem: 

    


54



 Bad problem: 

    


55



 Didn't solve: 

    


33



 
Suppose somebody wins. In which round does he or she win?
A player can always undo what his opponent did in the previous turn.
Can you find the necessary and sufficient condition for (p,q) to be a caterpillar that makes Aron win?
Denote Nora's first move as round 1, Aron's first move as round 2, and so on. Suppose a player does not have a winning strategy in the k-th round, but he or she has a winning strategy in the (k+2)-th round — it can be shown impossible because the other player can always withdraw the last move of another player so that the status is the same as it was before the k-th round.Therefore: if a player wins in the k-th round, we claim that k≤2.Given p,q, let's determine who will eventually win the game.  If both p and q are leaves, the result is a tie. If p is a leaf while q is not, Nora wins. If q is a leaf while p is not, Aron wins. If neither p nor q is a leaf:    Can k=1? Nora wins if and only if p is adjacent to a leaf. Can k=2? Aron wins if and only if p is not adjacent to a leaf, and f(p,q) is adjacent to a leaf. Otherwise, the result is a tie.  The counting part can also be solved easily in O(n). Denote c as the number of leaves. The initial answer would be c⋅(n−c), considering the third case. For the fourth case, we can enumerate m=f(p,q), which is adjacent to at least one leaf. Given m, q must be a non-leaf neighbor of m, and let the number of different q be k. For each of the potential p, which is a non-leaf node whose neighbors are all non-leaf nodes too, it is computed exactly k−1 times for all the k candidates of q (since m must be on the simple path from p to q), so the extra contributions are easy to calculate. (If you do not think that much, you can use some simple DP, which I will not elaborate here.)
#include <bits/stdc++.h>

#define MAXN 200001
std::vector<int> g[MAXN];
inline int deg(int u) { return g[u].size(); }

int d[MAXN];
void solve() {
	int n; std::cin >> n; long long ans = 0;
	for (int i = 1, u, v; i < n; ++i) {
		std::cin >> u >> v;
		g[u].push_back(v), g[v].push_back(u);
	}
	int c1 = 0, c2 = 0;
	for (int i = 1; i <= n; ++i) c1 += (deg(i) == 1);
	ans += 1ll * c1 * (n - c1);
	for (int i = 1; i <= n; ++i) if (deg(i) > 1) {
		for (int v : g[i]) d[i] += (deg(v) > 1);
		c2 += (d[i] == deg(i));
	}
	for (int m = 1; m <= n; ++m) if (deg(m) > 1 && d[m] != deg(m)) 
		ans += 1ll * c2 * (d[m] - 1);
	std::cout << ans << '\n';
	for (int i = 1; i <= n; ++i) 
		(std::vector<int>()).swap(g[i]), d[i] = 0;
}

int main() {
	std::ios::sync_with_stdio(false);
	std::cin.tie(nullptr), std::cout.tie(nullptr);
	int t; std::cin >> t; while (t--) solve(); return 0;
}
 Amazing problem: 

    


38



 Good problem: 

    


129



 Average problem: 

    


38



 Bad problem: 

    


78



 Didn't solve: 

    


23



 
What are we going to fill into the matrix? In other words, is there any relationship between the filed numbers?
Try to come up with a naive DP solution that works in large time complexity, such as O(nk2).
For many different numbers between two consecutive rows, however, the transition is almost the same.
If x′=max(a,x+b) and x″=max(c,x′+d), then x″=max(max(a+d,c),x+b+d).
Conclusion: For each row, an optimal solution exists, such that the newly filled-in numbers are the same.   Proof: Consider fixing the rows i−1 and i+1, and observe all the newly filled-in numbers at row i. Then a new number u brings a contribution of cu,i−1+cu,i+1, and it is clear that there exists a scheme that takes the maximum value such that all the u filled in are equal. Adjusting for each row leads to the above conclusion. Consider dp. Let fi,j denote the maximum contribution that can be achieved between the first i rows (ignoring the initial contribution) when the empty elements in the i-th row are filled with j. Let ci be the number of −1 numbers in the i-th row, and di,j denote the number of elements j in the i-th row initially.The transfer should be as follows: fi,j=max(max1≤w≤k(fi−1,w+ci⋅di−1,w+ci−1⋅di−1,j),fi−1,j+(di,j+ci)⋅(di−1,j+ci−1)−di,jdi−1,j).In addition to being able to optimize the above transition to O(nk), the present problem in a matrix has a good property. Specifically, for the same i, there are only O(m) values of j such that di,j≠0!If di,j=0 and di−1,j=0, the original transfer can be viewed as fi,j=max(max1≤w≤k(fi−1,w),fi−1,j+ci⋅ci−1).This can be seen as a global modification in the form of x←max(a,x+b). The tags are composable in O(1); Otherwise, we can brutely update the new dpj for O(m) positions.Therefore, this problem is solved in O(nm). We decided to let every segment tree solution pass comfortably, so that we set small constraints and large TL.Bonus Hint for implementation: always use max(a,dpj+b) to get the real value.
#include <bits/stdc++.h>
 
namespace FastIO {
	char buf[1 << 21], *p1 = buf, *p2 = buf;
#define getchar() (p1 == p2 && (p1 = buf, p2 = (p1 + fread(buf, 1, 1 << 21, stdin))) == p1 ? EOF : *p1++)
	template <typename T> inline T read() { T x = 0, w = 0; char ch = getchar(); while (ch < '0' || ch > '9') w |= (ch == '-'), ch = getchar(); while ('0' <= ch && ch <= '9') x = x * 10 + (ch ^ '0'), ch = getchar(); return w ? -x : x; }
	template <typename T> inline void write(T x) { if (!x) return; write<T>(x / 10), putchar((x % 10) ^ '0'); }
	template <typename T> inline void print(T x) { if (x > 0) write<T>(x); else if (x < 0) putchar('-'), write<T>(-x); else putchar('0'); }
	template <typename T> inline void print(T x, char en) { print<T>(x), putchar(en); }
#undef getchar
}; using namespace FastIO;
 
using ll = long long;
void solve() {
	int n = read<int>(), m = read<int>(), k = read<int>(); ll cntP = 0, cntQ = 0;
	std::vector<int> vep(m), veq(m), cntp(k + 1), cntq(k + 1), vis(k + 1);
	std::vector<ll> dp(k + 1); ll a = 0, b = 0, v = 0, ext = 0; // max(a, x + b).
	cntp[0] = cntq[0] = m;
	auto get = [&](int x) -> int { return (~x) ? x : 0; };
	auto read_q = [&]() -> void {
		for (int i = 0; i < m; ++i) --cntq[get(veq[i])];
		for (int i = 0; i < m; ++i) ++cntq[get(veq[i] = read<int>())];
		cntQ = cntq[0];
	};
	auto roll = [&]() -> void { std::swap(vep, veq), std::swap(cntp, cntq), std::swap(cntP, cntQ); };
	auto chkmax = [&](ll &a, ll b) -> void { a = std::max(a, b); };
	read_q(), roll();
	for (int i = 2; i <= n; ++i) {
		read_q();
		ll max_dp = std::max(a, v + b);
		for (int k : vep) if (~k) chkmax(max_dp, std::max(a, dp[k] + b) + cntP * cntq[k]);
		for (int k : veq) if (~k) chkmax(max_dp, std::max(a, dp[k] + b) + cntP * cntq[k]);
		for (int k : vep) if ((~k) && vis[k] != i) {
			vis[k] = i, ext += 1ll * cntp[k] * cntq[k];
			dp[k] = std::max(a, dp[k] + b) + cntP * cntq[k] + cntQ * cntp[k] - b;
			chkmax(dp[k], max_dp + cntp[k] * cntQ - b - cntP * cntQ);
			chkmax(v, dp[k]);
		} for (int k : veq) if ((~k) && vis[k] != i) {
			vis[k] = i;
			dp[k] = std::max(a, dp[k] + b) + cntP * cntq[k] + cntQ * cntp[k] - b;
			chkmax(dp[k], max_dp + cntp[k] * cntQ - b - cntP * cntQ);
			chkmax(v, dp[k]);
		} a = std::max(max_dp, a + cntP * cntQ), b += cntP * cntQ;
		roll();
	} print<ll>(std::max(a, v + b) + ext, '\n');
}
 
int main() { int T = read<int>(); while (T--) solve(); return 0; }
 Amazing problem: 

    


54



 Good problem: 

    


54



 Average problem: 

    


5



 Bad problem: 

    


17



 Didn't solve: 

    


49



 
(If we do not have to be deterministic) We do not need any hard string algorithm.
In what cases won't greed work? Why? 
Is your brute forces actually faster (maybe you can explain it by harmonic series)?
Let's call the prefix s1 the short string and the suffix s2 the long string. If |s1|>|s2|, swapping the order doesn't affect the answer.Consider a greedy approach. We first match a few short strings until we can't match anymore. If we can't match, we try discarding a few short strings and placing one long string. We enumerate how many short strings to discard. Find the first position where we can place a long string. We call this placing once a "matching process." The starting position of each "matching process" is the next position after the previous "matching process."However, this approach has a flaw. Below, I will explain the situation where this flaw occurs.  Why it has a flawIt's not difficult to view the long string as several short strings concatenated with a "tail" at the end.Why only find the first position? Why wouldn't it be better to backtrack and discard a few more s1's before placing the long string?The diagram above is an example. The red line indicates the cutoff position for matching s1. The three orange boxes represent the possible choices for attempting to match the long string.The last one is invalid, so skip it. Replace it with the "The first valid position to place the long string." box. This box is correct.The difference between choosing the second box and the first box is that when we end the matching and proceed to the next round, the content we need to match is that a suffix of s1 has been moved to the beginning of $s_1$。As shown in the diagram.The alignment results in the following diagram.In the diagram, the case where |pre|>|suf| is shown. The other case follows similarly.pre+suf=suf+pre, and as can be seen from the diagram, here pre+suf needs to be "misaligned but equal." This means that s1 must have a periodic cycle, and the "tail" must also be able to be formed through this cycle. Additionally, the |s1| characters at the beginning of s2 must still be able to be formed by the periodic cycle.In summary, it is equivalent to s1 and s2 having a common periodic cycle.In other words, backtracking twice can lead to a solution, but backtracking once may not always work. It is necessary for s1 and s2 to have a common periodic cycle.Having a common periodic cycle is too specific. First, the common periodic cycle of these two strings must indeed be the periodic cycle of string s. By finding this cycle in advance, it essentially becomes a problem of solving an equation. Let a=|s1| and b=|s2|, and we need to check whether there are non-negative integer solutions x and y that satisfy the equation xa+yb=|s|.This equation-solving part is just for show. We enumerate y, and for each value of y, we compute the enumeration O(mn) times. At most, we do this n times, so the overall complexity is O(m).If we directly implement this, the worst-case complexity is related to the harmonic series. Consider a case like s1=a,s2=aaaaaaaab, and t=aaaaaaaaaaaaaaaaaaaaaaaaab. In this case, we would need to attempt O(m|s1|) steps to finish matching the short string. Each time we backtrack, it requires at most O(m|s2|) steps, and each of those takes O(|s2||s1|).
It's not difficult to view the long string as several short strings concatenated with a "tail" at the end.Why only find the first position? Why wouldn't it be better to backtrack and discard a few more s1's before placing the long string?The diagram above is an example. The red line indicates the cutoff position for matching s1. The three orange boxes represent the possible choices for attempting to match the long string.The last one is invalid, so skip it. Replace it with the "The first valid position to place the long string." box. This box is correct.The difference between choosing the second box and the first box is that when we end the matching and proceed to the next round, the content we need to match is that a suffix of s1 has been moved to the beginning of $s_1$。As shown in the diagram.The alignment results in the following diagram.In the diagram, the case where |pre|>|suf| is shown. The other case follows similarly.pre+suf=suf+pre, and as can be seen from the diagram, here pre+suf needs to be "misaligned but equal." This means that s1 must have a periodic cycle, and the "tail" must also be able to be formed through this cycle. Additionally, the |s1| characters at the beginning of s2 must still be able to be formed by the periodic cycle.
Thanks to orzdevinwang and crazy_sea for pointing out it!Yes, this problem can indeed be solved in linear time.First, let the prefix of the long string contain c short strings. Then, the first "valid position to place the long string" we backtrack to can only be obtained by either backtracking c short strings or c+1 short strings.This is easy to understand. Backtracking c short strings means considering the prefix of the long string, then adding the "tail" of the long string. Backtracking c+1 short strings only happens when the "tail" part of the long string is a prefix of the short string. For example, the hack in the CF comment section:https://codeforces.com/blog/entry/136455?#comment-1234262 1
8 8
abaabaab
abaababaThe correct output should be: 0010000When k=3, s1=aba, s2=abaab, we first filled in 2 short strings, but if we backtrack c=1 short string, it will be judged as unsolvable. This is how the error in std occurs. This situation only arises when the "tail" part of s2 is a prefix of s1.So, each time we calculate, we first use binary search to find this c, and the complexity is O(n∑i=1log(ni))=O(n). After that, backtracking only requires two checks. The backtracking process becomes linear.Next, let's accelerate the process of filling in short strings. The hack for brute-force filling has already been given above. If we directly use the method that everyone initially thought was correct, which is the "binary search for the number of short string occurrences" method, Then it can be accelerated by this set of hacks to achieve a log complexity. 1
2 5000000
ab
abababab....ababababcrazy_sea points out an alternative solution.Similar to block division, let B=n|s1|. We first try to match B occurrences of s1, meaning that each match can move forward by n positions. After that, the remaining part will not exceed B occurrences, and we binary search to find how many are left. For the part where we moved forward by B occurrences, we can backtrack at most once, and then the binary search will take O(logB). Each time, we can at least fill in |s2| occurrences. The time complexity for calculating the answer becomes O(m|s2|logB), and the total complexity, due to O(n∑i=1log(ni))=O(n), is O(m).Thus, the problem is solved in linear time.
During testing, we found that jqdai0815's solution is actually more violent than we thought (We have also received something similar in contest).He specially handled the case in which X and T share a common shortest period, and for the rest i, he just used two queues to optimize the BFS progress (actually changing it to std::priority_queue<int> or similar also works), and it passed just seeming to have a larger constant time complexity.I'm curious if anybody can (hack it or) prove that it is correct. Thanks in advance!
This is written by Caylex. #include <bits/stdc++.h>
using namespace std;
template <int P>
class mod_int
{
    using Z = mod_int;

private:
    static int mo(int x) { return x < 0 ? x + P : x; }

public:
    int x;
    int val() const { return x; }
    mod_int() : x(0) {}
    template <class T>
    mod_int(const T &x_) : x(x_ >= 0 && x_ < P ? static_cast<int>(x_) : mo(static_cast<int>(x_ % P))) {}
    bool operator==(const Z &rhs) const { return x == rhs.x; }
    bool operator!=(const Z &rhs) const { return x != rhs.x; }
    Z operator-() const { return Z(x ? P - x : 0); }
    Z pow(long long k) const
    {
        Z res = 1, t = *this;
        while (k)
        {
            if (k & 1)
                res *= t;
            if (k >>= 1)
                t *= t;
        }
        return res;
    }
    Z &operator++()
    {
        x < P - 1 ? ++x : x = 0;
        return *this;
    }
    Z &operator--()
    {
        x ? --x : x = P - 1;
        return *this;
    }
    Z operator++(int)
    {
        Z ret = x;
        x < P - 1 ? ++x : x = 0;
        return ret;
    }
    Z operator--(int)
    {
        Z ret = x;
        x ? --x : x = P - 1;
        return ret;
    }
    Z inv() const { return pow(P - 2); }
    Z &operator+=(const Z &rhs)
    {
        (x += rhs.x) >= P && (x -= P);
        return *this;
    }
    Z &operator-=(const Z &rhs)
    {
        (x -= rhs.x) < 0 && (x += P);
        return *this;
    }
    Z operator-() { return -x; }
    Z &operator*=(const Z &rhs)
    {
        x = 1ULL * x * rhs.x % P;
        return *this;
    }
    Z &operator/=(const Z &rhs) { return *this *= rhs.inv(); }
#define setO(T, o)                                  \
    friend T operator o(const Z &lhs, const Z &rhs) \
    {                                               \
        Z res = lhs;                                \
        return res o## = rhs;                       \
    }
    setO(Z, +) setO(Z, -) setO(Z, *) setO(Z, /)
#undef setO
        friend istream &
        operator>>(istream &is, mod_int &x)
    {
        long long tmp;
        is >> tmp;
        x = tmp;
        return is;
    }
    friend ostream &operator<<(ostream &os, const mod_int &x)
    {
        os << x.val();
        return os;
    }
};
typedef long long ll;
typedef unsigned long long ull;
mt19937 rnd(chrono::system_clock::now().time_since_epoch().count());
constexpr int p = 993244853;
using Hash = mod_int<p>;
// using Hash = ull;
const Hash base = rnd() % 20091119 + 30;
string s, t;
Hash st;
int mnlen;
Hash S[5000020];
Hash T[5000020];
Hash pw[5000020];
inline Hash SUM(const int l, const int r, const Hash *s) { return s[r] - s[l - 1] * pw[r - l + 1]; }
int n, m;
inline bool check(const int l, const int r, const Hash x, const int len, const Hash *S) { return r - l + 1 >= len && SUM(l, l + len - 1, S) == x && SUM(l, r - len, S) == SUM(l + len, r, S); }
inline bool calc(const int L1, const int R1, const int L2, const int R2, const int l1, const int l2)
{
    if (mnlen && check(L1, R1, st, mnlen, S) && check(L2, R2, st, mnlen, S))
    {
        if (check(1, m, st, mnlen, T))
        {
            for (int i = 0; i <= m; i += l2)
            {
                if (!((m - i) % l1))
                    return 1;
            }
            return 0;
        }
    }
    const Hash s1 = SUM(L1, R1, S);
    const Hash s2 = SUM(L2, R2, S);
    // int l = 1, r = l2 / l1, okcnt = 0;
    // while (l <= r)
    // {
    //     int mid = l + r >> 1;
    //     if (check(L2, L2 + mid * l1 - 1, s1, l1, S))
    //         l = (okcnt = mid) + 1;
    //     else
    //         r = mid - 1;
    // }
    int ed = 0;
    while (ed <= m)
    {
        int L = 1, R = (m - ed) / l1, cnt = 0;
        while (L <= R)
        {
            int mid = L + R >> 1;
            if (check(ed + 1, ed + mid * l1, s1, l1, T))
                L = (cnt = mid) + 1;
            else
                R = mid - 1;
        }
        if (ed + cnt * l1 + 1 > m)
            return 1;
        // bool found = 0;
        // int st = ed + (cnt - okcnt) * l1 + 1;
        // if (st > ed && st + l2 - 1 <= m && SUM(st, st + l2 - 1, T) == s2)
        // {
        //     ed = st + l2 - 1;
        //     found = 1;
        // }
        // if (!found)
        //     return 0;
        bool found = 0;
        for (int st = ed + cnt * l1 + 1; st > ed; st -= l1)
        {
            if (st + l2 - 1 <= m && SUM(st, st + l2 - 1, T) == s2)
            {
                ed = st + l2 - 1;
                found = 1;
                break;
            }
        }
        if (!found)
            return 0;
    }
    return 1;
}
void solve()
{
    // build();
    mnlen = 0;
    cin >> n >> m >> s >> t;
    s = ' ' + s;
    t = ' ' + t;
    for (int i = 1; i <= n; i++)
        S[i] = S[i - 1] * base + Hash(s[i] - 'a' + 1);
    for (int i = 1; i <= m; i++)
        T[i] = T[i - 1] * base + Hash(t[i] - 'a' + 1);
    for (int i = 1; i <= n; i++)
    {
        if (n % i == 0 && check(1, n, S[i], i, S))
        {
            st = S[i];
            mnlen = i;
            break;
        }
    }
    for (int i = 1; i < n; i++)
        putchar('0' ^ (i <= n - i ? calc(1, i, i + 1, n, i, n - i) : calc(i + 1, n, 1, i, n - i, i)));
    putchar('\n');
}
int main()
{
    pw[0] = Hash(1);
    for (int i = 1; i <= 5'000'000; i++)
        pw[i] = pw[i - 1] * base;
    ios::sync_with_stdio(0), cin.tie(0), cout.tie(0);
    int t;
    cin >> t;
    while (t--)
        solve();
    return 0;
}
This is written by Caylex. #include <bits/stdc++.h>
using namespace std;
template <int P>
class mod_int
{
    using Z = mod_int;

private:
    static int mo(int x) { return x < 0 ? x + P : x; }

public:
    int x;
    int val() const { return x; }
    mod_int() : x(0) {}
    template <class T>
    mod_int(const T &x_) : x(x_ >= 0 && x_ < P ? static_cast<int>(x_) : mo(static_cast<int>(x_ % P))) {}
    bool operator==(const Z &rhs) const { return x == rhs.x; }
    bool operator!=(const Z &rhs) const { return x != rhs.x; }
    Z operator-() const { return Z(x ? P - x : 0); }
    Z pow(long long k) const
    {
        Z res = 1, t = *this;
        while (k)
        {
            if (k & 1)
                res *= t;
            if (k >>= 1)
                t *= t;
        }
        return res;
    }
    Z &operator++()
    {
        x < P - 1 ? ++x : x = 0;
        return *this;
    }
    Z &operator--()
    {
        x ? --x : x = P - 1;
        return *this;
    }
    Z operator++(int)
    {
        Z ret = x;
        x < P - 1 ? ++x : x = 0;
        return ret;
    }
    Z operator--(int)
    {
        Z ret = x;
        x ? --x : x = P - 1;
        return ret;
    }
    Z inv() const { return pow(P - 2); }
    Z &operator+=(const Z &rhs)
    {
        (x += rhs.x) >= P && (x -= P);
        return *this;
    }
    Z &operator-=(const Z &rhs)
    {
        (x -= rhs.x) < 0 && (x += P);
        return *this;
    }
    Z operator-() { return -x; }
    Z &operator*=(const Z &rhs)
    {
        x = 1ULL * x * rhs.x % P;
        return *this;
    }
    Z &operator/=(const Z &rhs) { return *this *= rhs.inv(); }
#define setO(T, o)                                  \
    friend T operator o(const Z &lhs, const Z &rhs) \
    {                                               \
        Z res = lhs;                                \
        return res o## = rhs;                       \
    }
    setO(Z, +) setO(Z, -) setO(Z, *) setO(Z, /)
#undef setO
        friend istream &
        operator>>(istream &is, mod_int &x)
    {
        long long tmp;
        is >> tmp;
        x = tmp;
        return is;
    }
    friend ostream &operator<<(ostream &os, const mod_int &x)
    {
        os << x.val();
        return os;
    }
};
typedef long long ll;
typedef unsigned long long ull;
mt19937 rnd(chrono::system_clock::now().time_since_epoch().count());
constexpr int p = 993244853;
using Hash = mod_int<p>;
// using Hash = ull;
const Hash base = rnd() % 20091119 + 30;
string s, t;
Hash st;
int mnlen;
Hash S[5000020];
Hash T[5000020];
Hash pw[5000020];
// int doit;
inline Hash SUM(const int l, const int r, const Hash *s) { return s[r] - s[l - 1] * pw[r - l + 1]; }
int n, m;
inline bool check(const int l, const int r, const Hash x, const int len, const Hash *S)
{
    // doit++;
    return r - l + 1 >= len && SUM(l, l + len - 1, S) == x && SUM(l, r - len, S) == SUM(l + len, r, S);
}
inline bool calc(const int L1, const int R1, const int L2, const int R2, const int l1, const int l2)
{
    if (mnlen && check(L1, R1, st, mnlen, S) && check(L2, R2, st, mnlen, S))
    {
        if (check(1, m, st, mnlen, T))
        {
            for (int i = 0; i <= m; i += l2)
            {
                if (!((m - i) % l1))
                    return 1;
            }
            return 0;
        }
    }
    const Hash s1 = SUM(L1, R1, S);
    const Hash s2 = SUM(L2, R2, S);
    int l = 1, r = l2 / l1, okcnt = 0;
    while (l <= r)
    {
        int mid = l + r >> 1;
        if (check(L2, L2 + mid * l1 - 1, s1, l1, S))
            l = (okcnt = mid) + 1;
        else
            r = mid - 1;
    }
    const int tt = (n / l1);
    int ed = 0;
    while (ed <= m)
    {
        int L = 1, R = (m - ed) / l1, cnt = 0;
        int tcnt = 0;
        while (tcnt + tt <= R && check(ed + 1, ed + (tcnt + tt) * l1, s1, l1, T))
            tcnt += tt;
        L = max(L, tcnt);
        R = min(R, tcnt + tt - 1);
        // cerr << ed << ' ' << L << ' ' << R << '\n';
        while (L <= R)
        {
            int mid = L + R >> 1;
            if (check(ed + 1, ed + mid * l1, s1, l1, T))
                L = (cnt = mid) + 1;
            else
                R = mid - 1;
        }
        if (ed + cnt * l1 + 1 > m)
            return 1;
        // int st = ed + (cnt - okcnt) * l1 + 1;
        // if (st > ed && st + l2 - 1 <= m && SUM(st, st + l2 - 1, T) == s2)
        // {
        //     ed = st + l2 - 1;
        //     continue;
        // }
        // return 0;
        bool found = 0;
        for (int st = ed + (cnt - okcnt) * l1 + 1, cnt = 1; cnt <= 2 && st > ed; st -= l1, cnt++)
        {
            if (st + l2 - 1 <= m && SUM(st, st + l2 - 1, T) == s2)
            {
                ed = st + l2 - 1;
                found = 1;
                break;
            }
        }
        if (!found)
            return 0;
    }
    return 1;
}
void solve()
{
    // build();
    mnlen = 0;
    cin >> n >> m >> s >> t;
    s = ' ' + s;
    t = ' ' + t;
    for (int i = 1; i <= n; i++)
        S[i] = S[i - 1] * base + Hash(s[i] - 'a' + 1);
    for (int i = 1; i <= m; i++)
        T[i] = T[i - 1] * base + Hash(t[i] - 'a' + 1);
    for (int i = 1; i <= n; i++)
    {
        if (n % i == 0 && check(1, n, S[i], i, S))
        {
            st = S[i];
            mnlen = i;
            break;
        }
    }
    for (int i = 1; i < n; i++)
        putchar('0' ^ (i <= n - i ? calc(1, i, i + 1, n, i, n - i) : calc(i + 1, n, 1, i, n - i, i)));
    putchar('\n');
    // cerr << doit << '\n';
}
int main()
{
    // freopen("out.txt", "r", stdin);
    pw[0] = Hash(1);
    for (int i = 1; i <= 5'000'000; i++)
        pw[i] = pw[i - 1] * base;
    ios::sync_with_stdio(0), cin.tie(0), cout.tie(0);
    int t;
    cin >> t;
    while (t--)
        solve();
    // cerr << fixed << setprecision(10) << 1.0 * clock() / CLOCKS_PER_SEC << '\n';
    return 0;
}
 Amazing problem: 

    


13



 Good problem: 

    


6



 Average problem: 

    


2



 Bad problem: 

    


8



 Didn't solve: 

    


34



 
What if w=2? Is it optimal to increase n∑i=0[ai≠ai+1] (suppose a0=an+1=2)?
If w≥3, what's the answer to the first question?
If ai=ai+1, after the operation we can obtain ai−1=ai or ai+1=ai+2 (and possibly, both).
Try to think of the whole process reversedly. If w≥3, 1≤ai≤w−1, can you solve the problem?
How many extra operations are required for each 1≤i≤n if ai=w, in the above scheme you use for ai≤w−1?
Read the Hints.  w=2 After any operation, k=n∑i=0[ai≠ai+1] won't decrease (suppose a0=an+1=2). For a fixed k, the maximal ∑ai=2n−12k and can be reached by each time turning a [2,1,1] into [2,2,1] (or symmetrically, [1,1,2]→[1,2,2].  w≥3  No initial operations can be conducted, or min(ai)=w  This case is trivial.  w≥3  Some initial operations can be conducted  We claim that the answer to the first question is nw−1. For the second question, let's study some rather easier cases below.  w≥3  Some initial operations can be conducted      ai≠w   We pretend that the final sequence is [w,w,…,w,(w−1),w,w,…,w], then since (ai,ai+1) must be different after the operation, the last operation can only occur on [w,(w−1)] (or [(w−1),w]). And since initially ai≠w, each position must have been operated on at least once.This gives us states such as [w,…,w,x,x,w,…,w], [w,…,w,y,y,x,w,…,w], etc. To the leftmost positions, we get a1=a2 (essentially based on Hint 3). Also, we get ...... an−1=an? This is if and only if the initial [w,(w−1)] is neither at the beginning nor at the end. If the initial [w,(w−1)] is at the beginning, we only need an−1=an to achieve the goal, and symmetrically the same. Less is more. Obviously, we only need to satisfy either a1=a2 or an−1=an, and then use n−1 more operations to reach the target situation.How do we get to a1=a2 (symmetrically the same)? Based on Hint 3, we find the smallest x that satisfies ax=ax+1, and then follow the example above, again using x−1 operations to conduct the equality sign to a1=a2. Why is it optimal?Lemma 1: We can never choose an index ai=w, fix it (i.e. avoid changing ai in the following operations), and then use some operations to reach ∑ai=nw−1 unless [a1,…,ai]=[w,…,w] or [ai,…,an]=[w,…,w]. Proof: If not so, the array is split into two parts: [a1,…,ai−1] and [ai+1,…,an]. We have: after some operations, the maximum ∑ai we can get for each part are respectively (i−1)w−1,(n−i)w−1, and add them up and we get nw−2, which is less than nw−1, so it's never optimal. Lemma 2: Look at the final array a, consisting of n−1 element w and 1 element (w−1). Obtain an array a′ by keeping the elements with the value of w. Denote ti as the last round in which a′i was changed to w (and then become fixed). Then, there exists some k such that t1<t2<⋯<tk>tk+1>⋯>tn−1. Proof: This follows from Lemma 1.According to Lemma 2, we can see the pattern that we used above is optimal.  w≥3  Some initial operations can be conducted      a1≠w,an≠w   Basically, the idea remains to reach a1=a2 in the same way first (symmetrically the same), and then to extend to all positions. However, at this point, in the second stage, some problems may arise as follows:  […ak_ ak+1 w ak+3…] […ak+1 ak+1_ w ak+3…] […s w w_ ak+3…] […s s_ t ak+3…] […w t t_ ak+3…] […w w ak+3 ak+3_…] In which s,t,w are three distinct integers in the range [1,w] (This also explains why we need to specially deal with the w=2 case). Since we cannot fix ak+2=w at the beginning (refer to the "Why is it optimal?" spoiler above), we have to first change ak+2 into something not equal to w, and that cost at least 2 extra operations, which is shown here.Do we always need 2 extra operations? One may note that if ai=ai+1=w, in which the two elements are both in the way of expansion, we can only use 1 operation to vanish their existence. Formally, if there is a maximum continuous subsegment of w in the way of expansion, let its length be L, then we will spend ⌈L2⌉+[L=1] extra operations. What is 'in the way of expansion'?Suppose in the first stage, we pick ax=ax+1 and keep operating on it until a1=a2. Then after it, ∀3≤k≤x+1, ak can be an arbitrary number which is different from the initial ak−1, thus we can always force it to be ≠w.In the above case, only elements [ax+2,…,an] are considered 'in the way of expansion', and symmetrically the same.  w≥3  Some initial operations can be conducted      No additional constraints   It may come to you that if a1=w, we can ignore a1; if a1=a2=w, we can ignore a2. Symmetrically the same. And so on... Then we boil the problem down to the case above.It is correct unless in some rare cases when we ignore all the prefixes and suffixes, there will be no remaining ai=ai+1; or if we pick any pair ai=ai+1 as the starting pair in the remaining array, it is not optimal compared to picking an ak=ak+1=w(ak+2≠w) (symmetrically the same). So, we have to special handle the deleted prefix and suffix, once it has a length greater than 2.In summary, the problem can be solved in O(n).
Lemma 1: We can never choose an index ai=w, fix it (i.e. avoid changing ai in the following operations), and then use some operations to reach ∑ai=nw−1 unless [a1,…,ai]=[w,…,w] or [ai,…,an]=[w,…,w]. Proof: If not so, the array is split into two parts: [a1,…,ai−1] and [ai+1,…,an]. We have: after some operations, the maximum ∑ai we can get for each part are respectively (i−1)w−1,(n−i)w−1, and add them up and we get nw−2, which is less than nw−1, so it's never optimal. Lemma 2: Look at the final array a, consisting of n−1 element w and 1 element (w−1). Obtain an array a′ by keeping the elements with the value of w. Denote ti as the last round in which a′i was changed to w (and then become fixed). Then, there exists some k such that t1<t2<⋯<tk>tk+1>⋯>tn−1. Proof: This follows from Lemma 1.According to Lemma 2, we can see the pattern that we used above is optimal.
Suppose in the first stage, we pick ax=ax+1 and keep operating on it until a1=a2. Then after it, ∀3≤k≤x+1, ak can be an arbitrary number which is different from the initial ak−1, thus we can always force it to be ≠w.In the above case, only elements [ax+2,…,an] are considered 'in the way of expansion', and symmetrically the same.
#include <bits/stdc++.h>

#define MAXN 200005
int a[MAXN];

void solve() {
	int N, w; scanf("%d%d", &N, &w);
	for (int i = 1; i <= N; ++i) scanf("%d", a + i);
	if (N == 1) return (void)printf("%d 0\n", a[1]);
	if (*std::min_element(a + 1, a + N + 1) == w)
		return (void)printf("%lld 0\n", 1ll * w * N);
	if (w == 2) {
		int ans = N * 2, pans = 0;
		for (int i = 1, j = 1; i <= N; i = ++j) if (a[i] == 1) {
			--ans; while (j < N && a[j + 1] == 1) ++j; pans += j - i;
		}
		return (void)printf("%d %d\n", ans, pans);
	}
	bool flag = true;
	for (int i = 1; i < N; ++i) if (a[i] == a[i + 1]) flag = false;
	if (flag) return (void)printf("%lld 0\n", std::accumulate(a + 1, a + N + 1, 0ll));
	printf("%lld ", 1ll * w * N - 1);
	if (std::accumulate(a + 1, a + N + 1, 0ll) == 1ll * w * N - 1) return (void)puts("0");
	int ans = 0x3f3f3f3f, l = (a[1] == w ? 2 : 1), r = (a[N] == w ? N - 1 : N);
	if ((a[1] == w && a[2] == w) || (a[N] == w && a[N - 1] == w)) {
		int Lw = 0, Rw = N + 1;
		while (a[Lw + 1] == w) ++Lw; while (a[Rw - 1] == w) --Rw;
		int pans = Rw - Lw;
		for (int i = Lw + 1, j = i; i < Rw; i = ++j) if (a[i] == w) {
			while (j + 1 < Rw && a[j + 1] == w) ++j;
			pans += (i == j ? 2 : ((j - i) >> 1) + 1);
		}
		ans = pans, l = Lw + 1, r = Rw - 1;
	}
	for (int d = 0; d < 2; std::reverse(a + l, a + r + 1), ++d) 
		for (int i = l - 1, pre = 0, len = 0; i + 2 <= r; ) {
			if (a[i + 1] == a[i + 2]) 
				ans = std::min(r - (i + 1) + r - l - 1 + pre - ((len == 1) && i + 2 < r && a[i + 3] != w ? 1 : 0), ans);
			++i; if (a[i] == w) ++len, pre += (len == 1 ? 2 : len == 2 ? -1 : (len & 1)); else len = 0;
	}
	printf("%d\n", ans);
}

int main() { int T; scanf("%d", &T); while (T--) solve(); return 0; }
 Amazing problem: 

    


4



 Good problem: 

    


2



 Average problem: 

    


1



 Bad problem: 

    


5



 Didn't solve: 

    


25



 
What is the minimized LIS?
How do you prove that it is an achievable lower bound?
Go for a brute DP first.
We claim that the minimized LIS is ∑ai. Let p be ∑ai.Since it is required that LIS(b)=p while ∑bi=p, we point out that it is equivalent to each of the prefix sums of the sequence being between [0,p].  Sufficiency: ∀X∈[0,p],Y∈[0,p], X−Y≤p. Also, we can pick X=p,Y=0, so it can only be =p. Necessity: disproof. If a prefix sum is <0, then choose the whole array except for this prefix; if a prefix sum is >p, then choose this prefix. Both derive a contradiction of the LIS being greater than p. Consider dp. Let fi,j denote, after considering the first i numbers, the minimum extra sequence length (i.e. the actual length minus i), when the current prefix sum is j. The initial states are f0,j=[j≠0]. The transfer is simple too:  fi,j=min0≤k+ai≤p(fi−1,k+[k+ai≠j])It is possible to optimize the transfer to O(np), since for each j, the contribution from at most one k is special (+0). We can calculate the prefix and suffix min for fi−1 and it will be fast to get the dp array in the new row. Then, let's focus on optimizing it to O(n).We call the set of 0≤k≤p satisfying 0≤k+ai≤p as the legal interval of i (denoted as Li).It is concluded that the range of fi,0…p is at most 1, and this can be proven by considering the transfer to each of the j with the k∈Li which has the least fi−1,k. Let vi=min0≤j≤p(fi,j). We also have: for those j with fi,j=vi, they form a consecutive segment in the integer field. Let the segment be covering [li,ri].Inductive proof. The essence of the transfer is that it shifts all the DP values =vi−1 by ai unit length, and all the other numbers will be updated to vi−1+1. Then truncates the j∈((−inf,0)∪(p,+inf)) part. The consecutive segment remains consecutive. Specially, if [li−1,ri−1]∩Li=∅, then mink∈Li(fi−1,k)=vi−1+1, hence we need to set vi=vi−1+1, and li,ri as the range of j=k+ai in which k∈Li. Otherwise, vi=vi−1, and li,ri can be calculated by shifting li−1,ri−1 by ai unit length.In fact, we only need to maintain three variables l,r,v to represent the current consecutive segment and the current value field. Therefore, this problem can be easily solved in O(n).
#include <bits/stdc++.h>
 
namespace FastIO {
	template <typename T> inline T read() { T x = 0, w = 0; char ch = getchar(); while (ch < '0' || ch > '9') w |= (ch == '-'), ch = getchar(); while ('0' <= ch && ch <= '9') x = x * 10 + (ch ^ '0'), ch = getchar(); return w ? -x : x; }
	template <typename T> inline void write(T x) { if (!x) return; write<T>(x / 10), putchar((x % 10) ^ '0'); }
	template <typename T> inline void print(T x) { if (x > 0) write<T>(x); else if (x < 0) putchar('-'), write<T>(-x); else putchar('0'); }
	template <typename T> inline void print(T x, char en) { print<T>(x), putchar(en); }
}; using namespace FastIO;
 
#define MAXN 3000001
int a[MAXN];
void solve() {
	int N = read<int>(); long long p = 0, l = 0, r = 0, v = 0;
	for (int i = 1; i <= N; ++i) p += (a[i] = read<int>());
	for (int i = 1; i <= N; ++i) if (a[i] >= 0) {
		l += a[i], r = std::min(r + a[i], p);
		if (l > r) ++v, l = a[i], r = p;
	} else {
		a[i] = -a[i];
		r -= a[i], l = std::max(l - a[i], 0ll);
		if (l > r) ++v, l = 0, r = p - a[i];
	}
	print<int>(v + N + (int)(r != p), '\n');
}
int main() { int T = read<int>(); while (T--) solve(); return 0; }
 Amazing problem: 

    


15



 Good problem: 

    


11



 Average problem: 

    


4



 Bad problem: 

    


4



 Didn't solve: 

    


29



 
Try insert numbers into spaces between the elements of a (including the beginning and the end). Note that an array be can be formed in multiple ways (for example, you can insert a number x to the left or right of the original number x in array a). What's the number of different ways? AnswerIt's actually the "value", that is, the number of occurrances of a. Use the fact that "only one number can be inserted into each space" to prove.
It's actually the "value", that is, the number of occurrances of a. Use the fact that "only one number can be inserted into each space" to prove.
Read the editorial for I1 and the hints first.According to the hint, you can count the number of ways to insert the new numbers into the space, so the dp and transitions are similar to those in problem I1.We can add an additional dp array, gi,j representing the number of different ways when everything meets the description of fi,j. Let's see from which values it can be transferred:  If fi,j=vi, then fi,j can only be transferred from fi−1,j−ai. That is, gi,j=gi−1,j−ai. If fi,j=vi+1, then fi,j=∑k∈Li,fi−1,k=fi,j−1gi−1,k. We can use some tags and a Deque to maintain the whole process, so the amortized time complexity is O(n).
#include <bits/stdc++.h>
 
namespace FastIO {
	template <typename T> inline T read() { T x = 0, w = 0; char ch = getchar(); while (ch < '0' || ch > '9') w |= (ch == '-'), ch = getchar(); while ('0' <= ch && ch <= '9') x = x * 10 + (ch ^ '0'), ch = getchar(); return w ? -x : x; }
	template <typename T> inline void write(T x) { if (!x) return; write<T>(x / 10), putchar((x % 10) ^ '0'); }
	template <typename T> inline void print(T x) { if (x > 0) write<T>(x); else if (x < 0) putchar('-'), write<T>(-x); else putchar('0'); }
	template <typename T> inline void print(T x, char en) { print<T>(x), putchar(en); }
}; using namespace FastIO;
 
const int MOD = 998244353;
namespace Modint {
	inline int add(int x, int y) { return (x += y) >= MOD ? x - MOD : x; }
	inline int sub(int x, int y) { return x < y ? x - y + MOD : x - y; }
	inline int mul(int x, int y) { return 1ll * x * y % MOD; }
	inline int pow(int x, int y) { int r = 1; for (; y; y >>= 1, x = mul(x, x)) if (y & 1) r = mul(r, x); return r; }
	inline int inv(int x) { return pow(x, MOD - 2); }
};
struct modint {
	int v;
	modint (int x = 0) : v(x) { /* for debug only. assert(0 <= x && x < MOD); */ }
	inline int get() { return v; }
	modint operator - () const { return v ? MOD - v : 0; }
	modint operator + (const modint &k) const { return Modint::add(v, k.v); }
	modint operator - (const modint &k) const { return Modint::sub(v, k.v); }
	modint operator * (const modint &k) const { return Modint::mul(v, k.v); }
	modint operator / (const modint &k) const { return Modint::mul(v, Modint::inv(k.v)); }
	modint pow(const modint &k) const { return Modint::pow(v, k.v); }
	modint inverse() const { return Modint::inv(v); }
	modint operator += (const modint &k) { (v += k.v) >= MOD && (v -= MOD); return *this; }
	modint operator -= (const modint &k) { (v -= k.v) < 0 && (v += MOD); return *this; }
	modint operator *= (const modint &k) { return v = Modint::mul(v, k.v); }
	modint operator /= (const modint &k) { return v = Modint::mul(v, Modint::inv(k.v)); }
};
 
struct Node {
	int f; modint g; long long len;
	Node () {}
	Node (int F, int G, long long L) : f(F), g(G), len(L) {}
	Node (int F, modint G, long long L) : f(F), g(G), len(L) {}
}; std::deque<Node> Q;
 
#define MAXN 3000001
int a[MAXN];
void solve() {
	int N = read<int>(); long long p = 0, l = 0, r = 0, v = 0;
	for (int i = 1; i <= N; ++i) p += (a[i] = read<int>());
	for (int i = 1; i <= N; ++i) assert (std::abs(a[i]) <= p);
	Q.clear(); Q.push_back(Node(0, 1, 1)), Q.push_back(Node(1, 1, p));
	modint gv = 1, gz = p % MOD, tv = 0, tz = 0;
	for (int i = 1; i <= N; ++i) if (a[i] >= 0) {
		for (long long ls = a[i]; ls > 0; ) {
			Node k = Q.back(); Q.pop_back();
			if (ls < k.len) Q.push_back(Node(k.f, k.g, k.len - ls)), k.len = ls;
			(k.f == v ? gv : gz) -= k.g * (k.len % MOD), ls -= k.len;
		}
		l += a[i], r = std::min(r + a[i], p);
		if (l > r) ++v, l = a[i], r = p, gv = gz, tv = tz, gz = tz = 0;
		gz += -tz * (a[i] >= MOD ? a[i] - MOD : a[i]);
        if (a[i] > 0) Q.push_front(Node(v + 1, -tz, a[i]));
        tz += gv + tv * ((r - l + 1) % MOD);
	} else if (a[i] < 0) {
		a[i] = -a[i];
		for (long long ls = a[i]; ls > 0; ) {
			Node k = Q.front(); Q.pop_front();
			if (ls < k.len) Q.push_front(Node(k.f, k.g, k.len - ls)), k.len = ls;
			(k.f == v ? gv : gz) -= k.g * (k.len % MOD), ls -= k.len;
		}
		r -= a[i], l = std::max(l - a[i], 0ll);
		if (l > r) ++v, l = 0, r = p - a[i], gv = gz, tv = tz, gz = tz = 0;
		gz += -tz * (a[i] >= MOD ? a[i] - MOD : a[i]), Q.push_back(Node(v + 1, -tz, a[i])), tz += gv + tv * ((r - l + 1) % MOD);
    }
	print<int>((Q.back().g + (r == p ? tv : tz)).get(), '\n');
}
int main() { int T = read<int>(); while (T--) solve(); return 0; }
Try to solve the initial problem: count the number of valid array b for n≤500. hintConsider fi,j,k: the number of ways to fill the first i elements of b, which contains at most j first elements from a as a subsequence, and the sum of the first i elements is k.Try to optimize this from O(n2s2) to O(n2s), and then O(poly(n)), and then O(n3).
Consider fi,j,k: the number of ways to fill the first i elements of b, which contains at most j first elements from a as a subsequence, and the sum of the first i elements is k.Try to optimize this from O(n2s2) to O(n2s), and then O(poly(n)), and then O(n3).
 Amazing problem: 

    


3



 Good problem: 

    


1



 Average problem: 

    


5



 Bad problem: 

    


14



 Didn't solve: 

    


17



 
Why can't we just implement the procedure in the statement as it is?
Study examples in the statements and notice the values that we add to the result
The procedure is a divide and conquer. Split the problem in two halfs. Can you see any relation between the first and second half?
Can you quickly calc the second half given certain info about the first half? what are this info?
Let's say we know that there are x values counted in the first half with sum = y. How to calc the sum of values in second half in O(1)? 
For each counted value in the first half, there is a corresponding value in the second half at the same index.So, if you counted value number 5 in range [l, m], then you also count value number 5 in [m+l, r], for example.
Let's write the values of c, w and s at level i as ci, wi and si.Initially, c1=1, w1=n, and s1=1. At level i, do the following:  If wi<k, then we abort the process. ci+1=2ci and wi+1=⌊wi2⌋. If wi is even, si+1=2si+ciwi+1. If wi is odd, the sum of lucky values at this level is si+ciwi+1. Then si+1=2si+ci(wi+1+1). 
Let's say the j-th segment is [aj,…,aj+wi−1] (1≤j≤ci). If wi is even, the segment is split as [aj,…,aj+wi+1−1],[aj+wi+1,…,aj+wi−1]. Then, si+1 is calculated like:  si+1=ci∑j=1(aj+(aj+wi+1))=2ci∑j=1aj+ciwi+1=2si+ciwi+1.The odd case and the sum of lucky values can be handled in the same way.
If X and T have a common shortest period, the problem can be transformed into a pure number theory problemThis is like the process of doing Euclid algorithms on numbers, so if X and T don't share a common shortest period, there is at most one partition. I believe you are talking about common shortest period between X and Y? Or am I missing something?


[Editorial - contest/2043]
Tutorial is loading...
t = int(input())
for i in range(t):
    n = int(input())
    ans = 1
    while n > 3:
        n //= 4
        ans *= 2
    print(ans)
Tutorial is loading...
import sys
 
sys.set_int_max_str_digits(6000)
 
def fact(x):
    if x == 0:
        return 1
    return x * fact(x - 1)
 
t = int(input())
for i in range(t):
    n, k = map(int, input().split())
    n = min(n, 7)
    s = int(str(k) * fact(n))
    for i in range(1, 10, 2):
        if s % i == 0:
            print(i, end = ' ')
    print()
2043C - Sums on SegmentsWhat could the answer to the problem be if all elements were equal to 1 or -1? Let's consider all segments with a fixed left boundary l. The empty segment [l; l-1] has a sum of 0. As we move the right boundary to the right, the sum will change by pm1. That is, we can obtain all sums from the minimum sum to the maximum one. To find the sums for the entire array, we need to find the union of the segments. Since all segments include 0, their union is also a segment. Therefore, the possible sums are all sums from the minimum sum to the maximum sum in the entire array.Now let's apply this reasoning to the given problem. The segments that do not include the strange element still form a segment of possible sums that includes 0. As for the segments that include the strange element, we can look at them this way. We will remember these segments and remove the strange element. Then the resulting sums will also form a segment that includes 0. If we return the element to its place, all sums will increase exactly by this element. Thus, it will remain a segment, however, not necessarily including 0 now.Then the solution could be as follows. We will find the minimum and maximum sum among the segments that do not contain the strange element. We will find the minimum and maximum sum among the segments that do contain it. Then we will output the union of the obtained sum segments.Next, you need to adapt your favorite algorithm for finding the maximum sum segment for this problem. My favorite is reducing it to prefix sums. The sum of the segment [l; r] is equal to mathit{pref}_{r+1} - mathit{pref}_l. We fix the right boundary of the segment r. Since the first term for all segments is now the same, the maximum sum segment with this right boundary is the one with the minimum possible prefix sum at the left boundary. We will then iterate over r in increasing order and find the maximum sum among all right boundaries. The minimum prefix sum on the left can be maintained on the fly.For a fixed right boundary, we have two options: for some prefix of left boundaries, the strange element is inside the segment, and for some suffix, it is outside. This suffix may be empty if the boundary r is to the left of the strange element. Therefore, we will maintain two values on the fly: the minimum prefix sum before the strange element and after it.Finally, we need to find the possible sums in the union of the two segments. There are two options here. If the segments intersect, then it includes all sums from the minimum of the left boundaries to the maximum of the right ones. If they do not intersect, then it is simply two segments.Overall complexity: O(n) per testcase.
for _ in range(int(input())):
	n = int(input())
	a = list(map(int, input().split()))
	l1, r1 = 0, 0
	l2, r2 = 2*10**9, -2*10**9
	
	pr = 0
	mnl, mxl = 0, 0
	mnr, mxr = 2*10**9, -2*10**9
	for i in range(n):
		pr += a[i]
		if a[i] != -1 and a[i] != 1:
			mnr, mxr = mnl, mxl
			mnl, mxl = pr, pr
		l1 = min(l1, pr - mxl)
		r1 = max(r1, pr - mnl)
		l2 = min(l2, pr - mxr)
		r2 = max(r2, pr - mnr)
		mnl = min(mnl, pr)
		mxl = max(mxl, pr)
	res = []
	if l2 > r1:
		res = list(range(l1, r1 + 1)) + list(range(l2, r2 + 1))
	elif r2 < l1:
	    res = list(range(l2, r2 + 1)) + list(range(l1, r1 + 1))
	else:
		res = list(range(min(l1, l2), max(r1, r2) + 1))
	print(len(res))
	print(*res)
2043D - Problem about GCDFirst, let's try to solve this problem with G=1. We can check the pair (l, r). If its greatest common divisor is not 1, then we should check (l, r-1) and (l+1, r), i. e. the pairs on the distance (r-l-1). If these don't work, we can check (l, r-2), (l+1, r-1) and (l+2, r), and so on, and the answer will be located fast enough (more about that in the third paragraph of the editorial). So, we get a solution in O(K^2 log A) per test case, where A is the bound on the integers on the input, and K is the decrease in distance we had to make to find this pair (i. e. if the answer has distance |A-B|, then K = |r - l| - |A - B|).What to do if G ne 1? Almost the same, but first, we need to ensure that the first pair we try has both integers divisible by G. So, if l bmod G ne 0, let's shift it to the next closest integer which is divisible by G; and if r bmod G ne 0, let's subtract r bmod G from r to make it divisible. Then, we make the same process, but instead of trying pairs like (l, r-1), (l+1, r), (l, r-2) and so on, we try (l, r-G), (l+G, r), (l, r - 2G), and so on.Okay, now let's talk about why this works fast, i. e. why this K in the complexity formula is not that big. All the following paragraphs will assume G=1, but we can use the same reasoning with G>1 if we divide everything by G.Intuitively, we can think about it in terms of prime gaps: as soon as r-K becomes a prime number, we get our result. Average gap between two primes is about ln A, but there can be pretty big gaps, more than 1000. If you're bold and brave, you can stop here and submit, but let's find a better bound.Instead of thinking about the gap between two primes, let's think about the gap between two numbers which are coprime with l. Let's assume that l is the product of several first prime numbers (if it is not, integers which are coprime with l will appear even more often). frac{1}{2} of all integers are not divisible by 2; frac{2}{3} of them are not divisible by 3; frac{4}{5} of them are not divisible by 5, and so on. If we repeat this process until the product of primes we considered becomes too large, we can get that, on average, 1 in 7 or 8 integers is coprime with l. This is a better bound, but it still uses "average" gaps. However, this should be enough to try to submit the solution.Okay, now let's show a rigorous proof (which you really shouldn't need during the contest) of some reasonable bound. We can prove that if you consider all possible pairs of integers from intervals [l, l+30) and (r-30, r], you will find at least one coprime pair.There are 30 integers in each interval, so there are 900 pairs to consider. Suppose in some of them, both integers are divisible by 2. There will be at most 225 such pairs, so we are left with 675 pairs.Suppose in some of the remaining pairs, both integers are divisible by 3. There will be at most 10 integers divisible by 3 in each segment, so at most 100 pairs. We are left with 575 pairs.Suppose in some of the remaining pairs, both integers are divisible by 5. There will be at most 6 integers divisible by 5 in each segment, so at most 36 pairs. We are left with 539 pairs.If we repeat this until some prime number like 37, we will still have to "fix" more than 450 pairs, so at least one number has 15 or more pairs to "fix". This should mean that it is divisible by at least 15 primes which are greater than 37, and it means it's greater than 10^{18}. So, in every pair of intervals [l, l+30) and (r-30, r] such that the numbers are not greater than 10^{18}, there will be at least one coprime pair, and this proves that K le 60. In practice, it is much lower since, in our proof, we didn't consider the fact that a lot of pairs will have more than 1 prime which they are divisible by; if we take this into account (or repeat the same process until primes become much greater), we can prove tighter bounds, for example, K = 40.
#include<bits/stdc++.h>
 
using namespace std;
 
long long gcd(long long x, long long y)
{
    if(x == 0) return y;
    else return gcd(y % x, x);
}
 
void solve()
{
    long long l, r, g;
    scanf("%lld %lld %lld", &l, &r, &g);
    long long L = l + (l % g == 0 ? 0 : g - (l % g));
    long long R = r - r % g;
    for(int i = 0; i <= (R - L) / g; i++)
        for(int j = 0; j <= i; j++)
            if(gcd(L + j * g, R - (i - j) * g) == g)
            {
                printf("%lld %lld\n", L + j * g, R - (i - j) * g);
                return;
            }   
    puts("-1 -1");
}
 
int main()
{                             
    int t;
    scanf("%d", &t);
    for(int i = 0; i < t; i++) solve();
}
2043E - Matrix TransformationEvery operation which affects multiple bits can be split into several operations which only affect one bit. For example, if you make an  |= operation with x=11, it is the same as making three  |= operations with x=1, x=2 and x=8. So, let's solve the problem for each bit separately.If we consider only one bit, the problem becomes the following one:You are given a binary matrix A, and you have to check if it is possible to transform it into another binary matrix B. The operations you can make are "set all elements in some row to 0" and "set all elements in some column to 1".Let's find all cells where A_{i,j} ne B_{i,j}. If A_{i,j} = 0 and B_{i,j} = 1, then it means that we definitely have to apply an operation to the j-th column. Otherwise, if A_{i,j} = 1 and B_{i,j} = 0, then we definitely have to apply an operation to the i-th row. That way, we can find the operations we definitely need to apply. It's pretty obvious that we don't need to do the same operation twice — if we do the same operation to the same row/column twice, we can discard the first operation, since it will be overwritten by the last operation.But these are not all operations we need to apply. Suppose B_{i,j} = 0, and we change everything in the j-th column to 1. Then, we have to make an operation with the i-th row to set B_{i,j} back to 0. This means that after you apply an operation to the j-th column, you have to do an operation with the i-th row. Same when B_{i,j} = 1: after you apply an operation to the i-th row, you have to do an operation with the j-th column.Let's build a graph where every operation will be represented by a vertex, and a directed edge x rightarrow y means that, if you apply the operation x, the operation y must be applied after that. Some vertices of this graph represent operations which we definitely need to apply. If there is a cycle reachable from one of these vertices, the transformation is impossible, since we will apply operations forever and never get the matrix we need. But if there is no cycle reachable from any operation we need to apply, then we can "mark" all operations reachable from the operations we need, and apply them in the order of topological sorting, and we will get exactly the matrix B (for every cell that was changed, the last operation applied to it will make it correct; and we enforced that we need to apply operations to all cells that must change).Searching for a cycle in a directed graph can be done with "three-colored DFS" — a modification of DFS which, for each vertex, maintains one of three states — either this vertex wasn't reached by DFS at all, or it was already reached and is on the DFS stack, or this vertex was already fully processed (both reached by DFS and deleted from the DFS stack). This way, we can find a back-edge that creates the cycle as follows: if we try to go from a vertex to another vertex which is on the DFS stack, it means that we have found a cycle. There are other methods of cycle detection, but this one is the most common.If for every bit, we can make the transformations we need, the answer is Yes. Otherwise, the answer is No. The solution works in O(n m log A).
#include<bits/stdc++.h>
 
using namespace std;
 
struct graph
{
    int V;
    vector<vector<int>> g;
    vector<int> color;
 
    bool dfs(int v)
    {
        if(color[v] != 0) return false;
        color[v] = 1;
        bool res = false;
        for(auto y : g[v])
        {
            if(color[y] == 2) continue;
            else if(color[y] == 0)
                res |= dfs(y);
            else res = true;
        }
        color[v] = 2;
        return res;
    }
 
    void add_edge(int x, int y)
    {
        g[x].push_back(y);
    }
 
    graph(int V)
    {
        this->V = V;
        this->g.resize(V);
        this->color.resize(V);
    };
};
 
int get_bit(int x, int y)
{
    return (x >> y) & 1;
}
 
bool check(const vector<vector<int>>& a, const vector<vector<int>>& b, int k)
{
    int n = a.size();
    int m = a[0].size();
    vector<bool> must_row(n);
    vector<bool> must_col(m);
    auto G = graph(n + m);
    for(int i = 0; i < n; i++)
        for(int j = 0; j < m; j++)
        {
            if(get_bit(a[i][j], k) != get_bit(b[i][j], k))
            {
                if(get_bit(b[i][j], k) == 0) must_row[i] = true;
                else must_col[j] = true;
            }
            if(get_bit(b[i][j], k) == 0) G.add_edge(j + n, i);
            else G.add_edge(i, j + n);
        }                 
    for(int i = 0; i < n; i++)
        if(must_row[i] && G.dfs(i))
            return false;
    for(int j = 0; j < m; j++)
        if(must_col[j] && G.dfs(j + n))
            return false;
    return true;
}
 
void solve()
{
    int n, m;
    scanf("%d %d", &n, &m);
    vector<vector<int>> a(n, vector<int>(m));
    auto b = a;
    for(int i = 0; i < n; i++)
        for(int j = 0; j < m; j++)
            scanf("%d", &a[i][j]);
    for(int i = 0; i < n; i++)
        for(int j = 0; j < m; j++)
            scanf("%d", &b[i][j]);
    for(int i = 0; i < 30; i++)
    {
        if(!check(a, b, i))
        {
            puts("No");
            return;
        }
    }
    puts("Yes");
}
 
int main()
{                             
    int t;
    scanf("%d", &t);
    for(int i = 0; i < t; i++) solve();
}
2043F - NimLet's recall the condition for the second player to win in the game of "Nim". The XOR of the sizes of the piles must be equal to 0. That is, we are asked to remove as many piles as possible so that the XOR becomes 0.Notice the following fact. Suppose there are c piles of size x on a segment. If we remove an even number of piles, the XOR does not change. If we remove an odd number, it changes by x. Therefore, there is no point in keeping more than 2 piles. If we keep t > 2 piles, we can remove another 2 piles, and it will not change anything at all.We will answer the queries independently. Let's find the count of each of the 51 elements in the given segment. For example, we can precompute how many times each element appears in each prefix.Now we can write the following dynamic programming solution. mathit{dp}[i][j][f] represents a pair of (maximum amount of removed elements, number of ways to remove that amount), where we have considered the first i of the 51 values, the current XOR among the non-removed values is j, and f = 1 if at least one element is not removed and 0 otherwise.Let the amount of the current value be c. From each state, there are at most three transitions:   remove all elements with that value — 1 way;  keep 1 element — c ways;  keep 2 elements — frac{c(c-1)}{2} ways. The base case is mathit{dp}[0][0][0] = (0, 1), the rest are filled with (-1, -1), for example. The final state is mathit{dp}[51][0][1]. If it's equal to (-1, -1), there's no answer.Since the XOR cannot exceed 63, the number of states in the dynamic programming solution is 51 cdot 64 cdot 2. From each state, there are three transitions, which fits within the time constraints.
#include <bits/stdc++.h>
 
using namespace std;
 
#define forn(i, n) for(int i = 0; i < int(n); i++) 
 
const int MOD = 998244353;
 
int add(int a, int b){
	a += b;
	if (a >= MOD)
		a -= MOD;
	return a;
}
 
int mul(int a, int b){
	return a * 1ll * b % MOD;
}
 
struct state{
	int mx, cnt;
};
 
void merge(state &a, int mx, int cnt){
	if (a.mx > mx) return;
	if (a.mx < mx) a.mx = mx, a.cnt = 0;
	a.cnt = add(a.cnt, cnt);
}
 
state dp[52][64][2];
 
int main(){
	cin.tie(0);
	ios::sync_with_stdio(false);
	int n, q;
	cin >> n >> q;
	vector<int> a(n);
	forn(i, n) cin >> a[i];
	int mx = *max_element(a.begin(), a.end());
	vector<vector<int>> cnt(n + 1, vector<int>(mx + 1));
	forn(i, n){
		cnt[i + 1] = cnt[i];
		++cnt[i + 1][a[i]];
	}
	forn(_, q){
		int l, r;
		cin >> l >> r;
		--l;
		memset(dp, -1, sizeof(dp));
		dp[0][0][0] = {0, 1};
		forn(i, mx + 1){
			int c = cnt[r][i] - cnt[l][i];
			int c2 = c * 1ll * (c - 1) / 2 % MOD;
			forn(val, 64) forn(fl, 2) if (dp[i][val][fl].cnt >= 0){
				if (c > 0)
					merge(dp[i + 1][val ^ i][true], dp[i][val][fl].mx + c - 1, mul(dp[i][val][fl].cnt, c));
				if (c > 1)
					merge(dp[i + 1][val][true], dp[i][val][fl].mx + c - 2, mul(dp[i][val][fl].cnt, c2));
				merge(dp[i + 1][val][fl], dp[i][val][fl].mx + c, dp[i][val][fl].cnt);
			}
		}
		auto ans = dp[mx + 1][0][1];
		if (ans.cnt == -1)
			cout << -1 << '\n';
		else
			cout << ans.mx << ' ' << ans.cnt << '\n';
	}
}
2043G - Problem with QueriesFirst, let's reformulate the problem. Instead of counting the number of pairs of distinct elements in a segment, we will count the number of pairs of identical elements and subtract it from the total number of pairs. To solve this problem, we will use square root decomposition on the array.Let's divide the original array into blocks of size B and learn how to answer queries (l, r) that satisfy the following conditions:   l = L cdot B — this means that the left boundary of the query coincides with the beginning of some block of the square root decomposition;  r = R cdot B - 1 — this means that the right boundary of the query coincides with the last element of some block of the square root decomposition. Due to this restriction on the problem, we can utilize certain properties that will be necessary for our solution:   The order of elements within a block does not matter; we can treat each block of our square root decomposition as an unordered multiset;  Changing the value of an element in terms of a multiset can be reformulated as removing the old value and adding the new value. In general, the modified queries can be rewritten in the following format:   add ind~x — add an element with value x to the block ind.  del ind~x — remove an element with value x from the block ind.  get L~R — count the number of pairs of positions (i, j), where L cdot B le i < j le R cdot B and a_i = a_j. Let's assume we have an array blocks[i][j], which stores the answer to the third type of query for all possible segments of blocks 0 le i le j le K, where K is the number of blocks in the square root decomposition of our array. Initially, we fill the blocks array with zeros and then add all elements using the add operation.Let's observe how the first type of query modifies this array; the second type of query is considered similarly. When an element with value x is added to the block ind, it affects all elements of the array blocks[i][j] such that 0 le i le ind le j.For a specific element of the array blocks[i][j], its value increases by the number of occurrences of the element x in the segment [i cdot B; j cdot B]. This happens because the added element can form a pair with all existing elements equal to the specified value that belong to this segment. Formally, this can be described as blocks[i][j]~=blocks[i][j] + count(i, j, x), where count(i, j, x) is a function that returns the number of occurrences of the element x in the blocks i, dots, j. The function count(i, j, x) can be maintained by storing an array pref[val][i], where for each element val, it will store how many times it appears in the segment of blocks [0, i].When adding an element, the number of values that need to be recalculated will be about frac{K cdot (K - 1)}{2}. If we can do this in O(1), we can achieve a solution in O((Q+N) cdot N^{frac{2}{3}}, taking B = N^{frac{2}{3}}. Unfortunately, it is practically impossible to fit this within time limits, so let's try to improve the solution. Returning to the description of how to modify an arbitrary element of the array blocks[i][j], let's rewrite and transform the formula:  blocks[i][j]~=blocks[i][j] + count(i, j, x) into  blocks[i][j]~=blocks[i][j] + count(i, ind, x) + count(ind + 1, j, x). The second term in this expression does not use the right boundary j, and the third term does not use the left boundary i. Suppose we want to add the second term to the relevant elements blocks[i][j]; we can iterate over the left boundary i and add count(i, ind, x) for all right boundaries where j ge ind.To perform such additions in O(1), we will use something like a difference array: we will create an array update_right[i][j], where for a fixed left boundary, we will store how the suffix of right boundaries will change. When iterating over the left boundary i, for the suffix of right boundaries j ge ind, we need to add the same amount count(i, ind, x); but we will handle this addition on the suffix in one position of the array update_right[i][ind] = update_right[i][ind] + count(i, ind, x).Then, to account for these additions in the third type of queries get(L,~ R), we will need to take the sum of the elements of the array update_right[L][L] + update_right[L][L + 1] + dots + update_right[L][R].The third term from the sum blocks[i][j]~=blocks[i][j] + count(i, ind, x) + count(ind + 1, j, x) is processed similarly: we will iterate over the right boundary and form an array update_left, where the additions will be on the prefix.Thus, each modification query will be executed in O(K). A query of the third type requires us to iterate over one of the fixed boundaries and find the sum, which will require O(K) operations. By choosing B = sqrt N, each of these queries can be executed in O(sqrt N).Returning to the original problem, let's describe how to find the answer to a query whose boundaries do not coincide with the boundaries of the blocks:   First, find the answer for the problem we learned to solve above for the largest segment of blocks that is completely contained within the query;  Now, we need to add the contribution of O(B) elements from the blocks that are not fully included in the query. Each of these O(B) elements can form a pair with all elements in our block segment, so we will need to take the number of occurrences of this element from the pref array. Additionally, these O(B) elements can form pairs with each other; to handle this, we can maintain an array of size N, where for each value, we keep track of the number of additional elements with that value. When processing some additional element x, we will add the count of these elements from the array to the answer and increase this count by 1; at the end of processing the query for all additional elements, we will reset their count back to 0.Thus, we have obtained a solution in O((N+Q) cdot sqrt N).


[Editorial - contest/2051]
2051A - Preparing for the OlympiadLet's consider what contribution each day that Monokarp trains makes to the difference. For each day, except the last one, if Monokarp trains on that day, then the number of problems he has solved will increase by aiai, and the number of problems solved by Stereokarp will increase by bi+1bi+1. Therefore, if ai−bi+1>0ai−bi+1>0, it is beneficial for Monokarp to train on the ii-th day; otherwise, it is not beneficial.On the last day, it is always beneficial to train, as Stereokarp will not solve anything on the day following it.
#include <bits/stdc++.h>
 
using namespace std;

int main() {
  int t;
  cin >> t;
  while (t--) {
    int n;
    cin >> n;
    vector<int> a(n), b(n);
    for (auto &x : a) cin >> x;
    for (auto &x : b) cin >> x;
    int ans = a[n - 1];
    for (int i = 0; i < n - 1; ++i)
      ans += max(0, a[i] - b[i + 1]);
    cout << ans << '\n';
  }
}
2051B - JourneyProcessing every day separately is too slow. Instead, we will use the fact that every three days, the number of kilometers Monocarp walks repeats, and process days in "triples".During every three days, Monocarp walks exactly (a+b+c)(a+b+c) kilometers, so we can do the following: while n≥a+b+cn≥a+b+c, subtract (a+b+c)(a+b+c) from nn and increase the answer by 33; and finally, process the remaining days, since there will be at most 33 of them.However, this works in O(n)O(n) per test case, so it is still too slow. We need to improve the part when we subtract a+b+ca+b+c from nn until nn becomes less than this sum. Does this sound familiar?The number of times we need to subtract (a+b+c)(a+b+c) from nn is exactly ⌊na+b+c⌋⌊na+b+c⌋, and the number we get after that is nmod(a+b+c)nmod(a+b+c) by definition of integer division and remainder. This allows us to process all "triples" in O(1)O(1), instead of running a loop in O(n)O(n).The solution we get works in O(1)O(1) per test case.
t = int(input())
for i in range(t):
    n, a, b, c = map(int, input().split())
    sum = a + b + c
    d = n // sum * 3
    if n % sum == 0:
        print(d)
    elif n % sum <= a:
        print(d + 1)
    elif n % sum <= a + b:
        print(d + 2)
    else:
        print(d + 3)

2051C - Preparing for the ExamFor every question list, we should check if Monocarp knows all questions from the list, i. e. all numbers 1,2,…,ai−1,ai+1,…,n1,2,…,ai−1,ai+1,…,n appear in the list [q1,q2,…,qk][q1,q2,…,qk]. Searching for every number in the list qq naively is too slow; instead, we can make a boolean array such that the jj-th element in it is true if and only if Monocarp knows the jj-th question. That way, we can check if an integer appears in the list qq in O(1)O(1).However, that is not enough, since every list of questions contains O(n)O(n) questions, and there are O(n)O(n) lists. We need to use the fact that every list contains exactly n−1n−1 questions somehow.If Monocarp knows all nn questions, he can answer any question list (since he knows everything). If Monocarp knows n−2n−2 questions or less, he cannot pass at all, since every question list contains more questions than he knows. The only case that's left if when k=n−1k=n−1, i. e. Monocarp knows all questions except for one. Let's analyze it in more detail (the two next paragraphs will assume that k=n−1k=n−1).Since every question list has the same size as the set of questions known by Monocarp, then in order for Monocarp to pass the exam, these two sets of questions must be equal. However, checking that they are equal by iterating on their contents is too slow; instead, we will check that two sets of questions are different by using the elements which are absent from them.Let's check if Monocarp knows the question aiai. If he does, then the ii-th list of questions is different from the set of questions he knows, so he can't pass. But if Monocarp doesn't know the aiai-th question, then he knows every question which is not aiai, so he can pass. So, Monocarp knows the ii-th question list if and only if he does not know the aiai-th question, and this can be checked in O(1)O(1).This way, we get a solution working in O(n)O(n) on each test case.
for _ in range(int(input())):
    n, m, k = map(int, input().split())
    a = list(map(int, input().split()))
    q = list(map(int, input().split()))
    used = [False for i in range(n + 1)]
    for i in q:
        used[i] = True
    l = len(q)
    for i in range(m):
        if l == n or (l == n-1 and not used[a[i]]):
            print(1, end='')
        else:
            print(0, end='')
    print()
2051D - Counting PairsThere is a common trick in problems of the form "count something on segment [l,r][l,r]": calculate the answer for [0,r][0,r], and then subtract the answer for [0,l−1][0,l−1]. We can use this trick in our problem as follows: calculate the number of pairs i,ji,j such that the sum of all other elements is less than y+1y+1, and subtract the number of pairs such that the sum is less than xx.Now we need to solve the following problem: given an array and an integer xx, calculate the number of ways to choose i,ji,j (1≤i<j≤n1≤i<j≤n) so that the sum of all elements, except for aiai and ajaj, is less than xx.Naive solution (iterate on the pair, calculate the sum of remaining elements) works in O(n3)O(n3). It can be improved to O(n2)O(n2) if, instead of calculating the sum of remaining elements in O(n)O(n), we do it in O(1)O(1): if we remove aiai and ajaj, the remaining elements sum up to s−ai−ajs−ai−aj, where ss is the sum of all elements.However, O(n2)O(n2) is still too slow. For every ii, let's try to calculate the number of elements jj which "match" it faster. If we sort the array, the answer won't change; but in a sorted array, for every ii, all possible values of jj form a suffix of the array (if s−ai−aj<xs−ai−aj<x and aj+1≥ajaj+1≥aj, then s−ai−aj+1<xs−ai−aj+1<x). So, for every ii, let's find the minimum j′j′ such that s−ai−aj′<xs−ai−aj′<x; all j≥j′j≥j′ are possible "matches" for ii. This can be done with two pointers method: when we decrease ii, the index j′j′ won't decrease.Unfortunately, this method has an issue. We need to calculate only pairs where i<ji<j, but this method doesn't maintain this constraint. However, this issue can be easily resolved.First, let's get rid of pairs where i=ji=j. To do so, simply calculate the number of indices ii such that s−2ai<xs−2ai<x.Then, let's get rid of pairs where i>ji>j. For every such pair, there is a pair with i<ji<j where these two indices are swapped (and vice versa), so we just need to divide the number of pairs by 22.Now we have a solution working in O(nlogn)O(nlog⁡n) for each test case. Instead of two pointers, you can use binary search, the complexity will be the same.
def calcLessThanX(a, x):
    n = len(a)
    s = sum(a)
    j = 0
    ans = 0

    for i in range(n-1, -1, -1):
        while j < n and s - a[i] - a[j] >= x:
            j += 1
        ans += (n - j)

    for i in range(n):
        if s - a[i] - a[i] < x:
            ans -= 1
    
    return ans // 2

for _ in range(int(input())):
    n, x, y = map(int, input().split())
    a = list(map(int, input().split()))
    
    a = sorted(a)
    print(calcLessThanX(a, y+1) - calcLessThanX(a, x))
2051E - Best PriceFirst, let's design a solution in O(n2)O(n2). We can solve the problem in O(n⋅maxbi)O(n⋅maxbi), if we iterate on the price pp we use, and for every price, calculate the number of trees bought and the number of negative reviews. However, we don't need to check every possible price from 11 to maxbimaxbi: let's instead check every integer in the union of aa and bb (or check every aiai, and then check every bibi).Why is it always optimal? Suppose some integer price pp which is not present in the union of aa and bb is optimal. Then, if we use p+1p+1 instead of pp, the status of each customer will be the same, but we will get more money for each tree we sell. So, it is enough to check the elements of aa and the elements of bb as possible prices. This works in O(n2)O(n2), we need to speed it up. I will explain two different methods that allow to check every price faster.Event processing (or sweep line):Shortly, we process all possible prices in ascending order, and when we go from one price to the next, we update the customers which no longer want to buy a tree with a new price, and the customers which will leave a negative review if the price is increased.One of the ways to implement it is as follows. For every customer, create two "events" of the type "when price exceeds aiai, the customer will leave a negative review" and "when price exceeds bibi, the customer will no longer buy a tree and leave a negative review". These events can be implemented as pairs of integers (ai,1)(ai,1) and (bi,2)(bi,2).Then, we can sort the events and process them from left to right in sorted order, maintaining the number of trees and negative reviews. When we process the event with price pp, the change it makes will come into effect only when the price exceeds pp, so we should first update the answer, then apply the change from the event. Furthermore, all events with the same price value should be processed at the same time (so if there are multiple events with the same price value, you don't update the answer after processing only several of them). All of this is a bit complicated to implement, that's why I would like to show you anAlternative approach:For every price pp, we need to calculate two values:  the number of trees bought, i. e. the number of customers ii such that bi≥pbi≥p;  the number of negative reviews, i. e. the number of customers ii such that ai<p≤biai<p≤bi. The first one can be calculated in O(logn)O(log⁡n) with binary search, if we sort the array bb. The second one is a bit trickier.Let's calculate it as follows: take the number of trees bought, and then subtract the number of trees bought without a negative review (which is the number of customers ii such that ai≥pai≥p). If we sort both arrays aa and bb, this value can also be processed in O(logn)O(log⁡n) with binary search. So, we spend O(logn)O(log⁡n) time to check one possible price, and the number of different prices we have to check is up to 2n2n, so this solution works in O(nlogn)O(nlog⁡n).
#include <bits/stdc++.h>
 
using namespace std;

int main() {
  ios::sync_with_stdio(false); cin.tie(0);
  int t;
  cin >> t;
  while (t--) {
    int n, k;
    cin >> n >> k;
    vector<int> a(n), b(n);
    for (auto &x : a) cin >> x;
    for (auto &x : b) cin >> x;
    vector<pair<int, int>> ev;
    for (int i = 0; i < n; ++i) {
      ev.emplace_back(a[i], 1);
      ev.emplace_back(b[i], 2);
    }
    sort(ev.begin(), ev.end());
    long long ans = 0;
    int cnt = n, bad = 0;
    for (int i = 0; i < 2 * n;) {
      auto [x, y] = ev[i];
      if (bad <= k) ans = max(ans, x * 1LL * cnt);
      while (i < 2 * n && ev[i].first == x) {
        bad += (ev[i].second == 1);
        bad -= (ev[i].second == 2);
        cnt -= (ev[i].second == 2);
        ++i;
      }
    }
    cout << ans << '\n';
  }
}
2051F - JokerLet's represent the positions where the joker can be as a set of non-overlapping segments [l1,r1][l1,r1], [l2,r2][l2,r2], .... Let's consider what happens to the segment [l,r][l,r] after applying the ii-th operation:   if ai<lai<l, the possible positions segment becomes [l−1,r][l−1,r] (since moving the aiai-th card to the front does not change the joker's positions, while moving it to the back shifts the positions up by 11);  if ai>rai>r, the possible positions segment becomes [l,r+1][l,r+1] (since moving the aiai-th card to the front shifts the positions down by 11, while moving it to the back does not change the joker's positions);  if l≤ai≤rl≤ai≤r, let's consider 33 subsegments where the joker can be located:   positions from the subsegment [l,ai−1][l,ai−1] moves to [l,ai][l,ai] (similarly to the case ai>rai>r);  positions from the subsegment [ai+1,r][ai+1,r] moves to [ai,r][ai,r] (similarly to the case ai<lai<l);  the joker from position aiai moves to one of two positions: 11 or nn.  Thus, in this case, the segment [l,r][l,r] remains, but we need to add two new segments ([1,1][1,1] and [n,n][n,n]) to the set. Note that when l=r=ail=r=ai, the current segment disappears.At first glance, it seems that this solution works in O(nq)O(nq), since the number of segments can be O(n)O(n), and we need to update each of them. However, it is not difficult to notice that there cannot be more than 33 segments. Specifically: the initial segment [m,m][m,m], which expands to the left and right, the segment [1,1][1,1], which expands only to the right, and the segment [n,n][n,n], which expands only to the left.
#include <bits/stdc++.h>
 
using namespace std;

int main() {
  int t;
  cin >> t;
  while (t--) {
    int n, m, q;
    cin >> n >> m >> q;
    vector<pair<int, int>> segs({{1, -q}, {m, m}, {n + q + 1, n}});
    while (q--) {
      int x;
      cin >> x;
      bool ins = false;
      for (auto& [l, r] : segs) {
        if (x < l) l = max(1, l - 1);
        else if (x > r) r = min(n, r + 1);
        else {
          ins = true;
          if (l == r) l = n + q, r = -q;
        }
      }
      if (ins) {
        segs[0] = {1, max(segs[0].second, 1)};
        segs[2] = {min(segs[2].first, n), n};
      }
      int lf = 0, rg = -1, ans = 0;
      for (auto [l, r] : segs) {
        if (l > r) continue;
        if (l > rg) {
          ans += max(0, rg - lf + 1);
          lf = l; rg = r;
        }
        rg = max(rg, r);
      }
      ans += max(0, rg - lf + 1);
      cout << ans << ' ';
     }
     cout << '\n';
  }
}
2051G - SnakesNote that when you place snakes on the strip in some order, they form some permutation. And when you fix that permutation, you can place them greedily.In other words, when you know in what order you'll place snakes, it's always optimal to place them as close to each other as possible. Since the bigger the initial distance — the bigger the resulting distance of the farthest snake (or the bigger the final score). We can even calculate that final score precisely: it's equal to 1+sum of distances+number of times the last snake enlarges1+sum of distances+number of times the last snake enlarges.So, we can solve the task in two steps. First, let's calculate minDist[i][j]minDist[i][j] — the minimum possible distance between snakes ii and jj if we plan to place snake jj right after snake ii. Suppose the initial gap between these snakes is xx. Let's skim through all events:   each time the ii-th snake enlarges, our gap decreases, or x′=x−1x′=x−1.  each time the jj-th snake shrinks, our gap increases, or x′=x+1x′=x+1.  if at any moment x′x′ becomes negative, then we lose. In other words, we needed bigger initial xx. We can rephrase what happens more formally: for each event ii let ei=1ei=1 if xx increases, ei=−1ei=−1 if xx decreases or 00 otherwise. Then after the ii-th event the current gap will be equal to x′=x+∑ij=1ejx′=x+∑j=1iej.The following inequality should hold for each ii: x+∑ij=1ej≥0x+∑j=1iej≥0 or x≥−∑ij=1ejx≥−∑j=1iej. So, if we will find the minimum min1≤i≤q∑ij=1ejmin1≤i≤q∑j=1iej then we can set the initial distance to this minimum gap plus one, or minDist[i][j]=−min1≤i≤q∑ij=1ej+1minDist[i][j]=−min1≤i≤q∑j=1iej+1.Now we know the minimum distances between neighboring snakes, so we can find the optimal order. Let's do it with bitmask dp d[mask][lst]d[mask][lst], since all we need to know in each state is the set of already placed snakes maskmask and the last snake lstlst. Transitions are straightforward: let's just choose the next snake to place and place it at distance minDistminDist.The initial states are d[2i][i]=1d[2i][i]=1 for each ii. The answer is min1≤i≤nd[2n−1][i]+number of times snake i enlargesmin1≤i≤nd[2n−1][i]+number of times snake i enlarges, i. e. we just choose the last snake.The time complexity is O(n2q)O(n2q) for the first part (or O(nq)O(nq) if written more optimally) plus O(2nn2)O(2nn2) for the second part.
#include<bits/stdc++.h>

using namespace std;

#define fore(i, l, r) for(int i = int(l); i < int(r); i++)
#define sz(a) int((a).size())

const int INF = int(1e9);

int n, q;
vector<int> id, ch;

bool read() {
    if (!(cin >> n >> q))
        return false;
    id.resize(q);
    ch.resize(q);
    fore (i, 0, q) {
        char c;
        cin >> id[i] >> c;
        id[i]--;
        ch[i] = c == '+' ? 1 : -1;
    }
    return true;
}

int getDist(int s, int t) {
    int pSum = 0, cMin = 0;
    fore (e, 0, q) {
        if (id[e] == t)
            pSum += ch[e] < 0;
        if (id[e] == s)
            pSum -= ch[e] > 0;
        cMin = min(cMin, pSum);
    }
    return -cMin + 1;
}

inline void solve() {
    vector<vector<int>> minDist(n, vector<int>(n, INF));

    fore (i, 0, n) fore (j, 0, n)
        minDist[i][j] = getDist(i, j);

    vector<int> len(n, 0);
    fore (e, 0, q)
        len[id[e]] += ch[e] > 0;
    
    vector< vector<int> > d(1 << n, vector<int>(n, INF));
    fore (i, 0, n)
        d[1 << i][i] = 1;
    
    fore (mask, 1, 1 << n) fore (lst, 0, n) {
        if (d[mask][lst] == INF)
            continue;
        fore (nxt, 0, n) {
            if ((mask >> nxt) & 1)
                continue;
            int nmask = mask | (1 << nxt);
            d[nmask][nxt] = min(d[nmask][nxt], d[mask][lst] + minDist[lst][nxt]);
        }
    }
    int ans = INF;
    fore (lst, 0, n)
        ans = min(ans, d[(1 << n) - 1][lst] + len[lst]);
    cout << ans << endl;
}

int main() {
#ifdef _DEBUG
    freopen("input.txt", "r", stdin);
    int tt = clock();
#endif
    ios_base::sync_with_stdio(false);

    if(read()) {
        solve();
        
#ifdef _DEBUG
        cerr << "TIME = " << clock() - tt << endl;
        tt = clock();
#endif
    }
    return 0;
}
#include <bits/stdc++.h>
using namespace std;
#define int long long
#define endl "\n"

void solve() {
    int n, k;
    cin >> n >> k;
    map<int, int> positive_review, negative_review;
    priority_queue<int, vector<int>, greater<>> prices;

    for (int i = 0; i < n; i++) {
        int a;
        cin >> a;
        positive_review[a]++;
        prices.emplace(a);
    }

    for (int i = 0; i < n; i++) {
        int a;
        cin >> a;
        negative_review[a]++;
        prices.emplace(a);
    }

    int best = 0;
    int negative = 0;
    int last = -1;
    while (!prices.empty()) {
        int price = prices.top();
        prices.pop();
        if (price == last)
            continue;
        last = price;
        int cur = n * price;
        if (negative <= k)
            best = max(best, n * price);
        negative += positive_review[price];
        negative -= negative_review[price];
        n -= negative_review[price];
    }

    cout << best << endl;
}

signed main() {
    #ifndef ONLINE_JUDGE
    freopen("input.in", "r", stdin);
    freopen("output.out", "w", stdout);
    #endif

    ios_base::sync_with_stdio(false);
    cin.tie(NULL);
    cout.tie(NULL);

    int t;
    cin >> t;
    while (t--) {
        solve();
    }

    return 0;
}


[Editorial - contest/2049]
2049A - MEX DestructionCase 1: All elements are 0. Then the answer is 0.Case 2: Some element is non-zero, and all non-zero elements form a contiguous subarray. Then the answer is 1 since we can choose that subarray and replace it with a 0.Case 3: Otherwise, the answer is 2.  We can replace the entire array with a non-zero element (since 0 is in the array), then replace the entire array again with a 0 (since the only element left is non-zero). 1 operation is not enough. If we only use 1 operation, the selected subarray must contain all non-zero elements. Since the non-zero elements do not form a subarray, the selected subarray must contain a 0, thus the MEX will be non-zero. 
#include <bits/stdc++.h>
using namespace std;

void solve()
{
    int n; cin >> n;
    vector<int> a(n);
    for (int i = 0; i < n; i++)
        cin >> a[i];

    while (!a.empty() && a.back() == 0)
        a.pop_back();

    reverse(a.begin(), a.end());
    while (!a.empty() && a.back() == 0)
        a.pop_back();
    reverse(a.begin(), a.end());

    if (a.empty())
    {
        cout << 0 << '\n';
        return;
    }

    bool hasZero = false;
    for (const auto x : a)
        hasZero |= x == 0;
    if (hasZero)
        cout << 2 << '\n';
    else
        cout << 1 << '\n';
}

int main()
{
    int t;
    cin >> t;
    for (int i = 0; i < t; i++)
        solve();

    return 0;
}
2049B - pspspspsSince the entire p must be a permutation, if s1=s, we can set s1=., and if sn=p, we can set sn=..After that, the answer is YES if and only if all non-dot characters in s are all p or s.If all non-dot characters are p, we can choose the permutation p=[1,2,…,n]. If all non-dot characters are s, we can choose p=[n,n−1,…,1].Otherwise, there exists both a p and a s. Suppose for contradiction that there is a solution. Let a and b represent the subarrays represented by the p and s respectively. Without loss of generality, suppose a is the shorter subarray.  Since b is also a permutation, the elements of a must be in b. Since p is a permutation, a must be a subarray of b. However, b cannot contain a: since b is not the entire p, b does not contain p1. However, a contains p1. Contradiction. 
#include <bits/stdc++.h>
using namespace std;

void solve()
{
    int n; cin >> n;
    string s; cin >> s;
    if (s[0] == 's') s[0] = '.';
    if (s.back() == 'p') s.back() = '.';
    bool found_p = false;
    bool found_s = false;
    for (const auto c : s)
    {
        switch (c)
        {
        case 'p':
            found_p = true;
            break;
        case 's':
            found_s = true;
            break;
        }
    }
    cout << (found_p && found_s ? "NO" : "YES") << '\n';
}

int main()
{
    int t; cin >> t;
    for (int i = 0; i < t; i++) solve();

    return 0;
}
2049C - MEX CycleThere are many possible solutions. The simplest one we can find (thanks to Kaey) is as follows:  Set ax=0,ax+1=1,ax+2=0,…, alternating between 0 and 1, wrapping around accordingly. Formally, using 0-based indexing, set a(x+i)modn=imod2 for all i (0≤i≤n−1). If n is odd or if x−y is even, set ax=2. Why this works:  If n is even and x−y is odd, all 0's are only friends with 1's and vice versa. If n is odd, ax will be adjacent to 0 and 1, so we set ax=2. Now a is valid ignoring the extra friendship. Adding in the extra friendship, a is still valid since ax=2>ay, so it will not affect ay. If n is even and x−y is even, the extra friendship connects two 0 or two 1. Setting ax=2 works because dragon x's friends still have another neighbor to maintain their MEX. 
#include <iostream>
#include <vector>
using namespace std;

void solve() {
    int n, x, y;
    cin >> n >> x >> y;
    --x; --y;
    vector<int> ans(n);
    for (int i = 0; i < n; ++i) ans[(x + i) % n] = i % 2;
    if (n % 2 || (x - y) % 2 == 0)
        ans[x] = 2;
    for (auto x : ans)cout << x << ' ';
    cout << endl;
}

int main() {
    int T;
    cin >> T;
    while (T--) solve();
}
2049D - Shift + EscLet f(i,j) be the minimum cost to move to cell (i,j) after shifting and g(i,j,x) be the minimum cost to move to (i,j) assuming row i is shifted to the left by x.For simplicity sake, we will add a row with all zeros above the first row. Also note that the operations with states denoting columns are all under modulo m, I am omitting the notation to avoid clutter.The transitions are as follows:Base cases: f(0,j)=0(0≤j<m)g(0,j,x)=kx(0≤j,x<m)From row i to row i+1: g(i,j,x)=min(f(i−1,j)+kx,g(i,j−1,x))+a(i,j+x)(∗)f(i,j)=minxg(i,j,x)In (∗), the f(i−1,j) term is from the case where you move from (i−1,j) to (i,j). Similarly the g(i,j−1,x) term is from the case where you move from (i,j−1) to (i,j). The final answer is f(n,m−1). The overall complexity is O(nm2).
#include<bits/stdc++.h>
using namespace std;
typedef long long int ll;
ll dp[511][511],a[511][511];

void solve()
{
    int n,m,k;
    cin>>n>>m>>k;
    for(int i=1;i<=n;i++){
        for(int j=0;j<m;j++)cin>>a[i][j];
    }
    for(int i=0;i<=n;i++){
        for(int j=0;j<m;j++)dp[i][j] = 1e18;
    }

    dp[0][0] = 0;
    for(int i=1;i<=n;i++){
        for(int shift = 0;shift<m;shift++){
            vector<ll>tmp(m,1e18);
            for(int j=0;j<m;j++)tmp[j] = dp[i-1][j] + a[i][(j+shift)%m] + k*1LL*shift;

            for(int j=0;j<m;j++)tmp[j] = min(tmp[j],tmp[(j+m-1)%m] + a[i][(j+shift)%m]);
            for(int j=0;j<m;j++)tmp[j] = min(tmp[j],tmp[(j+m-1)%m] + a[i][(j+shift)%m]);
            for(int j=0;j<m;j++)dp[i][j] = min(dp[i][j],tmp[j]);
        }
        //for(int j=0;j<m;j++)cout<<dp[i][j]<<" ";
       // cout<<'\n';
    }
    cout<<dp[n][m-1]<<endl;
}

int main()
{
    int t; cin>>t;
    for (int i = 0; i < t; i++) solve();
}
2049E - Broken QueriesMake 2 queries [1,n/4] and [n/4+1,n/2]. This tells us which half the 1 is in: it is in [1,n/2] if the query results are different and [n/2+1,n] otherwise.Make 1 query: query [1,n/2] if the 1 is in it or [n/2+1,n] otherwise. This tells us that k<n/2 if the result is 1 and k≥n/2 otherwise.Without loss of generality, assume that the 1 is in [1,n/2]. Now we can binary search for k in [1,n/2] or [n/2+1,n]. Let k′ be our guess.  If k<n/2, query [n/2+1,n/2+k′]. The result is 1 if k′≥k and 0 otherwise. If k≥n/2, query [1,k′]. The result is 0 if k′≥k and 1 otherwise. In both cases, the binary search takes logn−1≤29 queries. Overall, this takes at most 2+1+29=32 queries.The limit of 33 queries (instead of 32) is to allow less optimized solutions and other solutions. For example, one can instead do 3 queries in the beginning [1,n/4], [n/4+1,n/2], [n/2+1,3n/4] to determine which quarter the 1 is in.
#include <bits/stdc++.h>
using namespace std;

int qry(int l, int r, bool rev = 0, int n = 0) {
    if (rev) {
        int t = n - l;
        l = n - r;
        r = t;
    }
    cout << "? " << l + 1 << ' ' << r << endl;
    cin >> r;
    return r;
}

void solve() {
    int n;
    cin >> n;
    int a = qry(0, n / 4);
    int b = qry(n / 4, n / 2);
    bool kSmall = 1;
    bool firstHalf = 1;
    if (a == b) firstHalf = 0;
    int bs = 0;
    if (qry(0, n / 2, firstHalf, n) == 0) kSmall = 0;
    if (kSmall) {
        for (int k = n / 4; k; k /= 2)
            if (qry(0, bs + k, firstHalf, n) == 0) bs += k;
    } else {
        bs = n / 2 - 1;
        for (int k = n / 4; k; k /= 2)
            if (qry(0, bs + k, 1-firstHalf, n) == 1) bs += k;
    }
    cout << "! " << bs + 1 << endl;
}

int main() {
    int T = 1;
    cin >> T;
    while (T--) solve();
    return 0;
}
2049F - MEX OR ManiaLet's figure out when a sequence is good. Let m be the maximum element of the sequence. Notice that the bitwise OR of the sequence is at least m and as MEX − OR =1, that means MEX has to be at least m+1. Which means all elements from 0 to m has to be present in the sequence. As MEX can't be greater than m+1, the MEX has to be exactly m+1.Now we need to check for which m the bitwise OR of the elements from 0 to m is exactly m. It's not hard to see that this is true for m=2k−1 for some integer k≥0. The reason is that all bits from 0 to k−1 have to be set in m for the OR to be m and it's only possible if m is of the form 2k−1.So, a sequence is good if the maximum element is m=2k−1 for some integer k and all elements from 0 to m are present in the sequence.Now, let's see how to answer the queries without any updates. To find the longest good subarray, we can use a two-pointers approach. But a better way to do this is to fix the power k(0≤k≤log2n) and find the longest good subarray with maximum element 2k−1. To do this, ignore the elements greater than 2k−1 and then split the array into segments of consecutive numbers where each segment has elements from 0 to 2k−1. To check if a segment is good, we can track the number of distinct elements in the segment. If the number of distinct elements is 2k, then the segment is good.So to sum it up, for each power k, we will track some segments/components and the number of distinct elements in them and also the lengths of the segments to get the longest one during queries.Now regarding the updates, it is hard to track everything if we do the updates normally. But its's easier if we look at them in reverse order!Then each update will be decreasing the value of ai by x. Then for each power k, we will have to add a new element to a component or merge two components. For tracking distinct elements, we can use a map or unordered map and to merge we can use DSU with small to large merging. And that's pretty much it.Please check my code for more details.Overall complexity is O((n+q)log2n) or O((n+q)log3n) depending on if you use an unordered map or a map.
#include<bits/stdc++.h>
using namespace std;
 
const int N = 1e5 + 9, Q = 3e5 + 9;
using ll = long long;
 
struct GoodSet { // insert, erase and track distinct and total elements
  map<int, int> mp;
  int size;
  int k;
  GoodSet() {}
  GoodSet(int _k): k(_k), size(0) { };
  void insert(int x, int c = 1) {
    mp[x] += c;
    size += c;
  }
  void erase(int x) {
    if (mp[x] == 1) {
      mp.erase(x);
    }
    else {
      mp[x]--;
    }
    size -= 1;
  }
  void merge(GoodSet oth) {
    for (auto [x, c]: oth.mp) {
      insert(x, c);
    }
  }
  bool is_good() { // check if all elements from 0 to 2^k - 1 exists in the set
    return (int) mp.size() == (1 << k);
  }
  int get_value() {
    if (is_good()) return size;
    return 0;
  }
};
 
struct MaxSet { // insert, erase and track max element
  map<int, int> mp;
  MaxSet() {}
  void insert(int x) {
    mp[x]++;
  }
  void erase(int x) {
    mp[x]--;
    if (mp[x] == 0) mp.erase(x);
  }
  int get_max() {
    return mp.rbegin() -> first;
  }
};
 
struct DSU { // DSU for each power of 2
  int n;
  int k;
  vector<int> par;
  vector<GoodSet> comp;
  MaxSet good_lengths;
  DSU() {}
  DSU(int _n, int _k): n(_n), k(_k) {
    par.resize(n + 1);
    comp.resize(n + 1);
    for (int i = 1; i <= n; i++) {
      par[i] = i;
      comp[i] = GoodSet(k);
      good_lengths.insert(comp[i].get_value());
    }
  }
  int find(int u) {
    return par[u] = (par[u] == u ? u : find(par[u]));
  }
  void merge(int u, int v) {
    u = find(u); v = find(v);
    if (u == v) return;
    good_lengths.erase(comp[u].get_value());
    good_lengths.erase(comp[v].get_value());
 
    // small to large merging
    if (comp[u].mp.size() < comp[v].mp.size()) {
      comp[u].mp.swap(comp[v].mp);
      swap(comp[u].size, comp[v].size);
    }
    comp[u].merge(comp[v]);
    comp[v].mp.clear(); // clear to save up memory
 
    good_lengths.insert(comp[u].get_value());
    par[v] = u;
  }
  // insert or erase an element from the component that u belongs to
  void update_in_component(int u, int x, bool insert = true) {
    u = find(u);
    good_lengths.erase(comp[u].get_value());
    if (insert) comp[u].insert(x);
    else comp[u].erase(x);
    good_lengths.insert(comp[u].get_value());
  }
};
DSU f[18];
ll a[N]; // make it long long as total sum can be huge
int id[Q], x[Q], ans[Q];
void solve() {
  int n, q; cin >> n >> q;
  for (int i = 1; i <= n; i++) {
    cin >> a[i];
  }
  for (int i = 1; i <= q; i++) {
    cin >> id[i] >> x[i];
    a[id[i]] += x[i];
  }
  MaxSet se;
  for (int k = 0; (1 << k) <= n; k++) {
    f[k] = DSU(n, k);
    for (int i = 1; i <= n; i++) {
      if (a[i] < (1 << k)) {
        f[k].update_in_component(i, a[i], true);
      }
    }
    for (int i = 2; i <= n; i++) {
      if (a[i] < (1 << k) and a[i - 1] < (1 << k)) {
        f[k].merge(i - 1, i);
      }
    }
    se.insert(f[k].good_lengths.get_max());
  }
  for (int qid = q; qid >= 1; qid--) {
    ans[qid] = se.get_max();
    int i = id[qid], sub = x[qid];
    for (int k = 0; (1 << k) <= n; k++) {
      se.erase(f[k].good_lengths.get_max());
 
      if (a[i] < (1 << k)) f[k].update_in_component(i, a[i], false);
      if (a[i] - sub < (1 << k)) f[k].update_in_component(i, a[i] - sub, true);
 
      if (a[i] >= (1 << k) and a[i] - sub < (1 << k)) {
        if (i > 1 and a[i - 1] < (1 << k)) {
          f[k].merge(i - 1, i);
        }
        if (i + 1 <= n and a[i + 1] < (1 << k)) {
          f[k].merge(i, i + 1);
        }
      }
 
      se.insert(f[k].good_lengths.get_max());
    }
    a[i] -= sub;
  }
 
  for (int i = 1; i <= q; i++) {
    cout << ans[i] << '\n';
  }
}
 
int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
#include <bits/stdc++.h>
using namespace std;

typedef long long ll;
const ll INF = 1e18; 

void print_dp(vector<vector<vector<ll>>>& dp) {
    for (int i = 0; i < dp.size(); i++) {
        cout << "i = " << i << ":\n";
        for (int j = 0; j < dp[i].size(); j++) {
            cout << "j = " << j << ": ";
            for (int x = 0; x < dp[i][j].size(); x++) {
                cout << dp[i][j][x] << " ";
            }
            cout << endl;
        }
        cout << endl;
    }
}

void solve() {
    ll n, m, k;
    cin >> n >> m >> k;
    vector<vector<ll>> a(n, vector<ll>(m));
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < m; j++) {
            cin >> a[i][j];
        }
    }

    vector<vector<vector<ll>>> dp(n, vector<vector<ll>>(m, vector<ll>(m, INF)));
    // dp[i][j][x] = min cost from (i,j) to (n-1,m-1) if x ops performed on row i

    // base case
    for (int x = 0; x < m; x++) {
        dp[n - 1][m - 1][x] = a[n - 1][(m - 1 + x) % m] + k * x;
    }

    // transition
    for (int i = n - 1; i >= 0; i--) {
        for (int j = m - 1; j >= 0; j--) {
            if (i == n - 1 && j == m - 1) continue;
            for (int x = 0; x < m; x++) {
                ll right = INF, down = INF;

                // right
                if (((j + x) % m) + 1 < m) {
                    right = dp[i][(j + x) % m + 1][x];
                }

                // down
                if (i + 1 < n) {
                    for (int x2 = 0; x2 < m; x2++) {
                        down = min(down, dp[i + 1][j][x2]);
                    }
                }
                // TODO: Optimize min value using another array

                dp[i][j][x] = a[i][(j + x) % m] + min(right, down) + k * x;

                dp[i][j][x] = min(dp[i][j][x], INF);
            }
        }
    }

    ll result = INF;
    for (int x = 0; x < m; x++) {
        result = min(result, dp[0][0][x]);
    }

    // print_dp(dp);

    cout << result << endl;
}

int main() {
    ios::sync_with_stdio(0);
    cin.tie(0);
    cout.tie(0);
    int t;
    cin >> t;
    while (t--) {
        solve();
    }
    return 0;
}
Spoiler exists.
Firstly, for complex equation which means nothing at first look, we do this deduction :  For a subarray, let MEX = A, then we know all elements from 0 to A-1 should be present. OR of subarray will therefore be >= A-1 For OR to be exactly A-1, A-1 should not have any unset bits otherwise OR from 0 to A-1 will exceed A-1. Thus A-1 should be equal to (2^k — 1) for some k. Thus, the MEX should always be equal to 2^k for some k. Note that the MEX of an array for size N can never be more than N. Thus, the only powers for 2 that interests us are from 2^0 to 2^16. Solve for each power of 2 individually. 
 Now consider that MEX is 2^k, find all subarrays in the array which have values strictly between 0 and 2^k — 1. These subarrays are possible candidates for answer. We will call this a Range. You can do this using 2-pointers. Corresponding to each Range, store a freq map. If the size of this freq map is 2^k, all elements from 0 to 2^k — 1 lie and the MEX is 2^k, store this as potential answer. Do this for all values of k from 0 to 16 to create a set of Ranges at each level and store all potential answers in a multiset. 
Handling updates requires a major observation.The values of a particular element will only increase. This means that the ranges we calculated in the 2nd part can only be broken down into smaller pieces. They can not merge, or increase in size.This observation leads to a simple idea :We stored a freq map corresponding to each Range in 2nd part, we will use that here :  If the new value doesn't break the range (i.e becomes >= 2^k), update the freq map and check if the new map constitutes an answer. If the new value does break the range, brute force on the smaller part of the broken range to create a new freq map. Split the range into essentially two ranges with their own freq maps. I spent hours trying to step 3 thinking this will give me linear complexity before realizing the combined splits on a level will always result in nlogn complexity across queries.


[Editorial - contest/2048]
No editorial content found.


[Editorial - contest/2044]
For any n, Cube can set a = any integer between 1 and n-1 inclusive, and set b = n - a. a cannot be less than 1, because then it would be non-positive, and a cannot be greater than n-1, because then b would be less than 1, which would make it non-positive. Therefore the answer is just n-1 for all n.
input = sys.stdin.readline
for _ in range(int(input())):
    print(int(input())-1)
The letters she reads that comprise string b are just the letters that comprise string a, flipped left-to-right. This means that 'p' becomes 'q', 'q' becomes 'p', and 'w' stays 'w', since it is vertically symmetrical. The order in which the letters are read is also reversed, because what used to be the left side of string a gets flipped over to the right side of string b, and vice versa.We now have an algorithm for constructing string b, which is to iterate from right-to-left on string a, outputting 'p' when there is a 'q', 'q' when there is a 'p', and 'w' when there is a 'w'.
#include <bits/stdc++.h>
using namespace std;
#define ll long long
#define pll pair<ll, ll>

int t;

int main() {
	cin.tie(0)->sync_with_stdio(0);
	cin >> t;
	while (t--) {
		string s;
		cin >> s;
		reverse(s.begin(), s.end());
		for (char &c : s) if (c == 'q') c = 'p'; else if (c == 'p') c = 'q';
		cout << s << '\n';
	}
}
Let A, B, C be three sets of monkeys, such that monkeys in A can only sit in row 1, B in row 2, and C can sit anywhere. It is clear that if there is free space in row 1, and there are monkeys left in set A, it is optimal to seat a monkey from set A onto row 1. This is because a monkey from set C can be seated on either row, and there might be space left on the other row for that same monkey in set C after you've already seated the monkey from set A. However, this is not the case if you start by seating the monkeys in set C in the front row, since you might now leave empty seats at the back, but then have monkeys from set A still left unseated.Therefore, the strategy is as follows: seat as many monkeys from set A as you can in the front row, then seat as many monkeys from set B as you can in the back row, then seat as many monkeys from set C as you can, and that yields the answer.
#include<bits/stdc++.h>
#define ll long long
using namespace std;


int main()
{
    ios::sync_with_stdio(false);
    cin.tie(nullptr);
    int tt;
    cin>>tt;
    while(tt--)
    {
        int m,a,b,c;
        cin>>m>>a>>b>>c;
        int ans=0,rem=0;
        ans+=min(m,a);rem+=m-min(m,a);
        ans+=min(m,b);rem+=m-min(m,b);
        ans+=min(rem,c);
        cout<<ans<<'\n';
    }
    return 0;
}
Observe that if you have an array where all elements are unique, they will all have frequency 1, therefore they can all be classified as the mode. Therefore, it follows that the strategy for the construction is to just construct an array where for each prefix, the last element of this prefix appears in the array at least once. An easy way of doing is this is such:For each element a_i, if this value has appeared previously in the array (you can use a set to check this), set b_i equal to some random integer that isn't used elsewhere in the list a, and keep going. Otherwise, set b_i = a_i.
#include<bits/stdc++.h>
#define ll long long
using namespace std;


int main()
{
    ios::sync_with_stdio(false);
    cin.tie(nullptr);
    int tt;
    cin>>tt;
    while(tt--)
    {
        int n;
        cin>>n;
        vector<int> a(n+1),b(n);
        for(int i=0;i<n;i++)
        {
            int x;
            cin>>x;
            if(!a[x])
            {
                b[i]=x;
                a[x]=1;
            }
        }
        queue<int> q;
        for(int i=1;i<=n;i++)
            if(!a[i])
                q.push(i);
        for(int i=0;i<n;i++)
        {
            if(!b[i])
            {
                b[i]=q.front();
                q.pop();
            }
        }
        for(int i=0;i<n;i++)
            cout<<b[i]<<" \n"[i==n-1];
    }
    return 0;
}
Clearly, trying to bruteforce over all possible values of x or y is too slow, because the bounds are 1 ≤ l_1 ≤ r_1 ≤ 10^9. However, there is another variable that you can actually bruteforce over — and that is n. This is because exponentiation famously makes numbers very big very quickly — and if we set k as small as possible (i.e. 2), we only need to check 1 ≤ n ≤ 32. This is because 2^{32} > 10^9, so there cannot possibly be any solutions for n > 32 for any k.Now, let's rephrase the problem. We need to find pairs (x, y) such that x cdot k^n = y. Now, we can check every value of n from 1 to 32, and for each, binary search to find the smallest x such that y fits the conditions, and the largest x. Now, we can subtract these two values and add this to the answer.
Note that we do not need to care about more than 32 different values of k^n, because obviously k^{32} ge 2^{32} > 10^9. From here and on, we focus on solving for only one value of k^n.When k^n is fixed and you are given frac{y}{x}=k^n, notice y is fixed as x k^n. Therefore, if we count the values x such that y is in the given interval as well, we will be properly counting the ordered pairs.Formally, this condition can be cleared out as:  l_2 le x k^n le r_2 frac{l_2}{k^n} le x le frac{r_2}{k^n} Because x is an integer, left lceil {frac{l_2}{k^n}} right rceil le x le left lfloor {frac{r_2}{k^n}} right rfloor Thus, when we intersect the two intervals, we get the following interval at last. max left({l_1,left lceil {frac{l_2}{k^n}} right rceil}right) le x le min left({r_1,left lfloor {frac{r_2}{k^n}} right rfloor}right)Compute the size of this interval for all k^n (at most 32 values) and the answer can be found.Do note the following details while implementing:  When r < l, the size of the interval is 0, not negative. Beware of overflows. Dealing with big integers can be helpful in avoiding this, but it may make your solution slow. Do not round up a fraction using the ceil function; This has been a recurring issue in almost every Div.4! 
#include<bits/stdc++.h>
#define ll long long
using namespace std;


int main()
{
    ios::sync_with_stdio(false);
    cin.tie(nullptr);
    int tt;
    cin>>tt;
    while(tt--)
    {
        ll k,l1,r1,l2,r2;
        cin>>k>>l1>>r1>>l2>>r2;
        ll kn=1,ans=0;
        for(int n=0;r2/kn>=l1;n++)
        {
            ans+=max(0ll,min(r2/kn,r1)-max((l2-1)/kn+1,l1)+1ll);
            kn*=k;
        }
        cout<<ans<<'\n';
    }
    return 0;
}
This is an anti-hash test for python sets and dictionaries. Before you call us evil, we saved you from getting hacked in open hack phase. Beware!
Let's denote the beauty of the matrix as B, and denote text{SumA} as the sum of all the elements in the array a, and text{SumB} as the sum of all the elements in the array b.Before applying an operation, the beauty of the matrix can be expressed as:B = b_1 cdot a_1 + b_1 cdot a_2 + b_1 cdot a_3 + b_2 cdot a_1 + b_2 cdot a_2 + ldotsAfter factoring, this simplifies to: B = b_1 cdot (a_1 + a_2 + a_3 + ldots) + b_2 cdot (a_1 + a_2 + a_3 + ldots) + ldots Further factoring gives: B = (a_1 + a_2 + a_3 + a_4 + ldots) cdot (b_1 + b_2 + b_3 + ldots) This can be written as: B = text{SumA} cdot text{SumB}Now, consider the effect of an operation on a column C. The beauty decreases by A_c cdot text{SumB}. Similarly, when an operation is done on a row R, the beauty decreases by B_r cdot text{SumA}.An important observation is that the element at position (r, c) is counted twice, so we must account for this in the formula.After considering this, let the beauty after the operations be denoted as X. Using the observations above:X = B - (b_i cdot text{SumA} + a_j cdot text{SumB} - a_j cdot b_i)Simplifying further:X = text{SumA} cdot text{SumB} - b_i cdot text{SumA} - a_j cdot text{SumB} + a_j cdot b_iFactoring terms, we obtain:X = text{SumA} cdot (text{SumB} - b_i) - a_j cdot (text{SumB} - b_i)Finally:X = (text{SumB} - b_i) cdot (text{SumA} - a_j)At this stage, it is sufficient to iterate over the divisors of X. For each ordered pair of divisors whose product is X, we check whether the required values of text{SumB} - b_i and text{SumA} - a_j can be achieved.This can be implemented using a simple map or boolean vector for faster computation, although such optimization is not required for this problem.
#include <bits/stdc++.h>
using namespace std;
#define FOR(i,a,b) for (int i = (a); i < (b); ++i)
#define F0R(i,a) FOR(i,0,a)
#define int long long
#define vt vector
#define endl "\n"

const int N = 4e5 + 5;
bool apos[N], aneg[N], bpos[N], bneg[N], posspos[N], possneg[N];

signed main() {
    ios_base::sync_with_stdio(false); 
    cin.tie(0);
    int n,m,q;
    cin >> n >> m >> q;
    vector<int> a(n), b(m);
    int asum = 0, bsum = 0;
    F0R(i, n) {
        cin >> a[i];
        asum += a[i];
    }
    F0R(i, m) {
        cin >> b[i];
        bsum += b[i];
    }
    F0R(i, n) {
        if(abs(asum-a[i]) < N) {
            if(asum-a[i]<0) aneg[a[i]-asum]=true;   
            else apos[asum-a[i]]=true;
        } 
    }
    F0R(i, m) {
        if(abs(bsum-b[i]) < N) {
            if(bsum-b[i]<0) bneg[b[i]-bsum]=true;   
            else bpos[bsum-b[i]]=true;
        } 
    }
    FOR(i, 1, N) {
        FOR(j, 1, N) {
            if(i * j > N) break;
            if(apos[i]&&bpos[j]) posspos[i*j]=true;
            if(apos[i]&&bneg[j]) possneg[i*j]=true;
            if(aneg[i]&&bpos[j]) possneg[i*j]=true;
            if(aneg[i]&&bneg[j]) posspos[i*j]=true;
        }
    }
    while(q--) {
        int x;
        cin >> x;
        if(x>0) {
            if(posspos[x]) {
                cout << "YES" << endl;
            } else {
                cout << "NO" << endl;
            }
        } else {
            if(possneg[-x]) {
                cout << "YES" << endl;
            } else {
                cout << "NO" << endl;
            }
        }
    }
    return 0;
}
This problem deals with a specific subclass of graphs called "functional graphs", also known as "successor graphs". The key feature that they have is that each node only has one successor. Therefore, the graph in the problem will necessarily be split into k ≥ 1 components, where each component necessarily contains one cycle, and each node will either be in the cycle, or it will be on a path leading towards the cycle.Observe that if a node that is not on a cycle currently has a plushie, this plushie will cause the arrangement to be unstable until the plushie reaches the cycle. Proof: suppose node u has the plushie on day i. On the next day, u will no longer have this plushie, because they will have passed it down to r_u, therefore, the arrangement has changed. This continues inductively until the plushie reaches the cycle of its component.From this, we know that the answer is at least the distance of any node to the cycle. Now, since every node in the cycle already has a plushie, we know that these plushies just get passed round and round, so actually, nodes within the cycle cannot change the answer. Therefore, we've already found the final answer. 
#include<bits/stdc++.h>
#define ll long long
using namespace std;


int main()
{
    ios::sync_with_stdio(false);
    cin.tie(nullptr);
    int tt;
    cin>>tt;
    while(tt--)
    {
        int n;
        cin>>n;
        vector<int> r(n+1),d(n+1);
        for(int i=1;i<=n;i++)
        {
            cin>>r[i];
            d[r[i]]++;
        }
        set<pair<int,int> > s;
        for(int i=1;i<=n;i++)
            s.insert({d[i],i});
        int ans=2;
        queue<int> q;
        while(!s.empty()&&(*s.begin()).first==0)
        {
            while(!s.empty()&&(*s.begin()).first==0)
            {
                int k=(*s.begin()).second;
                auto it=s.find({d[r[k]],r[k]});
                d[r[k]]--;
                if(it!=s.end())
                {
                    s.erase(it);
                    q.push(r[k]);
                }
                s.erase(s.begin());
            }
            while(!q.empty())
                s.insert({d[q.front()],q.front()}),q.pop();
            ans++;
        }
        cout<<ans<<'\n';
    }
    return 0;
}
Note that similarly to G1, once all plushies end up in the hands of spiders who are in a loop, the process becomes stable. Let's model the input as a collection of rooted forests. For each spider i, if i is part of a loop, then let's compress the loop into a single node and use that as the root of a tree. Otherwise, if spider i gives a present to spider r_i, then let's draw an edge from i to r_i. Now, let i be any node that is not part of a loop. How long will it take until spider i runs out of presents? We can see that it is the subtree size of i, as one present leaves the subtree each year.Thus, our challenge now is to process the nodes in an efficient order such that we can find the subtree size of all nodes. This can be done with topological sorting, which gives us an order that processes all nodes starting from the leaf upwards. After the topological sort, we may do dynamic programming to find subtree sizes of all nodes. Let dp[i] be the number of days until spider i runs out of presents. Let's suppose that we already calculated dp[i] (we initialize it to be 1 for all nodes since each spider starts with a present). Then, we should add dp[i] to dp[r_i]. Doing this and adding up all dp values of nodes directly before a cycle will yield the answer. 
#include<bits/stdc++.h>
#define ll long long
using namespace std;


int main()
{
    ios::sync_with_stdio(false);
    cin.tie(nullptr);
    int tt;
    cin>>tt;
    while(tt--)
    {
        int n;
        cin>>n;
        vector<int> r(n+1),d(n+1),v(n+1,1);
        for(int i=1;i<=n;i++)
        {
            cin>>r[i];
            d[r[i]]++;
        }
        set<pair<int,int> > s;
        for(int i=1;i<=n;i++)
        {
            s.insert({d[i],i});
        }
        int ans=2;
        queue<int> q;
        while(!s.empty()&&(*s.begin()).first==0)
        {
            while(!s.empty()&&(*s.begin()).first==0)
            {
                int k=(*s.begin()).second;
                ans=max(ans,v[k]+2);v[r[k]]+=v[k];
                auto it=s.find({d[r[k]],r[k]});
                d[r[k]]--;
                if(it!=s.end())
                {
                    s.erase(it);
                    q.push(r[k]);
                }
                s.erase(s.begin());
            }
            while(!q.empty())
                s.insert({d[q.front()],q.front()}),q.pop();
        }
        cout<<ans<<'\n';
    }
    return 0;
}
Consider translating the sum back onto the matrix. For simplicity we discuss about querying the whole matrix.The sum we would like to find is sum_i icdot A_i. Here, A_i corresponds to M_{(x,y)}, so we will translate this to sum_{x,y} icdot M_{(x,y)}. The issue left is on the i multiplied to it.Remember that we index the entries in increasing order of y, and then increasing order of x. Assuming y and x were 0-indexed, this will mean entry (x,y) corresponds to xcdot n + y (also 0-indexed). You can notice that this naturally corresponds to the order we had defined as well.Then, what we want to find is sum_{x,y} (x cdot n + y + 1)cdot M_{(x,y)}. Notice x cdot n, y, 1 are independent, and we can split them into sums sum_x x cdot n cdot M_{(x,y)}, sum_y y cdot M_{(x,y)}, sum M_{(x,y)}. Each of these three sums can be precomputed entry by entry, and a 2D prefix sum can solve the answer for the entire matrix.The query for a submatrix is very similar. Formally, you have to care about:  That we have y_2-y_1+1 columns instead of n now; That the precomputed values might not start from 0 on the first row/column of the query. Still, these two issues can be fixed using the three sums we have precomputed. The time complexity becomes mathcal{O}(n^2+q).
#include <bits/stdc++.h>
using namespace std;
using ll = long long;
using vll = vector <ll>;
using ii = pair <ll, ll>;
using vii = vector <ii>;

void tc () {
    ll n, Q;
    cin >> n >> Q;
    vector <vll> mat(n, vll(n));
    for (vll &ve : mat) {
        for (ll &i : ve) cin >> i;
    }
    vector <vll> psR(n, vll(n+1)), psRr(n, vll(n+1)), psRc(n+1, vll(n+1)), ps(n+1, vll(n+1)), psRrc(n+1, vll(n+1));
    for (ll i = 0; i < n; i++) {
        for (ll j = 0; j < n; j++) {
            psR[i][j+1] = psR[i][j] + mat[i][j];
        }
    }
    for (ll i = 0; i < n; i++) {
        for (ll j = 0; j < n; j++) {
            psRr[i][j+1] = psRr[i][j] + mat[i][j]*(j+1);
        }
    }
    for (ll i = 0; i < n; i++) {
        for (ll j = 0; j <= n; j++) {
            psRc[i+1][j] = psRc[i][j] + psR[i][j]*(i+1);
        }
    }
    for (ll i = 0; i < n; i++) {
        for (ll j = 0; j <= n; j++) {
            psRrc[i+1][j] = psRrc[i][j] + psRr[i][j];
        }
    }
    for (ll i = 0; i < n; i++) {
        for (ll j = 0; j <= n; j++) {
            ps[i+1][j] = ps[i][j] + psR[i][j];
        }
    }
    while (Q--) {
        ll x1, y1, x2, y2;
        cin >> x1 >> y1 >> x2 >> y2;
        x1--; y1--; x2--; y2--;
        ll ans = 0;
        ans += -(ps[x2+1][y2+1]-ps[x2+1][y1]-ps[x1][y2+1]+ps[x1][y1])*x1*(y2-y1+1);
        ans += (psRc[x2+1][y2+1] - psRc[x1][y2+1] - (ps[x2+1][y2+1]-ps[x1][y2+1]))*(y2-y1+1);

        ans += (psRc[x2+1][y1] - psRc[x1][y1] - (ps[x2+1][y1]-ps[x1][y1]))*-(y2-y1+1);
        ans += (ps[x2+1][y2+1]-ps[x1][y2+1])*-y1;
        ans += (ps[x2+1][y1]-ps[x1][y1])*y1;

        ans += psRrc[x2+1][y2+1] - psRrc[x1][y2+1];
        ans +=-(psRrc[x2+1][y1] - psRrc[x1][y1]);
        cout << ans << ' ';
    }
    cout << '\n';
}

int main () {
    cin.tie(nullptr) -> sync_with_stdio(false);
    ll T; cin >> T; while (T--) { tc(); }
    return 0;
}
1
5 1 2 6 9
We want to find Sigma_{x,y}((x-x_1)cdot w + (y-y_1) + 1)cdot M_{(x,y)} where w is the width of the submatrix. Note that x, y, x_1, y_1 are all 0-indexed.
// First I find the range hi and lo instead of iterating 1 to 31. Even with using 1 to 31 it gives the same wrong answer.

int cal(int cur, int R, int L, int x) {
    int cnt = 0;
    while (cur <= R) {
        if (cur >= L) {
            cnt += 1;
        }
        cur *= x;
    }
    return cnt;
}
void solve() {
    int x, l, r, L, R;
    cin >> x >> l >> r >> L >> R;
    if (R < l) {
        cout << 0 << "\n";
        return;
    }
    int cur = l, cnt = 0;
    while (cur <= R) {
        if (cur >= L){
            cnt += 1;
        }
        cur *= x;
    }
    int hi = cnt;
    cur = r, cnt = 0;
    while (cur <= R) {
        if (cur >= L) {
            cnt += 1;
        }
        cur *= x;
    }
    int lo = cnt;
    int ans = 0;
    for (int i = lo; i <= hi; i++) {
        int left = l, right = r;
        while (left <= right) {
            int m = (left + right) / 2;
            if (cal(m, R, L, x) <= i) {
                right = m - 1;
            } else if (cal(m, R, L, x) > i) {
                left = m + 1;
            } 
        }
        int ll = left;
        left = l, right = r;
        while (left <= right) {
            int m = (left + right) / 2;
            if (cal(m, R, L, x) < i) {
                right = m - 1;
            } else if (cal(m, R, L, x) >= i) {
                left = m + 1;
            } 
        }
        int rr = right;
        ans += i * (rr - ll + 1);
    }
    cout << ans << "\n";
}
import java.util.*;

public class Main {

    static class UnionFind {
        int par[];
        int size[];
 
        UnionFind(int n) {
            par = new int[n];
            size = new int[n];
 
            for (int i = 0; i < n; i++) {
                par[i] = i;
                size[i] = 1;
            }
        }
 
        int find(int val) {
            if (par[val] == val) {
                return val;
            }
            return par[val] = find(par[val]);
        }
 
        boolean union(int a, int b) {
            int pa = find(a);
            int pb = find(b);
 
            if (pa == pb) return false;
 
            if (size[pa] > size[pb]) {
                return union(b, a);
            }
 
            par[pa] = pb;
            size[pb] += size[pa];
 
            return true;
        }
    }


    static UnionFind uf;
    static List<Integer> cycleSeeds;
    static List<List<Integer>> rev;
    static int depth[];
    static int cycle[];
    static int vis[];
    static int compID[];


    public static void main(String[] args) {
        Scanner sc = new Scanner(System.in);

        int t = sc.nextInt(); 
        StringBuilder result = new StringBuilder();

        while (t-- > 0) {
            int n = sc.nextInt(); 

            uf = new UnionFind(n + 1);
            int[] recipients = new int[n + 1];
            depth = new int[n + 1];
            cycle = new int[n + 1];
            vis = new int[n + 1];
            compID = new int[n + 1];

            
            rev = new ArrayList<>();
            cycleSeeds = new ArrayList<>();


            for(int i = 0; i <= n; i++) rev.add(new ArrayList<>());

            for (int i = 1; i <= n; i++) {
                recipients[i] = sc.nextInt();
                rev.get(recipients[i]).add(i);
                if (!uf.union(i, recipients[i])) {
                    cycleSeeds.add(i);
                }

            }

            int currComp = 0;
            for (int i : cycleSeeds) {
                if (vis[i] == 0) {
                    dfs(i, currComp);
                    currComp++;
                }
            }

            vis = new int[n + 1];

            int maxPathLength = 2;

            for(int i = 1; i <= n; i++) {
                if(vis[i] == 0 && cycle[i] == 0) {
                    int len = dfs2(i, recipients);
                    maxPathLength = Math.max(maxPathLength, len + 2);
                }
            }


            result.append(maxPathLength).append("\n");
        }

        System.out.print(result);
    }

    public static int dfs2(int node, int [] recipients) {
        vis[node] = 1;
 
        int child = recipients[node];
        int len = 1;
        if (cycle[child] == 0) {
            len += dfs2(child, recipients);
        }
        return len;
    }

    public static void dfs(int node, int currComp) {
        vis[node] = 1;
        compID[node] = currComp;
 
        for (int child : rev.get(node)) {
            if (vis[child] == 0) {
                depth[child] = depth[node] + 1;
                dfs(child, currComp);
            } else {
                cycle[child] = depth[node] + 1;
            }
            cycle[node] = Math.max(cycle[node], cycle[child]);
        }
    }

}
#include <iostream>
#include <vector>
#include <algorithm>
using namespace std;

class UnionFind {
public:
    vector<int> par, size;

    UnionFind(int n) {
        par.resize(n);
        size.resize(n, 1);
        for (int i = 0; i < n; i++) {
            par[i] = i;
        }
    }

    int find(int val) {
        if (par[val] == val) return val;
        return par[val] = find(par[val]);
    }

    bool unionSets(int a, int b) {
        int pa = find(a);
        int pb = find(b);

        if (pa == pb) return false;

        if (size[pa] > size[pb]) {
            swap(pa, pb);
        }

        par[pa] = pb;
        size[pb] += size[pa];

        return true;
    }
};

UnionFind* uf;
vector<int> cycleSeeds;
vector<vector<int>> rev;
vector<int> depth, cycle, vis, compID;

void dfs(int node, int currComp) {
    vis[node] = 1;
    compID[node] = currComp;

    for (int child : rev[node]) {
        if (vis[child] == 0) {
            depth[child] = depth[node] + 1;
            dfs(child, currComp);
        } else {
            cycle[child] = depth[node] + 1;
        }
        cycle[node] = max(cycle[node], cycle[child]);
    }
}

int dfs2(int node, const vector<int>& recipients) {
    vis[node] = 1;

    int child = recipients[node];
    int len = 1;
    if (cycle[child] == 0) {
        len += dfs2(child, recipients);
    }
    return len;
}

int main() {
    int t;
    cin >> t;

    while (t-- > 0) {
        int n;
        cin >> n;

        uf = new UnionFind(n + 1);
        vector<int> recipients(n + 1);
        depth.assign(n + 1, 0);
        cycle.assign(n + 1, 0);
        vis.assign(n + 1, 0);
        compID.assign(n + 1, 0);

        rev.assign(n + 1, vector<int>());
        cycleSeeds.clear();

        for (int i = 1; i <= n; i++) {
            cin >> recipients[i];
            rev[recipients[i]].push_back(i);
            if (!uf->unionSets(i, recipients[i])) {
                cycleSeeds.push_back(i);
            }
        }

        int currComp = 0;
        for (int i : cycleSeeds) {
            if (vis[i] == 0) {
                dfs(i, currComp);
                currComp++;
            }
        }

        vis.assign(n + 1, 0);

        int maxPathLength = 2;
        for (int i = 1; i <= n; i++) {
            if (vis[i] == 0 && cycle[i] == 0) {
                int len = dfs2(i, recipients);
                maxPathLength = max(maxPathLength, len + 2);
            }
        }

        cout << maxPathLength << "\n";
    }

    return 0;
}



[Editorial - contest/2052]
No editorial content found.


[Editorial - contest/2040]
2040A - Game of Division|x−y| is divisible by k if and only if xmodk=ymodk. Let's split all numbers into groups according to the value xmodk. The second player wins if he chooses a number from the same group. This means that the first player must choose the number that is the only one in its group.
#include <bits/stdc++.h>
 
using namespace std;
 
int main() {
    int tt;
    cin >> tt;
    while (tt--) {
        int n, k;
        cin >> n >> k;
        vector < vector <int> > b(k);
        for (int i = 1; i <= n; i++) {
            int x;
            cin >> x;
            b[x % k].push_back(i);
        }
        int res = -1;
        for (int i = 0; i < k; i++) {
            if ((int)b[i].size() == 1) {
                res = b[i][0];
                break;
            }
        }
        if (res == -1) {
            cout << "NO" << endl;
        }
        else {
            cout << "YES" << endl << res << endl;
        }
    }
    
    return 0;
}
for _ in range(int(input())):
    n, k = map(int, input().split())
    a = list(map(int, input().split()))
    b = [[] for _ in range(k)]
    for i in range(0, n):
        x = a[i]
        b[x % k].append(i + 1)
    res = -1
    for i in range(k):
        if len(b[i]) == 1:
            res = b[i][0]
            break
    if res == -1:
        print("NO")
    else:
        print("YES\n" + str(res))
2040B - Paint a StripAt each moment of time, the array contains a number of non-intersecting segments consisting only of ones. Using an operation of the first type can increase the number of these segments by 1. Using an operation of the second type decreases the number of these segments by x−1, where x — is the number of segments that this operation covers. Therefore, the number of operations of the second type is no more than the number of operations of the first type minus 1.The optimal strategy — is to perform one operation of the first type, and then alternate operations of the first and second types, increasing the number of ones from x to 2⋅(x+1) on each such pair of operations. There is no point in doing more operations of the first type on the prefix of operations, since we still must cover no more than two segments of ones with operations of the second type; otherwise, we will reduce the possible number of operations of the second type.
#include <bits/stdc++.h>
 
using namespace std;
 
int main() {
    int tt;
    cin >> tt;
    while (tt--) {
        int n;
        cin >> n;
        for (int ans = 1, cur = 1; ; ans++, cur = cur * 2 + 2) {
            if (cur >= n) {
                cout << ans << '\n';
                break;
            }
        }
    }
    
    return 0;
}
tt = int(input())
for _ in range(tt):
    n = int(input())
    ans = 1
    cur = 1
    while True:
        if cur >= n:
            print(ans)
            break
        ans += 1
        cur = cur * 2 + 2
At some point in the development of this problem, the following alternative statement appeared: we need to minimize the total number of operations of both types. How to solve this problem?
2040C - Ordered PermutationsThese permutations are generated as follows. We will greedily go through the numbers in order from 1 to n, and we will put each one either in the first free cell or in the last one. For example, if we want to put 4 in the permutation 1,3,∘,∘,…,∘,2, we can put it either in the third cell or in the second from the end. That is, the permutation first increases and then decreases.We can prove that the greedy algorithm works like this. Let us now want to put the number i. When we put this number, we can immediately say that the minimum on the segments, one of the ends of which is the chosen position, is equal to i (we do not take into account already placed numbers smaller than i). The number of these segments is equal to n−i+1. The answer we get is equal to the sum of this fixed number and what we get in the future. Assume we put the number i not at the end of the array. Let's consider the optimal further answer: […,xj,…]i[…,xj,…]. Now let's put i at the end of the array and leave the order of the following elements unchanged. All segments whose ends lie on elements that are larger than i may no longer cover the number i, but the sets of numbers larger than i that they cover have not changed. So the answer got better.Since we choose one of the ends independently, there are 2n−1 of such permutations, and we can find the k-th one using a simple loop, similar to converting a number into binary notation.
#include <bits/stdc++.h>
 
using namespace std;
 
int main() {
    int tt;
    cin >> tt;
    while (tt--) {
        int n;
        long long k;
        cin >> n >> k;
        vector <int> a, b;
        
        if (n <= 60 && (1ll << (n - 1)) < k) {
            cout << -1 << endl;
            continue;
        }
        k--;
        vector <int> d;
        while (k) {
            d.push_back(k % 2);
            k /= 2;
        }
        while (d.size() < n - 1) d.push_back(0);
        
        for (int i = n - 2, j = 1; i >= 0; i--, j++) {
            if (d[i] == 0) a.push_back(j);
            else b.push_back(j);
        }
        
        reverse(b.begin(), b.end());
        for (int i : a) cout << i << ' ';
        cout << n << ' ';
        for (int i : b) cout << i << ' ';
        cout << endl;
    }
 
    return 0;
}
tt = int(input())
for _ in range(tt):
    n, k = map(int, input().split())
    a, b = [], []
 
    if n <= 60 and (1 << (n - 1)) < k:
        print(-1)
        continue
    k -= 1
    d = []
    while k:
        d.append(k % 2)
        k //= 2
    while len(d) < n - 1:
        d.append(0)
 
    a, b = [], []
    j = 1
    for i in range(n - 2, -1, -1):
        if d[i] == 0:
            a.append(j)
        else:
            b.append(j)
        j += 1
 
    b.reverse()
    print(*a, n, *b)
2040D - Non Prime TreeThere are many array construction tactics that can be devised here. We will show two of them. We will perform a depth-first traversal of the graph and write a number 1 greater than the previous one in the traversal order into each subsequent vertex. If the next vertex is not a leaf, then some number has already been written into its parent, which may violate the condition "|aui−avi| is prime". If the difference is even and not equal to 2, then the condition is satisfied. Otherwise, the condition may be satisfied, but we will still achieve an even difference not equal to 2. If the difference is odd, first add the number 1. If the difference becomes 2, add another 2. It can be shown that if we added this additional 2, then we did not add them to the previous two vertices in the traversal order. We will write the values 2,4,6,… to the vertices with even depth in breadth-first order. We will write the values n⋅2,n⋅2−2,n⋅2−4,… to the vertices with odd depth in breadth-first order. In such a traversal, the condition "|aui−avi| is prime" can be violated only for one pair, and one of the vertices of this pair will be a leaf. We will change the value of this leaf to the value of the parent minus 1.
#include <bits/stdc++.h>
 
using namespace std;
 
int main() {
    int tt;
    cin >> tt;
    while (tt--) {
        int n;
        cin >> n;
        vector < vector <int> > g(n);
        for (int i = 0; i < n - 1; i++) {
            int a, b;
            cin >> a >> b;
            a--, b--;
            g[a].push_back(b);
            g[b].push_back(a);
        }
        
        vector <int> res(n);
        int lst = 1;
        res[0] = lst;
        
        function <void(int, int)> dfs = [&](int v, int p) {
            for (int to : g[v]) {
                if (to == p) continue;
                res[to] = lst + 1;
                while (res[to] != res[v] + 1 && 
                      (res[to] % 2 != res[v] % 2 || res[to] - res[v] == 2)) {
                    res[to]++;   
                }
                lst = res[to];
                dfs(to, v);
            }
        };
        
        dfs(0, 0);
        for (int i : res) cout << i << ' ';
        cout << endl;
    }
    
    return 0;
}
#include <bits/stdc++.h>
using namespace std;
 
using ll = long long;
 
void dfs(int v, vector<vector<int>>& g, vector<int>& h, int p) {
    h[v] = h[p] + 1;
    for (int u : g[v]) {
        if (u == p)
            continue;
        dfs(u, g, h, v);
    }
}
 
int main() {
    ios::sync_with_stdio(0);
    cin.tie(0);
    cout.tie(0);
    
    int tt;
    cin >> tt;
    while (tt--) {
        int n;
        cin >> n;
        vector<vector<int>> g(n);
        for (int i = 0; i < n - 1; i++) {
            int u, v;
            cin >> u >> v;
            u--, v--;
            g[u].push_back(v);
            g[v].push_back(u);
        }
        vector<int> h(n);
        dfs(0, g, h, 0);
        vector<vector<int>> hs(n + 1);
        for (int i = 0; i < n; i++)
            hs[h[i]].push_back(i);
        int l = 2, r = 2 * n;
        int cur = 0;
        vector<int> ans(n);
        for (int i = 1; i <= n; i++) {
           if (cur) {
               for (int v : hs[i]) {
                    ans[v] = r;
                    r -= 2;
               }
           } 
           else {
               for (int v : hs[i]) {
                    ans[v] = l;
                    l += 2;
               }
           }
           cur ^= 1;
        }
        bool found = false;
        for (int i = 0; i < n; i++) {
            for (int v : g[i]) {
                if (h[v] < h[i])
                    continue;
                if (abs(ans[v] - ans[i]) == 2) {
                    ans[v] = ans[i] - 1;
                    found = true;
                    break;
                }
            }
            if (found)
                break;
        }
        for (int i = 0; i < n; i++)
            cout << ans[i] << ' ';
        cout << '\n';
    }
    
    return 0;
}
There are many possible solutions to this problem, and almost all testers have implemented a unique solution. There are solutions that we could not prove correct, but we could not hack them either.
2040E - Control of RandomnessTo begin with, let's solve it without queries and forced movements. Let's consider the nature of the path. The current vertex v has a parent of parent u. Let there be an odd move now, and the robot will go to the parent of v. If we're lucky, it'll go to u. Otherwise, it will go to the brother of vertex v. But this won't change anything — the next step the robot will do the same thing again. For vertex v and all its brothers, the answer is the same. Let d[v] be the answer for vertex v, and let x be the number of brothers of vertex v, including itself. Then d[v]=2+1d+1⋅d[u]+dd+1⋅d[v], whence d[v]=d[u]+2⋅(x+1).We can see that our path consists of blocks of height 2 — the robot tries to overcome the next block until it succeeds, and then proceeds to the next one.We are now ready to answer the queries. Performing an operation is essentially skipping a block — the robot will pass it on the first try, spending not 2⋅(x+1) actions on it, but 2. Therefore we will delete blocks with the largest x greedily. We will traverse the graph and store two sets of degrees of vertices on the path to the root — one for vertices with odd depth, and the other for vertices with even depth. We will answer requests offline. Having detected a query, we will run through the first p elements of the corresponding set and subtract them.Asymptotics of the trivial implementation, in which for each query we move up to the root, is O(n⋅q).Asymptotics of a possible offline solution, where we will maintain sets of vertices while traversing the graph, is O(n+∑ipi⋅set).
#include <bits/stdc++.h>
 
using namespace std;
 
void solve() {
    int n, q;
    cin >> n >> q;
    
    vector < vector <int> > g(n);
    for (int i = 0; i < n - 1; i++) {
        int u, v;
        cin >> u >> v;
        u--, v--;
        g[u].push_back(v);
        g[v].push_back(u);
    }
    
    vector <int> depth(n);
    vector <int> d(n);
    vector <int> par(n);
 
    function <void(int, int)> dfs = [&](int v, int p) {
        if (depth[v] == 1) d[v] = 1;
        if (depth[v] > 1) d[v] = d[par[p]] + 2 * (int)g[p].size();
        par[v] = p;
        for(int to : g[v]) {
            if (to == p) continue;
            depth[to] = depth[v] + 1;
            dfs(to, v);
        }
    };
    
    dfs(0, 0);
    
    while (q--) {
        int v, p;
        cin >> v >> p;
        v--;
        int res = d[v];
        vector <int> cnt;
        while (v != 0 && par[v] != 0) {
            cnt.push_back((int)g[par[v]].size());
            v = par[par[v]];
        }
        sort(cnt.rbegin(), cnt.rend());
        for (int i = 0; i < min(p, (int)cnt.size()); i++) {
            res -= 2 * (cnt[i] - 1);
        }
        cout << res << '\n';
    }
}
 
int main() {
    int tt;
    cin >> tt;
    while (tt--) {
        solve();
    }
 
    return 0;
}
#include <bits/stdc++.h>
 
using namespace std;
 
void solve() {
    int n, q;
    cin >> n >> q;
    
    vector < vector <int> > g(n);
    for (int i = 0; i < n - 1; i++) {
        int u, v;
        cin >> u >> v;
        u--, v--;
        g[u].push_back(v);
        g[v].push_back(u);
    }
    
    vector <int> depth(n);
    vector <int> d(n);
    vector < vector < pair <int,int> > > qrs(n); // <p, idx>
    vector <int> res(q);
    
    for (int i = 0; i < q; i++) {
        int v, p;
        cin >> v >> p;
        v--;
        qrs[v].push_back({p, i});
    }
    
    multiset <int> st[2]; // store negative number to be able to use usual foreach loop
    
    function <void(int, int, int)> dfs = [&](int v, int p, int pp) {
        if (depth[v] == 1) d[v] = 1;
        if (depth[v] > 1) d[v] = d[pp] + 2 * (int)g[p].size();
        
        for (pair <int, int> qr : qrs[v]) {
            int p = qr.first, idx = qr.second;
            int ans = d[v];
            for (int i : st[1 - depth[v] % 2]) {
                if (p == 0) break;
                ans -= (-i - 1) * 2;
                p--;
            }
            res[idx] = ans;
        }
        
        if (depth[v] != 0) st[depth[v] % 2].insert(-(int)g[v].size());
        
        for (int to : g[v]) {
            if (to == p) continue;
            depth[to] = depth[v] + 1;
            dfs(to, v, p);
        }
        
        if (depth[v] != 0) st[depth[v] % 2].erase(st[depth[v] % 2].find(-(int)g[v].size()));
    };
    
    dfs(0, 0, 0);
    
    for (int i = 0; i < q; i++)
        cout << res[i] << '\n';
}
 
int main() {
    int tt;
    cin >> tt;
    while (tt--) {
        solve();
    }
 
    return 0;
}
This problem originally had the following constraints:  1≤n,q≤2⋅1051≤n,q≤2⋅105 The sum of pp in all queries is not greater than 2⋅1052⋅105 How to solve this problem?Could you solve this problem without the second constraint? HintHowever, it is not hard thanks to a recent blog.
However, it is not hard thanks to a recent blog.
2040F - Number of CubesRecall Burnside's lemma — the number of elements up to an action group is:1|G|⋅∑g∈G∑x∈X[gx=x], where [x]=1 if x=true and [x]=0 if x=false.Let's try to iterate over the elements of the action group — all triplets of numbers [0,a), [0,b), [0,c). When applying a fixed action (i,j,l), the element moves to this vector. Let's choose a cell and add a vector to it until we reach it again. We have drawn a cycle — all cells on it must be of the same type. An example of such a traversal for (a,b,c)=(9,4,1), (i,j,k)=(3,2,0) (each different number in the table corresponds to a cycle): 123123123456456456123123123456456456 You can count the cycles by traversal, or you can derive formula: the length of all cycles is the same and equals N=lcm(agcd(a,i),bgcd(b,j),cgcd(c,l)).What's good about the equal lengths of the cycles? Because the formula for calculating the number of stationary parallelepipeds is simple. First, all di must be divisible by N. Then we distribute them among the cycles. This is the multinomial coefficient for (d1N,d2N,…,dkN).Current total time O(a⋅b⋅c⋅k): iterated over a⋅b⋅c vector triplets, calculated N, checked divisibility for all k numbers, and if successful, calculated the multinomial coefficient of size k.Let's speed up the solution. Let's calculate G=gcd(d1,d2,…,dk). Since all di are divisible by N, then G is also divisible by N. There are no more different N than the number of divisors of a⋅b⋅c. Let's calculate the number of triplets that give each value of N, and at the end we will calculate the multinomial coefficient for all identical values of N at once.The total time is O(a⋅b⋅c⋅logC+d(a⋅b⋅c)⋅k), where d(x) — is the number of divisors of x, and log appears due to the calculation of gcd.Let's continue to speed up the solution. There are two solutions further.Solution 1.Let's look again at the formula N=lcm(agcd(a,i)…). For convenience, we will focus on the first element. Let's say we want the first element to be x=agcd(a,i). Then x is divisible by a and ax=gcd(a,i). i is divisible by gcd(i,…), so i is divisible by ax. Then the possible i are of the form p⋅ax, where 1≤p≤x, and the equality gcd(a,ax)=ax is exactly satisfied. p is coprime to x, otherwise the value of gcd will be multiplied by their common divisor and the equality will be violated. Therefore the number of suitable x is equal to phi(x), where phi(x) — Euler's function.So, let's enumerate triplets of divisors of a, b and c. The number of ways to obtain a triple (x,y,z) is equal to phi(x)⋅phi(y)⋅phi(z). Let's calculate phi(x) using the Sieve of Eratosthenes.We get a solution in O(d(a)⋅d(b)⋅d(c)⋅logC+d(a⋅b⋅c)⋅k) and O(a⋅b⋅c⋅loglog(a⋅b⋅c)) for pre-calculation.Solution 2.Let's calculate the same N using dynamic programming. For convenience, we denote the dimensions of a, b, and c by the array ai. Let dp[i][j] be the number of ways, having passed i dimensions, to obtain lcm equal to j. The transitions will be as follows: we will iterate over the pairs of the previous lcm t1 and the next divisor t2 of the size of the next dimension ai. Then the new lcm will be equal to lcm(t1,t2) and we make the transition dp[i+1][lcm(t1,t2)]+=dp[i][t1]⋅cnt[i][t2], where cnt[i][j] — the number of such x that aigcd(ai,x)=j.How to calculate the array cnt[i][j]. We cannot calculate it trivially in O((a+b+c)⋅logC), since it is too long time. For simplicity, we calculate the array cnt2[i][j] equal to the number of x such that gcd(ai,x)=j. We iterate over the divisors of ai in ascending order. Let the current divisor be d1. Add aid1 to cnt2[i][d1], since that many x will be divisible by d1. Those x that are divisible by d1 but are not equal to it, we will subtract later. We iterate over the divisors d2 of d1. We subtract cnt2[i][d1] from cnt2[i][d2], since their gcd is actually not d2, but d1 or a number that d1 divides. Let's calculate cnt[i][j]=cnt2[i][aij].If we pre-calculate the divisors of all numbers and compress their "coordinates", we get a solution in O(d(a⋅b⋅c)2⋅logC+d(a⋅b⋅c)⋅k).
#include <bits/stdc++.h>
#define int long long
 
using namespace std;
 
const int N = 3000010;
const int mod = 998244353;
int fact[N], ifact[N], phi[N];
 
int powmod(int a, int n) {
    int res = 1;
    while (n) {
        if (n % 2 == 0) {
            a = (a * a) % mod;
            n /= 2;
        }
        else {
            res = (res * a) % mod;
            n--;
        }
    }
    return res;
}
 
int inv(int a) {
    return powmod(a, mod - 2);
}
 
void prepare() {
    fact[0] = 1;
    for (int i = 1; i < N; i++) {
        fact[i] = (fact[i - 1] * i) % mod;
    }
    ifact[N - 1] = inv(fact[N - 1]);
    for (int i = N - 2; i >= 0; i--) {
        ifact[i] = (ifact[i + 1] * (i + 1)) % mod;
    }
 
    phi[0] = 0;
    phi[1] = 1;
    for (int i = 2; i < N; i++) {
        phi[i] = i - 1;
    }
    for (int i = 2; i < N; i++) {
        for (int j = i * 2; j < N; j += i) {
            phi[j] -= phi[i];
        }
    }
}
 
int C(int n, int k) {
    return ((fact[n] * ifact[k]) % mod * ifact[n - k]) % mod;
}
 
int MC(vector <int> &a) {
    int sum=0;
    for (int i : a) sum += i;
    int res = fact[sum];
    for (int i : a) {
        res = (res * ifact[i]) % mod;
    }
    return res;
}
 
int lcm(int a, int b) {
    return a / __gcd(a, b) * b;
}
 
vector <int> all_divs(int x) {
    vector <int> d;
    for (int i = 1; i * i <= x; i++) {
        if (x % i == 0) {
            d.push_back(i);
            if (i * i != x) {
                d.push_back(x / i);
            }
        }
    }
    return d;
}
 
void solve() {
    int a, b, c, k;
    cin >> a >> b >> c >> k;
    vector <int> v(k);
    for (int &i : v) cin >> i;
 
    int g = v[0];
    for (int i : v) g = __gcd(g, i);
 
    map <int, int> mp;
    for (int i : all_divs(a)) {
        for (int j : all_divs(b)) {
            for (int l : all_divs(c)) {
                int N = lcm(i, lcm(j, l));
                if (g % N == 0) {
                    mp[N] += phi[i] * phi[j] * phi[l];
                }
            }
        }
    }
 
    int sum = 0;
    for (pair <int, int> pr : mp) {
        int N = pr.first, cnt = pr.second;
        vector <int> u;
        for (int t : v) u.push_back(t / N);
        sum = (sum + (MC(u) * cnt) % mod) % mod;
    }
 
    sum = (sum * inv(a * b * c)) % mod;
 
    cout << sum << endl;
}
 
int32_t main() {
    prepare();
 
    int tt;
    cin >> tt;
    while (tt--) {
        solve();
    }
 
    return 0;
}
#include <bits/stdc++.h>
#define int long long
 
using namespace std;
 
const int N = 3000010;
const int mod = 998244353;
int fact[N], ifact[N];
int pos[N];
 
int powmod(int a, int n) {
    int res = 1;
    while (n) {
        if (n % 2 == 0) {
            a = (a * a) % mod;
            n /= 2;
        }
        else {
            res = (res * a) % mod;
            n--;
        }
    }
    return res;
}
 
int inv(int a) {
    return powmod(a, mod - 2);
}
 
void prepare() {
    fact[0] = 1;
    for (int i = 1;i < N; i++) {
        fact[i] = (fact[i - 1] * i) % mod;
    }
    ifact[N - 1] = inv(fact[N - 1]);
    for (int i = N - 2; i >= 0; i--) {
        ifact[i] = (ifact[i + 1] * (i + 1)) % mod;
    }
}
 
int C(int n, int k) {
    return ((fact[n] * ifact[k]) % mod * ifact[n - k]) % mod;
}
 
int MC(vector <int> &a) {
    int sum=0;
    for (int i : a) sum += i;
    int res = fact[sum];
    for (int i : a) {
        res = (res * ifact[i]) % mod;
    }
    return res;
}
 
int lcm(int a, int b) {
    return a / __gcd(a, b) * b;
}
 
vector <int> all_divs(int x) {
    vector <int> d1, d2;
    for (int i = 1; i * i <= x; i++) {
        if (x % i == 0) {
            d1.push_back(i);
            if (i * i != x) {
                d2.push_back(x / i);
            }
        }
    }
    reverse(d2.begin(), d2.end());
    for (int i : d2) d1.push_back(i);
    return d1;
}
 
void solve() {
    int a, b, c, k;
    cin >> a >> b >> c >> k;
    vector <int> v(k);
    for (int &i : v) cin >> i;
 
    int g = v[0];
    for (int i : v) g = __gcd(g, i);
    vector <int> divs_g = all_divs(g);
 
    set <int> divs;
    for (int i : all_divs(a)) divs.insert(i);
    for (int i : all_divs(b)) divs.insert(i);
    for (int i : all_divs(c)) divs.insert(i);
    for (int i : all_divs(g)) divs.insert(i);
    int D = divs.size();
    int i = 0;
    for (int j : divs) {
        pos[j] = i;
        i++;
    }
 
    int n = max({a, b, c}) + 1;
    vector < vector <int> > tmp(3, vector <int> (D));
    vector < vector <int> > cnt(3, vector <int> (D));
    for (int t = 0; t < 3; t++) {
        int x;
        if (t == 0) x = a;
        if (t == 1) x = b;
        if (t == 2) x = c;
        vector <int> divs_x = all_divs(x);
 
        for (int i = (int)divs_x.size() - 1; i >= 0; i--) {
            tmp[t][pos[divs_x[i]]] += x / divs_x[i];
            for (int j = 0; j < i; j++) {
                if (divs_x[i] % divs_x[j] == 0) {
                    tmp[t][pos[divs_x[j]]] -= tmp[t][pos[divs_x[i]]];
                }
            }
            cnt[t][pos[x / divs_x[i]]] = tmp[t][pos[divs_x[i]]];
        }
    }
        
    vector < vector <int> > dp(4, vector <int> (D));
    dp[0][0] = 1;
    for(int i = 0; i < 3; i++) {
        for (int t1 : divs_g) {
            for (int t2 : divs_g) {
                int new_pos = lcm(t1, t2);
                if (t2 < n) {
                    dp[i + 1][pos[new_pos]] = (dp[i + 1][pos[new_pos]] + dp[i][pos[t1]] * cnt[i][pos[t2]]) % mod;
                }
            }
        }
    }
 
    int sum = 0;
    i = 0;
    for (int j : divs) {
        if (g % j != 0) continue;
        int N = j, cnt = dp[3][pos[j]];
        vector <int> u;
        for (int t : v) u.push_back(t / N);
        sum = (sum + (MC(u) * cnt) % mod) % mod;
    }
 
    sum = (sum * inv(a * b * c)) % mod;
 
    cout << sum << endl;
}
 
int32_t main() {
    prepare();
 
    int tt;
    cin >> tt;
    while (tt--) {
        solve();
    }
 
    return 0;
}
1 2 3 4 5
1 2 3 5 4
1 2 4 5 3
1 2 5 4 3
1 3 4 5 2
1 3 5 4 2
1 4 5 3 2
1 5 4 3 2


[Editorial - contest/2050]
2050A - Line BreaksAn important condition in the problem: we can take xx words on the first line from the beginning and we cannot skip any word.The main idea is to compute the total length of words as we keep adding them, and stop when we reach a word where adding the next word would exceed the capacity of the first strip (which equals mm).It is important to take into account the case when all words can be placed on the first line or none will fit, but our solution takes this into account.
def solve():
    n, m = [int(i) for i in input().split()]

    ans = 0
    for i in range(n):
        l = input()
        if len(l) <= m:
            m -= len(l)
            ans += 1
        else:
            for i in range(i + 1, n):
                input()
            break

    print(ans)


t = int(input())
for i in range(t):
    solve()
2050B - TransfusionThe main idea of this problem is that these operations only change elements on the positions with the same parity. So, we can solve for elements on odd and even positions independently.Let's make two arrays odod and evev  — the first one will consist of all the elements on the odd positions, and the second one will consist of all the elements on the even positions. Now we can rewrite given operations as: pick any array odod or evev, after that pick any two adjacent elements and subtract 11 from one of these elements and add 11 to another. In order to make all the elements in array odod equal, the sum of all elements in odod must be divisible by |od||od|, and also the sum of all the elements in evev must be divisible by |ev||ev|, where |a||a| is the length of array aa. And also to make all the elements of the initial array equal, sum(od)|od|=sum(ev)|ev|sum(od)|od|=sum(ev)|ev| must be satisfied. If all these conditions are satisfied, the answer is "YES", otherwise "NO".
#include <bits/stdc++.h>

using namespace std;

void solve() {
    int n; cin >> n;
    vector<int> a(n);
    for (int &x : a) cin >> x;
    
    long long ods = 0, evs = 0;
    for (int i = 0; i < n; i++) {
        if (i & 1) ods += a[i];
        else evs += a[i];
    }
    int odc = n / 2, evc = n / 2;
    if (n & 1) evc++;

    if (ods % odc != 0 || evs % evc != 0 || ods / odc != evs / evc) {
        cout << "NO";
        return;
    }
    cout << "YES";
}

int main() {
    int TESTS; cin >> TESTS;
    while (TESTS --> 0) {
        solve();
        cout << '\n';
    }
    return 0;
}
2050C - Uninteresting NumberThe requirement that a digit must remain a digit imposes the following restrictions on transformations: we can transform 00 into 00, 11 into 11, 22 into 44, and 33 into 99. Any other digit squared will exceed 9, therefore, it cannot be transformed. Transformations involving 00 and 11 are useless, leaving us with two possible actions: squaring the digit 22 or the digit 33.We will use the divisibility rule for 99. It states that a number is divisible by 99 if and only if the sum of its digits is divisible by 99. Let's see how the sum of the digits will change with the possible transformations. If we square 22, the sum of the digits increases by 22−2=222−2=2, and if we square 33, the sum of the digits increases by 32−3=632−3=6.We will count the number of digits 22 in the number and the number of digits 33 in the number. We can choose how many of the available digits 22 and 33 we will transform. Transforming more than 8 twos and more than 8 threes is pointless because remainders modulo 99 their transformation adds to the sum will repeat.Thus, the final solution looks like this: we calculate the sum of the digits in the number, count the number of digits 22 and 33. We will iterate over how many digits 22 we change (possibly 0, but no more than 8), and how many digits 33 we change (possibly 0, but also no more than 8). Let's say we changed xx digits 22 and yy digits 33, then the sum of the digits in the number increased by x∗2+y∗6x∗2+y∗6. If new sum is divisible by 99, the answer is "YES". If such a situation was never reached during the iteration, then the answer is "NO".
def solve():
    s = [int(x) for x in list(input())]

    sm = sum(s)
    twos = s.count(2)
    threes = s.count(3)

    for i in range(min(10, twos + 1)):
        for j in range(min(10, threes + 1)):
            if (sm + i * 2 + j * 6) % 9 == 0:
                print('YES')
                return
    print('NO')


t = int(input())
for _ in range(t):
    solve()
2050D - Digital string maximizationLet's look at digit sisi. We can see that we can't move it to the left more than sisi times because it will be 00 after. So, we can say that only digits on indices from ii to i+9i+9 can stand on index ii, because the maximum digit 99 can be moved to the left no more than 99 times.Thus, for each ii we can brute force all digits from sisi to si+9si+9 and pick such jj that sj−(j−i)sj−(j−i) is maximum; if we have multiple maximum options, we will minimize jj. After that, we will move sjsj to the left until it is on index ii.
#include <bits/stdc++.h>

using namespace std;

void solve() {
    string s; cin >> s;
    for (int i = 0; i < s.size(); i++) {
        int best = s[i] - '0', pos = i;
        for (int j = i; j < min(i + 10, (int) s.size()); j++) {
            if (s[j] - '0' - (j - i) > best) {
                best = s[j] - '0' - (j - i);
                pos = j;
            }
        }
        while (pos > i) {
            swap(s[pos], s[pos - 1]);
            pos--;
        }
        s[i] = char(best + '0');
    }
    cout << s;
}

int main() {
    int TESTS = 1; cin >> TESTS;
    while (TESTS --> 0) {
        solve();
        cout << '\n';
    }
    return 0;
}
2050E - Three StringsLet's use the idea of dynamic programming. Let dp[i][j]dp[i][j] be the answer to the problem when considering string aa as its own prefix of length ii, string bb as its own prefix of length jj, and string cc as its own prefix of length i+ji+j.Then the dynamic programming recurrence is easy: we need to iterate over where we took the next ((i+ji+j)-th) character of string cc.If the character is taken from string aa, the answer is:  dp[i−1][j]dp[i−1][j], if ai=ci+jai=ci+j,  dp[i−1][j]+1dp[i−1][j]+1 otherwise (since we need to replace character aiai with ci+jci+j). If it is taken from string bb, the answer is calculated similarly:  dp[i][j−1]dp[i][j−1], if bj=ci+jbj=ci+j,  dp[i][j−1]+1dp[i][j−1]+1 otherwise. Thus, to obtain the minimum value of the current dynamic programming state, we need to take the minimum of the two obtained values.To get the answer, we need to take the value of the dynamic programming table at dp[n][m]dp[n][m], where nn is the length of string aa and mm is the length of string bb.The final time complexity of the solution is O(n⋅m)O(n⋅m) per test case.
#include <iostream>
#include <algorithm>

static const int inf = 1e9;

void solve() {
    std::string a, b, res;
    std::cin >> a >> b >> res;
    int n = (int) a.size(), m = (int) b.size();
    int dp[n + 1][m + 1];
    std::fill(&dp[0][0], &dp[0][0] + (n + 1) * (m + 1), inf);
    dp[0][0] = 0;
    for (int i = 0; i < n; i++) {
        dp[i + 1][0] = dp[i][0] + (a[i] != res[i]);
    }
    for (int j = 0; j < m; j++) {
        dp[0][j + 1] = dp[0][j] + (b[j] != res[j]);
    }
    for (int i = 1; i <= n; i++) {
        for (int j = 1; j <= m; j++) {
            dp[i][j] = std::min(dp[i - 1][j] + (a[i - 1] != res[i + j - 1]),
                                dp[i][j - 1] + (b[j - 1] != res[i + j - 1]));
        }
    }
    std::cout << dp[n][m] << std::endl;
}

int main() {
    int tests;
    std::cin >> tests;
    while (tests--) {
        solve();
    }
}
2050F - Maximum modulo equalityLet's look at two arbitrary integers xx and yy. Now we want to find the maximum mm, which satisfies xmodm=ymodmxmodm=ymodm. We know that xmodm=ymodmxmodm=ymodm, then |x−y|modm=0|x−y|modm=0, because they have the same remainder by mm. That means that any mm which is a divisor of |x−y||x−y| will satisfy the required condition.Now let's generalize the idea we've obtained to the segment: almodm=al+1modm=⋯=armodmalmodm=al+1modm=⋯=armodm means that almodm=al+1modmalmodm=al+1modm, and al+1modm=al+2modmal+1modm=al+2modm, and ..., and ar−1modm=armodmar−1modm=armodm. So, mm must be a divisor of |al−al+1||al−al+1|, |al+1−al+2||al+1−al+2|, ..., |ar−1−ar||ar−1−ar| at the same time. That means that mm should be GCD(|al−al+1||al−al+1|, |al+1−al+2||al+1−al+2|, ..., |ar−1−ar||ar−1−ar|), where GCD is the greatest common divisor. m=0m=0, when all the elements on the segment [l;rl;r] are equal.Let's build an array consisting of differences of adjacent elements; now we can use sparse table to find GCD on the segments efficiently.
#include <bits/stdc++.h>

using namespace std;

const int LOGN = 20;

vector<vector<int>> stGCD;

int get_gcd(int l, int r) {
    int k = __lg(r - l + 1);
    return __gcd(stGCD[k][l], stGCD[k][r - (1 << k) + 1]);
}

void solve() {
    stGCD.clear();
    int n, q; cin >> n >> q;
    vector<int> a(n);
    for (int &x : a) cin >> x;

    vector<int> b;
    for (int i = 1; i < n; i++)
        b.push_back(abs(a[i - 1] - a[i]));

    stGCD.resize(LOGN, vector<int>(b.size(), 1));
    for (int i = 0; i < b.size(); i++)
        stGCD[0][i] = b[i];
    for (int i = 1; i < LOGN; i++)
        for (int j = 0; j + (1 << (i - 1)) < b.size(); j++)
            stGCD[i][j] = __gcd(stGCD[i - 1][j], stGCD[i - 1][j + (1 << (i - 1))]);

    while (q--) {
        int l, r; cin >> l >> r;
        if (l == r) {
            cout << 0 << " ";
            continue;
        }
        l--; r -= 2;
        int gcd = get_gcd(l, r);
        cout << gcd << " ";
    }
}

int main() {
    int TESTS = 1; cin >> TESTS;
    while (TESTS --> 0) {
        solve();
        cout << "\n";
    }
    return 0;
}
2050G - Tree DestructionLet's choose some vertices aa and bb, between which there are kk edges. Then, when removing this path, the tree will split into s−2⋅ks−2⋅k, where ss is the sum of the degrees of the vertices on the path (this is exactly how many edges are connected to the chosen path).Let's suspend the tree from vertex 11, and for each vertex vv of the given tree, we will calculate two values: dp[v].xdp[v].x — the best answer if the path starts at vertex vv and ends in its subtree, and dp[v].ydp[v].y — the best answer if the path passes through vertex vv from one of its children to another. The recalculations of the dynamic programming will be similar to those used in finding the diameter of the tree using dynamic programming.The answer will be the largest value among all dp[v].xdp[v].x and dp[v].ydp[v].y.
#include <bits/stdc++.h>

#define int long long
#define x first
#define y second

using namespace std;

void dfs(int v, int p, vector<vector<int>> &sl, vector<pair<int, int>> &dp){
    dp[v].x = sl[v].size();
    int m1 = -1, m2 = -1;
    for(int u: sl[v]){
        if(u == p){
            continue;
        }
        dfs(u, v, sl, dp);
        dp[v].x = max(dp[v].x, dp[u].x + (int)sl[v].size() - 2);
        m2 = max(m2, dp[u].x);
        if(m1 < m2) swap(m1, m2);
    }
    dp[v].y = dp[v].x;
    if(m2 != -1){
        dp[v].y = m1 + m2 + sl[v].size() - 4;
    }
}

void solve(int tc){
    int n;
    cin >> n;
    vector<vector<int>> sl(n);
    for(int i = 1; i < n; ++i){
        int u, v;
        cin >> u >> v;
        sl[--u].emplace_back(--v);
        sl[v].emplace_back(u);
    }
    vector<pair<int, int>> dp(n);
    dfs(0, 0, sl, dp);
    int ans = 0;
    for(int i = 0; i < n; ++i){
        ans = max(ans, max(dp[i].x, dp[i].y));
    }
    cout << ans;
}

bool multi = true;

signed main() {
    int t = 1;
    if (multi)cin >> t;
    for (int i = 1; i <= t; ++i) {
        solve(i);
        cout << "\n";
    }
    return 0;
}
Implementation: 296305754


[Editorial - contest/2046]
NT = int(input())

sqs = set()
k = 1
while k * k <= 100 * 1000:
	sqs.add(k * k)
	k += 2

for T in range(NT):
	n = int(input())
	a = list(map(int, input().split()))
	answer = 0
	cursum = 0
	for t in a:
		cursum += t
		if cursum in sqs:
			answer += 1
	print(answer)

#include <bits/stdc++.h>

using namespace std;

int main() {
    cin.tie(0)->sync_with_stdio(0);
    int t;
    cin >> t;
    while (t--) {
        int n;
        cin >> n;
        string s;
        cin >> s;
        vector<int> occ(26);
        for (int i=0; i<n; i++)
            occ[s[i] - 'a'] += 1;
        pair<pair<int,char>,int> low, high;
        low = high = {{occ[s[0] - 'a'], s[0]}, 0};
        for (int i=1; i<n; i++) {
            low = min(low, {{occ[s[i] - 'a'], s[i]}, i});
            high = max(high, {{occ[s[i] - 'a'], s[i]}, i});
        }
        s[low.second] = s[high.second];
        cout << s << "\n";
    }
  return 0;
}
for _ in range(int(input())):
    n = int(input())
    a = []
    for i in range(2):
        a.append(list(map(int, input().split())))
    best = [max(a[0][i], a[1][i]) for i in range(n)]
    full = [a[0][i] + a[1][i] for i in range(n)]
    sum_best = sum(best)
    ans = -10 ** 19
    for i in range(n):
        ans = max(ans, sum_best + full[i] - best[i])
    print(ans)
#include <bits/stdc++.h>

using namespace std;

#ifdef LOCAL
    #define eprintf(...) fprintf(stderr, __VA_ARGS__)
#else
    #define eprintf(...) 42
#endif

using ll = long long;
using ld = long double;
using D = double;
using uint = unsigned int;
template<typename T>
using pair2 = pair<T, T>;

#define pb push_back
#define mp make_pair
#define all(x) (x).begin(),(x).end()
#define fi first
#define se second
mt19937_64 rng(chrono::steady_clock::now().time_since_epoch().count());

void solve()
{
	int n;
	scanf("%d", &n);
	vector<int> a(n);
	for (int i = 0; i < n; i++) scanf("%d", &a[i]);
	vector<int> front(n);
	int frontfront = n;
	int frontback = n;
	multiset<int> back;
	for (int i = n - 1; i >= 0; i--)
	{
		if (frontfront >= frontback || a[i] <= front[frontfront]) front[--frontfront] = a[i];
		else back.insert(a[i] + 1);
		while (frontfront < frontback && !back.empty() && front[frontback - 1] > *back.begin())
		{
			back.insert(front[frontback - 1] + 1);
			frontback--;
		}
	}
	vector<int> answer;
	for (int i = frontfront; i < frontback; i++) answer.pb(front[i]);
	for (auto t : back) answer.pb(t);
	for (auto t : answer) printf("%d ", t);
	printf("\n");
}

int main()
{
    int NT = 1;
    scanf("%d", &NT);
    for (int T = 1; T <= NT; T++)
    {
        solve();
    }
    return 0;
}

#include <math.h>
#include <unordered_set>
#include <unordered_map>
#include <map>
#include <iostream>
#include <fstream>
#include <vector>
#include <set>
#include <array>
#include <cstring>
#include <ctime>
#include <cassert>
#include <string_view>
#include <functional>
#include <sstream>
#include <numeric>
#include <cmath>
#include <deque>
#include <list>
#include <algorithm>
#include <iomanip>
 
using namespace std;
 
using i64 = long long;
using ui32 = unsigned int;
using ui64 = unsigned long long;
 
#define all(a) (a).begin(), (a).end()
 
 
struct Tree;
 
Tree* NewNode();
 
struct Count {
    int left = 0;
    int right = 0;
    void Add(int delta) {
        left += delta;
        if (delta < 0) {
            right -= delta;
        }
    }
    void operator += (const Count& c) {
        left += c.left;
        right += c.right;
    }
 
    int GetMin() {
        return min(left, right);
    }
};
 
struct Tree {
        Count count;
        Tree* left = nullptr;
        Tree* right = nullptr;
 
        void Add(int l, int r, int p, int delta = 1) {
            count.Add(delta);
            if (r - l == 1) {
                return;
            }
            int mid = (l + r) / 2;
            if (p < mid) {
                if (left == nullptr) {
                    left = NewNode();
                }
                left->Add(l, mid, p, delta);
            } else {
                if (right == nullptr) {
                    right = NewNode();
                }
                right->Add(mid, r, p, delta);
            }
        } 
 
        Count LeftCount() {
            if (left) {
                return left->count;
            }
            return {};
        }
        Count RightCount() {
            if (right) {
                return right->count;
            }
            return {};
        }
 
        void Remove(int l, int r, int p) {
            Add(l, r, p, -1);
        }
};
 
Tree nodes[7000000];
 
Tree* NewNode() {
    static Tree* nextNode = nodes;
    return nextNode++;
}
 
 
struct Solver {
    struct Point {
        int x, y;
        bool operator < (const Point& p) const {
            return x < p.x;
        }
    };
 
    int max = 0;
    int bx = 0;
    int by = 0;
 
    bool FindBest(int l, int r, Tree* node, const Count& left = {}, const Count& right = {}) {
        if (node == nullptr) {
            return false;
        }
        int mid = (l + r) / 2;
        Count newLeft = node->LeftCount();
        Count newRight = node->RightCount();
        newLeft += left;
        newRight += right;
        int mn = min(newLeft.GetMin(), newRight.GetMin());
        bool updated = false;
        if (mn > max) {
            max = mn;
            by = mid;
            updated = true;
        }
        if (mn == newLeft.GetMin()) {
            if (FindBest(mid, r, node->right, newLeft, right)) {
                return true;
            }
        } else {
            if (FindBest(l, mid, node->left, left, newRight)) {
                return true;
            }
        }
        return updated;
    }
 
    void Solve(istream& cin, ostream& cout) {
        int n;
        cin >> n;
        vector<Point> a(n);
        int t9 = 1000000001;
        #ifdef pperm
            t9 = 100;
        #endif
        Tree* tree = NewNode();
        for (Point& p : a) {
            cin >> p.x >> p.y;
            tree->Add(-t9, t9, p.y);
        }
        sort(all(a));
        for (int i = 0; i < n;) {
            int j = i + 1;
            while (j < n && a[j].x == a[i].x) {
                ++j;
            }
            if (FindBest(-t9, t9, tree)) {
                bx = a[i].x;
            }
            for (;i < j; ++i) {
                tree->Remove(-t9, t9, a[i].y);
 
            }
        }
        cout << max << '\n' << bx << ' ' << by << endl;
    }
};
 
int main(int argc, char* args[]) {
#ifdef pperm
    ifstream cin("/home/pperm86/My/Codeforces/input.txt");
#endif
    ios_base::sync_with_stdio(false);
    cin.tie(NULL);
#ifndef pperm
    srand(time(0));
#endif
    int T = 1;
    cin >> T;
    for (int iTest = 1; iTest <= T; ++iTest) {
		Solver solver{};
        solver.Solve(cin, cout);
    }
#ifdef pperm
    cout << clock() / static_cast<double>(CLOCKS_PER_SEC) << endl;
#endif
    return 0;
}
#define _CRT_SECURE_NO_WARNINGS

#include<iostream>
#include<fstream>
#include<vector>
#include<stack>
#include<queue>
#include<set>
#include<map>
#include<array>
#include<unordered_set>
#include<unordered_map>
#include<cstring>
#include<string>
#include<memory>
#include<iomanip>
#include<cassert>
#include<cmath>
#include<random>
#include<algorithm>
#include<chrono>

#pragma GCC optimize("O3,unroll-loops")
#pragma GCC target("avx2,bmi,bmi2,lzcnt,popcnt")

#define int long long
#define ld long double
#define endl '\n'

using namespace std;


constexpr int N = 500;
vector<int> g[N], gr[N], gcmp[N];
int a[N], acmp[N], used[N], color[N], cur_color = 0;
vector<int> order, cmp;

void dfs1(int u) {
	for (int v : g[u]) {
		if (used[v] == 0) {
			used[v] = 1;
			dfs1(v);
		}
	}
	order.push_back(u);
}

void dfs2(int u) {
	for (int v : gr[u]) {
		if (used[v] == 0) {
			used[v] = 1;
			dfs2(v);
		}
	}
	color[u] = cur_color;
}

inline array<int, 3> getInd(int u) {
	return { 3 * u, 3 * u + 1, 3 * u + 2 };
}

constexpr int INF = 0x3f3f3f3f;

struct MCMF {
	struct rib {
		int b, u, c, f;
		size_t back;
	};

	MCMF(int size) : n(size), g_mcmf(size) {};

	int n;
	vector<vector<rib>> g_mcmf;

	void rebuild(int sz) {
		n = sz, g_mcmf.clear(); g_mcmf.resize(sz);
	}

	void add_rib(int a, int b, int u, int c) {
		rib r1 = { b, u, c, 0, g_mcmf[b].size() };
		rib r2 = { a, 0, -c, 0, g_mcmf[a].size() };
		g_mcmf[a].push_back(r1);
		g_mcmf[b].push_back(r2);
	}

	pair<int, int> get_flow(int s, int t, int maxflow = INF) {
		int flow = 0, cost = 0;
		while (flow < maxflow) {
			vector<int> id(n, 0);
			vector<int> d(n, INF);
			vector<int> q(n);
			vector<int> p(n);
			vector<size_t> p_rib(n);
			int qh = 0, qt = 0;
			q[qt++] = s;
			d[s] = 0;
			while (qh != qt) {
				int v = q[qh++];
				id[v] = 2;
				if (qh == n)  qh = 0;
				for (size_t i = 0; i < g_mcmf[v].size(); ++i) {
					rib& r = g_mcmf[v][i];
					if (r.f < r.u && d[v] + r.c < d[r.b]) {
						d[r.b] = d[v] + r.c;
						if (id[r.b] == 0) {
							q[qt++] = r.b;
							if (qt == n)  qt = 0;
						}
						else if (id[r.b] == 2) {
							if (--qh == -1)  qh = n - 1;
							q[qh] = r.b;
						}
						id[r.b] = 1;
						p[r.b] = v;
						p_rib[r.b] = i;
					}
				}
			}

			if (d[t] == INF)  break;
			int addflow = maxflow - flow;
			for (int v = t; v != s; v = p[v]) {
				int pv = p[v];  size_t pr = p_rib[v];
				addflow = min(addflow, g_mcmf[pv][pr].u - g_mcmf[pv][pr].f);
			}
			for (int v = t; v != s; v = p[v]) {
				int pv = p[v];  size_t pr = p_rib[v], r = g_mcmf[pv][pr].back;
				g_mcmf[pv][pr].f += addflow;
				g_mcmf[v][r].f -= addflow;
				cost += g_mcmf[pv][pr].c * addflow;
			}
			flow += addflow;
		}
		return { flow, cost };
	}
};

void solve() {
	
	for (int i =0 ; i < N; i++)
	{
		g[i] = {};
		gr[i] = {};
		gcmp[i] = {};
	}
	memset(a, 0, sizeof a);
	memset(acmp, 0, sizeof acmp);
	memset(used, 0, sizeof used);
	memset(color, 0, sizeof color);
	cur_color = 0;
	order = {};
	cmp = {};
	
	int n, m; cin >> n >> m;
	for (int i = 0; i < n; i++) {
		g[i].clear();
		gr[i].clear();
	}

	for (int i = 0; i < n; i++) cin >> a[i];

	for (int i = 0; i < m; i++) {
		int u, v; cin >> u >> v; u--, v--;
		g[u].push_back(v);
		gr[v].push_back(u);
	}

	order.clear();
	memset(used, 0, sizeof(used[0]) * n);
	for (int i = 0; i < n; i++) {
		if (used[i] == 0) {
			used[i] = 1;
			dfs1(i);
		}
	}

	memset(used, 0, sizeof(used[0]) * n);
	for (int i = 0; i < n; i++) {
		int u = order[n - i - 1];
		if (used[u] == 0) {
			used[u] = 1;
			dfs2(u);
			cur_color++;
		}
	}

	// for (int i = 0; i < n; i++) cout << color[i] << " "; cout << endl;

	memset(acmp, 0, sizeof(acmp[0]) * cur_color);
	for (int i = 0; i < n; i++) {
		acmp[color[i]] += a[i];
		for (int v : g[i]) {
			if (color[i] != color[v]) {
				gcmp[color[i]].push_back(color[v]);
			}
		}
	}

	for (int i = 0; i < cur_color; i++) {
		auto& e = gcmp[i];
		sort(e.begin(), e.end());
		e.erase(unique(e.begin(), e.end()), e.end());

		// cout << i << " " << acmp[i] << ": ";
		// for (int v : e) cout << v << " "; cout << endl;
	}

	int s = 3 * cur_color, t = s + 1, so = t + 1, to = so + 1;
	MCMF gg(to + 1);

	for (int i = 0; i < cur_color; i++) {
		auto [uin, uout, ucnt] = getInd(i);
		gg.add_rib(s, ucnt, acmp[i], 0);
		gg.add_rib(ucnt, uin, 1, 1);
		gg.add_rib(ucnt, uout, INF, 0);

		gg.add_rib(uin, uout, INF, 0);
		gg.add_rib(uout, t, INF, 0);

		gg.add_rib(so, uout, 1, 0);
		gg.add_rib(uin, to, 1, 0);
	}

	gg.add_rib(t, s, INF, 0);

	for (int i = 0; i < cur_color; i++) {
		auto [uin, uout, ucnt] = getInd(i);
		for (int v : gcmp[i]) {
			auto [vin, vout, vcnt] = getInd(v);
			gg.add_rib(uout, vin, INF, 0);
		}
	}

	auto [flow, cost] = gg.get_flow(so, to);
	// cout << flow << " " << cost << endl;

	if (flow < cur_color) {
		cout << -1 << endl;
		return;
	}

	cout << cost << endl;
}

signed main() {
	// freopen("input.txt", "r", stdin);
	ios_base::sync_with_stdio(false);
	cin.tie(0); cout.tie(0);

	int q; cin >> q; while (q--)
	solve();
}

/**
 *    author:  tourist
 *    created: 01.12.2024 18:36:51
**/
#undef _GLIBCXX_DEBUG

#include <bits/stdc++.h>

using namespace std;

#ifdef LOCAL
#include "algo/debug.h"
#else
#define debug(...) 42
#endif

int main() {
  ios::sync_with_stdio(false);
  cin.tie(nullptr);
  int tt;
  cin >> tt;
  while (tt--) {
    int n, m;
    cin >> n >> m;
    vector<int> a(n), b(n), c(n);
    set<int> s;
    for (int i = 0; i < n; i++) {
      cin >> a[i] >> b[i] >> c[i];
      s.insert(c[i]);
    }
    vector<vector<int>> vs(m);
    for (int i = 0; i < m; i++) {
      int foo;
      cin >> foo;
      vs[i].resize(foo);
      for (int j = 0; j < foo; j++) {
        cin >> vs[i][j];
        --vs[i][j];
      }
    }
    const int inf = int(1.01e9);
    vector<int> min_a(m, inf);
    vector<int> max_a(m, -1);
    for (int i = 0; i < m; i++) {
      for (int j : vs[i]) {
        min_a[i] = min(min_a[i], a[j]);
        max_a[i] = max(max_a[i], a[j]);
      }
    }
    auto Unify = [&](vector<pair<int, int>>& bad) {
      sort(bad.begin(), bad.end());
      int ptr = 0;
      for (int i = 1; i < int(bad.size()); i++) {
        if (bad[i].first <= bad[ptr].second + 1) {
          bad[ptr].second = max(bad[ptr].second, bad[i].second);
        } else {
          bad[++ptr] = bad[i];
        }
      }
      bad.resize(ptr + 1);
    };
    vector<pair<int, int>> bad;
    for (int id = 0; id < m - 1; id++) {
      if (min_a[id] < max_a[id + 1]) {
        bad.emplace_back(min_a[id] + 1, max_a[id + 1]);
      }
    }
    Unify(bad);
    vector<int> ctr(n);
    for (int i = 0; i < m; i++) {
      for (int x : vs[i]) {
        ctr[x] = i;
      }
    }
    vector<pair<int, int>> tasks;
    int unused = 0;
    vector<int> order(n);
    iota(order.begin(), order.end(), 0);
    sort(order.begin(), order.end(), [&](int i, int j) {
      return a[i] > a[j];
    });
    multiset<int> before, after;
    for (int i = 0; i < n; i++) {
      after.insert(ctr[i]);
    }
    {
      int beg = 0;
      while (beg < n) {
        int end = beg;
        while (end + 1 < n && a[order[end + 1]] == a[order[end]]) {
          end += 1;
        }
        for (int i = beg; i <= end; i++) {
          before.insert(ctr[order[i]]);
          after.erase(after.find(ctr[order[i]]));
        }
        if (!before.empty() && !after.empty() && *prev(before.end()) <= *after.begin()) {
          for (int i = 0; i < 2; i++) {
            do {
              unused += 1;
            } while (s.find(unused) != s.end());
            tasks.emplace_back(a[order[end]], unused);
          }
        }
        beg = end + 1;
      }
    }
    map<int, int> add;
    for (int id = 0; id < m - 1; id++) {
      for (int i : vs[id]) {
        if (a[i] <= max_a[id + 1]) {
          if (add.find(c[i]) == add.end()) {
            add[c[i]] = b[i];
          } else {
            add[c[i]] = min(add[c[i]], b[i]);
          }
        }
      }
    }
    map<int, vector<pair<int, int>>> kill;
    for (int id = 1; id < m; id++) {
      for (int i : vs[id]) {
        if (a[i] >= min_a[id - 1]) {
          kill[c[i]].push_back({min_a[id - 1] + 1, b[i]});
        }
      }
    }
    for (auto& [type, x] : add) {
      auto& k = kill[type];
      Unify(k);
      int dif = x;
      while (true) {
        bool changed = false;
        {
          auto it = lower_bound(bad.begin(), bad.end(), make_pair(dif + 1, -1));
          if (it != bad.begin()) {
            it = prev(it);
            if (it->second >= dif) {
              dif = it->first - 1;
              changed = true;
            }
          }
        }
        {
          auto it = lower_bound(k.begin(), k.end(), make_pair(dif + 1, -1));
          if (it != k.begin()) {
            it = prev(it);
            if (it->second >= dif) {
              dif = it->first - 1;
              changed = true;
            }
          }
        }
        if (!changed) {
          break;
        }
      }
      tasks.emplace_back(dif, type);
    }
    debug(tasks);
    vector<int> all;
    map<int, int> spec;
    for (auto& [x, y] : tasks) {
      all.push_back(x);
      assert(spec.find(y) == spec.end());
      spec[y] = x;
    }
    sort(all.begin(), all.end());
    vector<int> solved(n);
    for (int i = 0; i < n; i++) {
      solved[i] = int(upper_bound(all.begin(), all.end(), a[i]) - all.begin());
      if (spec.find(c[i]) != spec.end() && spec[c[i]] > a[i] && spec[c[i]] <= b[i]) {
        solved[i] += 1;
      }
    }
    vector<int> min_solved(m, inf);
    vector<int> max_solved(m, -1);
    for (int i = 0; i < m; i++) {
      for (int j : vs[i]) {
        min_solved[i] = min(min_solved[i], solved[j]);
        max_solved[i] = max(max_solved[i], solved[j]);
      }
    }
    bool win = true;
    for (int id = 0; id < m - 1; id++) {
      if (min_solved[id] <= max_solved[id + 1]) {
        win = false;
        break;
      }
    }
    if (win) {
      cout << tasks.size() << '\n';
      for (auto& [x, y] : tasks) {
        cout << x << " " << y << '\n';
      }
    } else {
      cout << -1 << '\n';
    }
  }
  return 0;
}

#pragma GCC optimize("Ofast")
#include <iostream>
#include <cmath>
#include <cstdint>
#include <vector>
#include <string>
#include <iomanip>
#include <set>
#include <map>
#include <unordered_map>
#include <unordered_set>
#include <algorithm>
#include <functional>
#include <queue>
#include <fstream>
#include <random>
//#include <numbers>
#include <optional>
#include <deque>
#include <sstream>
#include <list>
#include <chrono>
#include <thread>
#include <cassert>
 
using namespace std;
using i64 = int64_t;
using ui64 = uint64_t;
#define YN(b) if (b) cout << "YES\n"; else cout << "NO\n";
 
template<typename T>
istream& operator>>(istream& is, vector<T>& v) { for (auto &e: v) { is >> e; } return is; }
 
template<typename T>
ostream& operator<<(ostream& os, vector<T>& v) { for (auto &e: v) { os << e << " "; } return os; }
 
template<typename T, typename V>
istream& operator>>(istream& is, pair<T, V>& v) { return is >> v.first >> v.second; }
 
template<typename T, typename V>
ostream& operator<<(ostream& os, pair<T, V>& v) { return os << v.first << " " << v.second; }
 
const int64_t md = 1e9+7;

int dx[4] = {-1, 0, 1, 0};
 
inline int64_t sqr(int64_t x) {
    return x * x;
}
 
inline int popcount(int64_t x) {
    int c = 0;
    while (x) c += x & 1, x >>= 1;
    return c;
}
 
pair<int64_t, int64_t> inter(pair<int64_t, int64_t> a, pair<int64_t, int64_t> b) {
    return {max(a.first, b.first), min(a.second, b.second)};
}


struct pt {
    using T = int;
    using V = int64_t;
    T x = 0, y = 0;
    pt() = default;
    pt(T x, T y) : x(x), y(y) {}
    inline pt& operator-=(const pt& other) {
        x -= other.x;
        y -= other.y;
        return *this;
    }
    inline pt operator-(const pt& other) const {
        pt copy(*this);
        copy -= other;
        return copy;
    }
    inline pt& operator+=(const pt& other) {
        x += other.x;
        y += other.y;
        return *this;
    }
    inline pt operator+(const pt& other) const {
        pt copy(*this);
        copy += other;
        return copy;
    }
    V operator^(const pt& other) const {
        return (V)x * other.y - (V)y * other.x;
    }
    V operator*(const pt& other) const {
        return (V)x * other.x + (V)y * other.y;
    }
    void print() const {
        cerr << x << " " << y << "\n";
    }
    bool operator==(const pt&) const = default;
};


inline bool in_triangle(const pt& a, const pt& b, const pt& c, const pt& point) {
    int64_t s1 = abs((b - a) ^ (c - a));
    int64_t s2 = abs((a - point) ^ (b - point)) + abs((b - point) ^ (c - point)) + abs((c - point) ^ (a - point));
    return s1 == s2;
}

struct mi {
    size_t i = 0;
    size_t ni = 1;
    const size_t m;
    mi(size_t m) : m(m) {}
    void add() {
        ++i;
        if (++ni == m) ni = 0;
    }
};
int64_t orientation(pt a, pt b, pt c) {
    return -((int64_t)a.x * (b.y - c.y) + (int64_t)b.x * (c.y - a.y) + (int64_t)c.x * (a.y - b.y));
}
inline bool comp(pt a, pt b) {
    auto cp = a ^ b;
    if (!cp) {
        return a * a < b * b;
    }
    return (pt::V)a.x * b.x < 0 ? (a.x > b.x) : cp > 0;
}

struct NMP {
    array<pt, 13> pts;
    int len = 0;
    template<typename... Args>
    void emplace_back(Args&& ...p) {
        new (&pts[len++]) pt(p...);
    }
    void push_back(const pt& x) {
        pts[len++] = x;
    }
    pt& operator[](size_t x) {
        return pts[x];
    }
    size_t size() const {
        return len;
    }

    const pt& operator[](size_t x) const {
        return pts[x];
    }
    pt* begin() {
        return &pts[0];
    }
    pt* end() {
        return &pts[len];
    }
    void resize(size_t x) {
        len = x;
    }
};

struct poly {
    using P = pt;
    NMP pts;
    void add(const P& p) {
        pts.push_back(p);
    }
    
    template<typename... Args>
    void emplace(Args&& ...p) {
        pts.emplace_back(p...);
    }

    void sort() {
        size_t min_id = 0;
        for (size_t i = 1; i < pts.size(); ++i) {
            if (pts[i].y < pts[min_id].y || (pts[i].y == pts[min_id].y && pts[i].x < pts[min_id].x)) {
                min_id = i;
            }
        }
        std::rotate(pts.begin(), pts.begin() + min_id, pts.end());
        auto p0 = pts[0];
        std::sort(pts.begin(), pts.end(), [&](const P& a, const P& b) {
            auto o = orientation(p0, a, b);
            if (!o)
                return (int64_t)(p0.x-a.x)*(p0.x-a.x) + (int64_t)(p0.y-a.y)*(p0.y-a.y)
                    < (int64_t)(p0.x-b.x)*(p0.x-b.x) + (int64_t)(p0.y-b.y)*(p0.y-b.y);
            return o < 0;
        });
    }

    void no_coll() {
        if (pts.size() < 3) {
            return;
        }
        size_t ptr = 1;
        for (size_t j = 2; j < pts.size(); ++j) {
            if ((pts[ptr] - pts[ptr - 1]) ^ (pts[j] - pts[ptr])) {
                pts[++ptr] = pts[j];
                continue;
            }
            pts[ptr] = pts[j];
        }
        pts.resize(ptr + 1);
    }

    poly operator+(const poly& other) const {
        if (pts.size() == 1) {
            poly c(other);
            for (auto& p: c.pts) p += pts[0];
            return c;
        }
        if (other.pts.size() < pts.size()) {
            return other + *this;
        }
        // size at least 2s
        poly res;
        mi i(pts.size()), j(other.pts.size());

        while (i.i < pts.size() && j.i < other.pts.size()) {
            res.emplace(pts[i.i] + other.pts[j.i]);
            auto a = (pts[i.ni] - pts[i.i]);
            auto b = (other.pts[j.ni] - other.pts[j.i]);
            auto cp = a ^ b;
            if (cp < 0) {
                j.add();
            } else if (cp > 0) {
                i.add();
            } else if ((P::V)a.y * b.y >= 0) {
                i.add();
                j.add();
            } else if (a.y > b.y) {
                i.add();
            } else {
                j.add();
            }
        }
        while (i.i < pts.size()) {
            res.emplace(pts[i.i] + other.pts[0]);
            i.add();
        }
        
        while (j.i < other.pts.size()) {
            res.emplace(pts[0] + other.pts[j.i]);
            j.add();
        }
        
        res.no_coll();
        return res;
    }

    void print() {
        for (auto &e: pts) {
            cout << "(" << e.x << " " << e.y << ") ";
        }
        cout << "\n";
    }

    bool in(const pt& p) const {
        if (pts.size() == 1) {
            return pts[0] == p;
        }
        if (pts.size() == 2) {
            return ((pts[0] - p) ^ (pts[1] - p)) == 0 
                && min(pts[0].x, pts[1].x) <= p.x && p.x <= max(pts[0].x, pts[1].x)
                && min(pts[0].y, pts[1].y) <= p.y && p.y <= max(pts[0].y, pts[1].y);
        }
        for (int i = 2; i < pts.size(); ++i) {
            if (in_triangle(pts[i], pts[i - 1], pts[0], p)) {
                return true;
            }
        }
        return false;
    }
};


struct co {
    array<int, 3> cst {};
    poly p;
    co() {
        p.emplace(0, 0);
    }

    co(int l, int a, int b) {
        cst = {
            max(0, 1 + l - (a == 0) - (b == 0)) / 2,
            max(0, 1 + l - (a == 1) - (b == 1)) / 2,
            max(0, 1 + l - (a == 2) - (b == 2)) / 2
        };
        p.emplace(min(cst[0], l - cst[2]), max(0, l - cst[0] - cst[2]));
        p.emplace(min(cst[0], l), max(0, l - cst[0] - cst[2]));
        p.emplace(cst[0], min(cst[1], l - cst[0]));
        p.emplace(min(l - cst[1], cst[0]), cst[1]);
        p.emplace(max(0, l - cst[1] - cst[2]), min(l, cst[1]));
        p.emplace(max(0, l - cst[1] - cst[2]), min(cst[1], l - cst[2]));
        p.sort();
        p.no_coll();
    }

    co operator+(const co& rhs) {
        co res;
        res.p = p + rhs.p;
        for (int j = 0; j < 3; ++j) res.cst[j] = cst[j] + rhs.cst[j];
        return res;
    }

    bool ok(int x, int y, int z) {
        return x <= cst[0] && y <= cst[1] && z <= cst[2]; 
    }

    bool in(int x, int y, int z) {
        return ok(x, y, z) && p.in(pt(x, y));
    }
};

char idx[128]{};
string ydx = "YDX";

struct fenwick {
    fenwick(int x) : t(x), n(x) {}
    vector<int> t;
    int n;
    int sum (int r) {
        int result = 0;
        for (; r >= 0; r = (r & (r+1)) - 1)
            result += t[r];
        return result;
    }

    void inc (int i, int delta) {
        for (; i < n; i = (i | (i+1)))
            t[i] += delta;
    }
};

using S = std::list<pair<short, int>>;

struct cmp {
    bool operator()(S::iterator a, S::iterator b) const {
        return a->second < b->second;
    };
};

auto encode1(auto a, auto b) {
    return a * 256 + b;
};

auto encode(auto it) {
    auto prev = it++;
    return encode1(prev->first, it->first);
};

auto erase_char(auto& curr_pos, S& str, fenwick& alive, auto& pos, auto it) {
    auto curr = it;
    auto prev = --it;
    it = curr;
    auto next = ++it;
    if (next != str.end()) {
        if (!pos[encode(curr)].count(curr)) {
            exit(-1);
        }
        pos[encode(curr)].erase(curr);
    }
    if (prev != str.end()) {
        if (!pos[encode(prev)].count(prev)) {
            exit(-1);
        }
        pos[encode(prev)].erase(prev);
    }
    curr_pos.emplace_back(curr->first, alive.sum(curr->second) - 1);
    alive.inc(curr->second, -1);
    str.erase(curr);
    if (next != str.end() && prev != str.end()) {
        auto p = prev;
        ++p;
        if (p != next) {
            exit(-1);
        }
        pos[encode(prev)].emplace(prev);
    }
};

bool is_ok(S::iterator x, S::iterator end) {
    auto curr = x;
    auto prev = --x;
    auto next = ++curr;
    if (prev != end && next != end) {
        return prev->first != next->first;
    }
    return true;
}

auto got(auto& curr_pos, auto& str, auto& alive, auto& pos, vector<S::iterator> t) {
    for (auto &e: t) {
        erase_char(curr_pos, str, alive, pos, e);
    }
};


auto relax(auto& curr_pos, auto& str, auto& alive, auto& pos, short sym, short co) {
    auto &v = pos[co];
    auto it = *v.begin();
    auto A = it;
    auto prev = --it;
    it = A;
    auto B = ++it;
    auto next = ++it;
    if (prev != str.end() && next != str.end() && prev->first == next->first) {
        if (prev->first != sym) {
            exit(-1);
        }
        got(curr_pos, str, alive, pos, {prev, A, B});
        return false;
    }
    
    got(curr_pos, str, alive, pos, {A, B});
    return true;
};

vector<array<pair<char, int>, 3>> solve_str(const string& s) {
    S str;
    fenwick alive(s.size());

    for (int i = 0; i < s.size(); ++i) {
        str.emplace_back(s[i], i);
        alive.inc(i, 1);
    }

    auto it = str.begin();

    map<int, set<decltype(it), cmp>> pos;
    while (it != str.end()) {
        auto prev = it++;
        if (it == str.end()) break;
        pos[encode(prev)].emplace(prev);   
    }
    vector<pair<char, int>> curr_pos;
    vector<decltype(it)> curr_t;
    vector<array<pair<char, int>, 3>> res;
    while (str.size()) {
        it = str.begin();
        auto curr = it++;
        if (it == str.end()) {
            exit(-1);
        }
        short code = curr->first;
        erase_char(curr_pos, str, alive, pos, curr);

        array<int, 2> candidates;
        if (code == 'Y') {
            candidates[0] = encode1('D', 'X');
            candidates[1] = encode1('X', 'D');
        } else if (code == 'X') {
            candidates[0] = encode1('D', 'Y');
            candidates[1] = encode1('Y', 'D');
        } else {
            candidates[0] = encode1('Y', 'X');
            candidates[1] = encode1('X', 'Y');
        }
        bool ok = 0;
        while (!ok) {
            for (auto &c: candidates) {
                if (!pos[c].size()) {
                    continue;
                }
                if (relax(curr_pos, str, alive, pos, code, c)) {
                    ok = 1;
                    res.emplace_back();
                    res.back()[0] = curr_pos[2];
                    res.back()[1] = curr_pos[1];
                    res.back()[2] = curr_pos[0];
                    curr_pos.clear();
                    break;
                }
                // A...ABCA, ABC removed
                res.emplace_back();
                for (int j = 0; j < 3; ++j) {
                    res.back()[j] = curr_pos.back(); // removed
                    res.back()[j].second += 1;
                    curr_pos.pop_back();
                }
                break;
            }
        }
    }
    reverse(res.begin(), res.end());
    return res;
}

bool check(const string& s) {
    array<int, 3> cnt{};
    char prev = -1;
    for (auto &e: s) {
        if (e == '?') {
            return false;
        }
        if (e != 'Y' && e != 'D' && e != 'X') {
            return false;
        }
        if (e == prev) return false;
        prev = e;
        ++cnt[idx[e]];
    }
    return cnt[0] == s.size() / 3 && cnt[1] == s.size() / 3 && cnt[2] == s.size() / 3;
}

optional<string> solve_fast1(string v) {
    auto sv = v;
    int N = v.size() / 3;
    array<int, 3> rem{N, N, N};
    for (auto &e: v) {
        if (e == '?') continue;
        --rem[idx[e]];
    }
    if (rem[0] < 0 || rem[1] < 0 || rem[2] < 0) return {};
    vector<co> mink;
    vector<pair<int, int>> segs;
    for (int i = 0; i < v.size(); ++i) {
        if (v[i] != '?') continue;
        int j = i + 1;
        while (j < v.size() && v[j] == '?') ++j;
        mink.emplace_back(j - i, i > 0 ? idx[v[i - 1]] : 3, j < v.size() ? idx[v[j]] : 3);
        segs.emplace_back(i, j - 1);
        i = j - 1;
    }
    reverse(mink.begin(), mink.end());
    reverse(segs.begin(), segs.end());
    for (int i = 1; i < mink.size(); ++i) {
        mink[i] = mink[i - 1] + mink[i];
    }
    if (mink.size()) {
        mink.pop_back();
    }
    while (segs.size()) {
        auto seg = segs.back();
        segs.pop_back();
        auto mk = mink.size() ? mink.back() : co();
        if (mink.size()) {
            mink.pop_back();
        }
        char prev = idx[seg.first ? v[seg.first - 1] : '?'];
        char next_r = idx[seg.second + 1 < v.size() ? v[seg.second + 1] : '?'];
        while (seg.first <= seg.second) {
            char next = seg.first == seg.second ? next_r : -1;
            bool found = 0;
            for (int j = 0; j < 3; ++j) {
                if (prev == j || next == j || !rem[j]) {
                    continue;
                }
                --rem[j];
                auto cs = co(seg.second - seg.first, j, seg.second + 1 < v.size() ? idx[v[seg.second + 1]] : 3);
                auto vv = mk + cs;
                if (!vv.in(rem[0], rem[1], rem[2])) {
                    ++rem[j];
                    continue;
                }
                v[seg.first++] = ydx[j];
                prev = j;
                found = 1;
                break;
            }
            if (!found) {
                return {};
            }
        }
    }
    return v;
}

optional<pair<vector<array<pair<char, int>, 3>>, string>> solve(string s) {
    auto ww = solve_fast1(s);
    if (!ww || !check(*ww)) {
        return {};
    }
    return pair{solve_str(*ww), *ww};
}

signed main() {
    ios::sync_with_stdio(0);
    cin.tie(0);
    cout.tie(0);
    idx['Y'] = 0;
    idx['D'] = 1;
    idx['X'] = 2;
    idx['?'] = 99;
    int t;
    cin >> t;
    while (t--) {
        string s;
        cin >> s;
        auto r = solve(s);
        if (r) {
            cout << "YES\n" << r->second << "\n";
            for (auto &x: r->first) {
                for (auto &e: x) {
                    cout << e.first << " " << e.second << " ";
                }
                cout << "\n";
            }
        } else {
            cout << "NO\n";
        }
    }
}

#include <bits/stdc++.h>
#include <ext/pb_ds/assoc_container.hpp>

#define F first
#define S second
#define all(x) x.begin(), x.end()
#define pb push_back
#define FIO ios_base::sync_with_stdio(false); cin.tie(0); cout.tie(0)

using namespace std;
using namespace __gnu_pbds;

typedef long long ll;
typedef pair <int, int> pii;

typedef tree<pii, null_type, less<pii>, rb_tree_tag, tree_order_statistics_node_update> oset;

void task() {
	int n; cin >> n;
	vector <pii> c;
	vector <int> v;
	for (int i = 0; i < n; i++) {
		int x, y; cin >> x >> y;
		c.pb({x, y});
		v.pb(i);
	}
	oset a, b;
	sort(all(v), [&](int x, int y) {return c[x].F < c[y].F;});
	int res = 0, rx = 0, ry = 0;
	for (int i = 0; i < n; i++) b.insert({c[i].S, i});
	for (int i = 0; i < n; i++) {
		int x = v[i];
		a.insert({c[x].S, x});
		b.erase({c[x].S, x});
		if (i < n-1 && c[x].F == c[v[i+1]].F) continue;
		while (1) {
			if (a.size() < res+1 || b.size() < res+1) break;
			int l1 = a.find_by_order(res)->F, r1 = a.find_by_order(a.size()-res-1)->F-1, l2 = b.find_by_order(res)->F, r2 = b.find_by_order(b.size()-res-1)->F-1;
			if (max(l1, l2) <= min(r1, r2)) res++, rx = c[x].F, ry = max(l1, l2);
			else break;
		}
	}
	cout << res << "\n" << rx+1 << " " << ry+1 << "\n";
}

int main () {
	FIO;
	int tt; cin >> tt;
	while (tt--) task();

	return 0;
}


[Editorial - contest/2047]
NT = int(input())

sqs = set()
k = 1
while k * k <= 100 * 1000:
	sqs.add(k * k)
	k += 2

for T in range(NT):
	n = int(input())
	a = list(map(int, input().split()))
	answer = 0
	cursum = 0
	for t in a:
		cursum += t
		if cursum in sqs:
			answer += 1
	print(answer)

#include <bits/stdc++.h>

using namespace std;

int main() {
    cin.tie(0)->sync_with_stdio(0);
    int t;
    cin >> t;
    while (t--) {
        int n;
        cin >> n;
        string s;
        cin >> s;
        vector<int> occ(26);
        for (int i=0; i<n; i++)
            occ[s[i] - 'a'] += 1;
        pair<pair<int,char>,int> low, high;
        low = high = {{occ[s[0] - 'a'], s[0]}, 0};
        for (int i=1; i<n; i++) {
            low = min(low, {{occ[s[i] - 'a'], s[i]}, i});
            high = max(high, {{occ[s[i] - 'a'], s[i]}, i});
        }
        s[low.second] = s[high.second];
        cout << s << "\n";
    }
  return 0;
}
for _ in range(int(input())):
    n = int(input())
    a = []
    for i in range(2):
        a.append(list(map(int, input().split())))
    best = [max(a[0][i], a[1][i]) for i in range(n)]
    full = [a[0][i] + a[1][i] for i in range(n)]
    sum_best = sum(best)
    ans = -10 ** 19
    for i in range(n):
        ans = max(ans, sum_best + full[i] - best[i])
    print(ans)
#include <bits/stdc++.h>

using namespace std;

#ifdef LOCAL
    #define eprintf(...) fprintf(stderr, __VA_ARGS__)
#else
    #define eprintf(...) 42
#endif

using ll = long long;
using ld = long double;
using D = double;
using uint = unsigned int;
template<typename T>
using pair2 = pair<T, T>;

#define pb push_back
#define mp make_pair
#define all(x) (x).begin(),(x).end()
#define fi first
#define se second
mt19937_64 rng(chrono::steady_clock::now().time_since_epoch().count());

void solve()
{
	int n;
	scanf("%d", &n);
	vector<int> a(n);
	for (int i = 0; i < n; i++) scanf("%d", &a[i]);
	vector<int> front(n);
	int frontfront = n;
	int frontback = n;
	multiset<int> back;
	for (int i = n - 1; i >= 0; i--)
	{
		if (frontfront >= frontback || a[i] <= front[frontfront]) front[--frontfront] = a[i];
		else back.insert(a[i] + 1);
		while (frontfront < frontback && !back.empty() && front[frontback - 1] > *back.begin())
		{
			back.insert(front[frontback - 1] + 1);
			frontback--;
		}
	}
	vector<int> answer;
	for (int i = frontfront; i < frontback; i++) answer.pb(front[i]);
	for (auto t : back) answer.pb(t);
	for (auto t : answer) printf("%d ", t);
	printf("\n");
}

int main()
{
    int NT = 1;
    scanf("%d", &NT);
    for (int T = 1; T <= NT; T++)
    {
        solve();
    }
    return 0;
}

#include <math.h>
#include <unordered_set>
#include <unordered_map>
#include <map>
#include <iostream>
#include <fstream>
#include <vector>
#include <set>
#include <array>
#include <cstring>
#include <ctime>
#include <cassert>
#include <string_view>
#include <functional>
#include <sstream>
#include <numeric>
#include <cmath>
#include <deque>
#include <list>
#include <algorithm>
#include <iomanip>
 
using namespace std;
 
using i64 = long long;
using ui32 = unsigned int;
using ui64 = unsigned long long;
 
#define all(a) (a).begin(), (a).end()
 
 
struct Tree;
 
Tree* NewNode();
 
struct Count {
    int left = 0;
    int right = 0;
    void Add(int delta) {
        left += delta;
        if (delta < 0) {
            right -= delta;
        }
    }
    void operator += (const Count& c) {
        left += c.left;
        right += c.right;
    }
 
    int GetMin() {
        return min(left, right);
    }
};
 
struct Tree {
        Count count;
        Tree* left = nullptr;
        Tree* right = nullptr;
 
        void Add(int l, int r, int p, int delta = 1) {
            count.Add(delta);
            if (r - l == 1) {
                return;
            }
            int mid = (l + r) / 2;
            if (p < mid) {
                if (left == nullptr) {
                    left = NewNode();
                }
                left->Add(l, mid, p, delta);
            } else {
                if (right == nullptr) {
                    right = NewNode();
                }
                right->Add(mid, r, p, delta);
            }
        } 
 
        Count LeftCount() {
            if (left) {
                return left->count;
            }
            return {};
        }
        Count RightCount() {
            if (right) {
                return right->count;
            }
            return {};
        }
 
        void Remove(int l, int r, int p) {
            Add(l, r, p, -1);
        }
};
 
Tree nodes[7000000];
 
Tree* NewNode() {
    static Tree* nextNode = nodes;
    return nextNode++;
}
 
 
struct Solver {
    struct Point {
        int x, y;
        bool operator < (const Point& p) const {
            return x < p.x;
        }
    };
 
    int max = 0;
    int bx = 0;
    int by = 0;
 
    bool FindBest(int l, int r, Tree* node, const Count& left = {}, const Count& right = {}) {
        if (node == nullptr) {
            return false;
        }
        int mid = (l + r) / 2;
        Count newLeft = node->LeftCount();
        Count newRight = node->RightCount();
        newLeft += left;
        newRight += right;
        int mn = min(newLeft.GetMin(), newRight.GetMin());
        bool updated = false;
        if (mn > max) {
            max = mn;
            by = mid;
            updated = true;
        }
        if (mn == newLeft.GetMin()) {
            if (FindBest(mid, r, node->right, newLeft, right)) {
                return true;
            }
        } else {
            if (FindBest(l, mid, node->left, left, newRight)) {
                return true;
            }
        }
        return updated;
    }
 
    void Solve(istream& cin, ostream& cout) {
        int n;
        cin >> n;
        vector<Point> a(n);
        int t9 = 1000000001;
        #ifdef pperm
            t9 = 100;
        #endif
        Tree* tree = NewNode();
        for (Point& p : a) {
            cin >> p.x >> p.y;
            tree->Add(-t9, t9, p.y);
        }
        sort(all(a));
        for (int i = 0; i < n;) {
            int j = i + 1;
            while (j < n && a[j].x == a[i].x) {
                ++j;
            }
            if (FindBest(-t9, t9, tree)) {
                bx = a[i].x;
            }
            for (;i < j; ++i) {
                tree->Remove(-t9, t9, a[i].y);
 
            }
        }
        cout << max << '\n' << bx << ' ' << by << endl;
    }
};
 
int main(int argc, char* args[]) {
#ifdef pperm
    ifstream cin("/home/pperm86/My/Codeforces/input.txt");
#endif
    ios_base::sync_with_stdio(false);
    cin.tie(NULL);
#ifndef pperm
    srand(time(0));
#endif
    int T = 1;
    cin >> T;
    for (int iTest = 1; iTest <= T; ++iTest) {
		Solver solver{};
        solver.Solve(cin, cout);
    }
#ifdef pperm
    cout << clock() / static_cast<double>(CLOCKS_PER_SEC) << endl;
#endif
    return 0;
}
#define _CRT_SECURE_NO_WARNINGS

#include<iostream>
#include<fstream>
#include<vector>
#include<stack>
#include<queue>
#include<set>
#include<map>
#include<array>
#include<unordered_set>
#include<unordered_map>
#include<cstring>
#include<string>
#include<memory>
#include<iomanip>
#include<cassert>
#include<cmath>
#include<random>
#include<algorithm>
#include<chrono>

#pragma GCC optimize("O3,unroll-loops")
#pragma GCC target("avx2,bmi,bmi2,lzcnt,popcnt")

#define int long long
#define ld long double
#define endl '\n'

using namespace std;


constexpr int N = 500;
vector<int> g[N], gr[N], gcmp[N];
int a[N], acmp[N], used[N], color[N], cur_color = 0;
vector<int> order, cmp;

void dfs1(int u) {
	for (int v : g[u]) {
		if (used[v] == 0) {
			used[v] = 1;
			dfs1(v);
		}
	}
	order.push_back(u);
}

void dfs2(int u) {
	for (int v : gr[u]) {
		if (used[v] == 0) {
			used[v] = 1;
			dfs2(v);
		}
	}
	color[u] = cur_color;
}

inline array<int, 3> getInd(int u) {
	return { 3 * u, 3 * u + 1, 3 * u + 2 };
}

constexpr int INF = 0x3f3f3f3f;

struct MCMF {
	struct rib {
		int b, u, c, f;
		size_t back;
	};

	MCMF(int size) : n(size), g_mcmf(size) {};

	int n;
	vector<vector<rib>> g_mcmf;

	void rebuild(int sz) {
		n = sz, g_mcmf.clear(); g_mcmf.resize(sz);
	}

	void add_rib(int a, int b, int u, int c) {
		rib r1 = { b, u, c, 0, g_mcmf[b].size() };
		rib r2 = { a, 0, -c, 0, g_mcmf[a].size() };
		g_mcmf[a].push_back(r1);
		g_mcmf[b].push_back(r2);
	}

	pair<int, int> get_flow(int s, int t, int maxflow = INF) {
		int flow = 0, cost = 0;
		while (flow < maxflow) {
			vector<int> id(n, 0);
			vector<int> d(n, INF);
			vector<int> q(n);
			vector<int> p(n);
			vector<size_t> p_rib(n);
			int qh = 0, qt = 0;
			q[qt++] = s;
			d[s] = 0;
			while (qh != qt) {
				int v = q[qh++];
				id[v] = 2;
				if (qh == n)  qh = 0;
				for (size_t i = 0; i < g_mcmf[v].size(); ++i) {
					rib& r = g_mcmf[v][i];
					if (r.f < r.u && d[v] + r.c < d[r.b]) {
						d[r.b] = d[v] + r.c;
						if (id[r.b] == 0) {
							q[qt++] = r.b;
							if (qt == n)  qt = 0;
						}
						else if (id[r.b] == 2) {
							if (--qh == -1)  qh = n - 1;
							q[qh] = r.b;
						}
						id[r.b] = 1;
						p[r.b] = v;
						p_rib[r.b] = i;
					}
				}
			}

			if (d[t] == INF)  break;
			int addflow = maxflow - flow;
			for (int v = t; v != s; v = p[v]) {
				int pv = p[v];  size_t pr = p_rib[v];
				addflow = min(addflow, g_mcmf[pv][pr].u - g_mcmf[pv][pr].f);
			}
			for (int v = t; v != s; v = p[v]) {
				int pv = p[v];  size_t pr = p_rib[v], r = g_mcmf[pv][pr].back;
				g_mcmf[pv][pr].f += addflow;
				g_mcmf[v][r].f -= addflow;
				cost += g_mcmf[pv][pr].c * addflow;
			}
			flow += addflow;
		}
		return { flow, cost };
	}
};

void solve() {
	
	for (int i =0 ; i < N; i++)
	{
		g[i] = {};
		gr[i] = {};
		gcmp[i] = {};
	}
	memset(a, 0, sizeof a);
	memset(acmp, 0, sizeof acmp);
	memset(used, 0, sizeof used);
	memset(color, 0, sizeof color);
	cur_color = 0;
	order = {};
	cmp = {};
	
	int n, m; cin >> n >> m;
	for (int i = 0; i < n; i++) {
		g[i].clear();
		gr[i].clear();
	}

	for (int i = 0; i < n; i++) cin >> a[i];

	for (int i = 0; i < m; i++) {
		int u, v; cin >> u >> v; u--, v--;
		g[u].push_back(v);
		gr[v].push_back(u);
	}

	order.clear();
	memset(used, 0, sizeof(used[0]) * n);
	for (int i = 0; i < n; i++) {
		if (used[i] == 0) {
			used[i] = 1;
			dfs1(i);
		}
	}

	memset(used, 0, sizeof(used[0]) * n);
	for (int i = 0; i < n; i++) {
		int u = order[n - i - 1];
		if (used[u] == 0) {
			used[u] = 1;
			dfs2(u);
			cur_color++;
		}
	}

	// for (int i = 0; i < n; i++) cout << color[i] << " "; cout << endl;

	memset(acmp, 0, sizeof(acmp[0]) * cur_color);
	for (int i = 0; i < n; i++) {
		acmp[color[i]] += a[i];
		for (int v : g[i]) {
			if (color[i] != color[v]) {
				gcmp[color[i]].push_back(color[v]);
			}
		}
	}

	for (int i = 0; i < cur_color; i++) {
		auto& e = gcmp[i];
		sort(e.begin(), e.end());
		e.erase(unique(e.begin(), e.end()), e.end());

		// cout << i << " " << acmp[i] << ": ";
		// for (int v : e) cout << v << " "; cout << endl;
	}

	int s = 3 * cur_color, t = s + 1, so = t + 1, to = so + 1;
	MCMF gg(to + 1);

	for (int i = 0; i < cur_color; i++) {
		auto [uin, uout, ucnt] = getInd(i);
		gg.add_rib(s, ucnt, acmp[i], 0);
		gg.add_rib(ucnt, uin, 1, 1);
		gg.add_rib(ucnt, uout, INF, 0);

		gg.add_rib(uin, uout, INF, 0);
		gg.add_rib(uout, t, INF, 0);

		gg.add_rib(so, uout, 1, 0);
		gg.add_rib(uin, to, 1, 0);
	}

	gg.add_rib(t, s, INF, 0);

	for (int i = 0; i < cur_color; i++) {
		auto [uin, uout, ucnt] = getInd(i);
		for (int v : gcmp[i]) {
			auto [vin, vout, vcnt] = getInd(v);
			gg.add_rib(uout, vin, INF, 0);
		}
	}

	auto [flow, cost] = gg.get_flow(so, to);
	// cout << flow << " " << cost << endl;

	if (flow < cur_color) {
		cout << -1 << endl;
		return;
	}

	cout << cost << endl;
}

signed main() {
	// freopen("input.txt", "r", stdin);
	ios_base::sync_with_stdio(false);
	cin.tie(0); cout.tie(0);

	int q; cin >> q; while (q--)
	solve();
}

/**
 *    author:  tourist
 *    created: 01.12.2024 18:36:51
**/
#undef _GLIBCXX_DEBUG

#include <bits/stdc++.h>

using namespace std;

#ifdef LOCAL
#include "algo/debug.h"
#else
#define debug(...) 42
#endif

int main() {
  ios::sync_with_stdio(false);
  cin.tie(nullptr);
  int tt;
  cin >> tt;
  while (tt--) {
    int n, m;
    cin >> n >> m;
    vector<int> a(n), b(n), c(n);
    set<int> s;
    for (int i = 0; i < n; i++) {
      cin >> a[i] >> b[i] >> c[i];
      s.insert(c[i]);
    }
    vector<vector<int>> vs(m);
    for (int i = 0; i < m; i++) {
      int foo;
      cin >> foo;
      vs[i].resize(foo);
      for (int j = 0; j < foo; j++) {
        cin >> vs[i][j];
        --vs[i][j];
      }
    }
    const int inf = int(1.01e9);
    vector<int> min_a(m, inf);
    vector<int> max_a(m, -1);
    for (int i = 0; i < m; i++) {
      for (int j : vs[i]) {
        min_a[i] = min(min_a[i], a[j]);
        max_a[i] = max(max_a[i], a[j]);
      }
    }
    auto Unify = [&](vector<pair<int, int>>& bad) {
      sort(bad.begin(), bad.end());
      int ptr = 0;
      for (int i = 1; i < int(bad.size()); i++) {
        if (bad[i].first <= bad[ptr].second + 1) {
          bad[ptr].second = max(bad[ptr].second, bad[i].second);
        } else {
          bad[++ptr] = bad[i];
        }
      }
      bad.resize(ptr + 1);
    };
    vector<pair<int, int>> bad;
    for (int id = 0; id < m - 1; id++) {
      if (min_a[id] < max_a[id + 1]) {
        bad.emplace_back(min_a[id] + 1, max_a[id + 1]);
      }
    }
    Unify(bad);
    vector<int> ctr(n);
    for (int i = 0; i < m; i++) {
      for (int x : vs[i]) {
        ctr[x] = i;
      }
    }
    vector<pair<int, int>> tasks;
    int unused = 0;
    vector<int> order(n);
    iota(order.begin(), order.end(), 0);
    sort(order.begin(), order.end(), [&](int i, int j) {
      return a[i] > a[j];
    });
    multiset<int> before, after;
    for (int i = 0; i < n; i++) {
      after.insert(ctr[i]);
    }
    {
      int beg = 0;
      while (beg < n) {
        int end = beg;
        while (end + 1 < n && a[order[end + 1]] == a[order[end]]) {
          end += 1;
        }
        for (int i = beg; i <= end; i++) {
          before.insert(ctr[order[i]]);
          after.erase(after.find(ctr[order[i]]));
        }
        if (!before.empty() && !after.empty() && *prev(before.end()) <= *after.begin()) {
          for (int i = 0; i < 2; i++) {
            do {
              unused += 1;
            } while (s.find(unused) != s.end());
            tasks.emplace_back(a[order[end]], unused);
          }
        }
        beg = end + 1;
      }
    }
    map<int, int> add;
    for (int id = 0; id < m - 1; id++) {
      for (int i : vs[id]) {
        if (a[i] <= max_a[id + 1]) {
          if (add.find(c[i]) == add.end()) {
            add[c[i]] = b[i];
          } else {
            add[c[i]] = min(add[c[i]], b[i]);
          }
        }
      }
    }
    map<int, vector<pair<int, int>>> kill;
    for (int id = 1; id < m; id++) {
      for (int i : vs[id]) {
        if (a[i] >= min_a[id - 1]) {
          kill[c[i]].push_back({min_a[id - 1] + 1, b[i]});
        }
      }
    }
    for (auto& [type, x] : add) {
      auto& k = kill[type];
      Unify(k);
      int dif = x;
      while (true) {
        bool changed = false;
        {
          auto it = lower_bound(bad.begin(), bad.end(), make_pair(dif + 1, -1));
          if (it != bad.begin()) {
            it = prev(it);
            if (it->second >= dif) {
              dif = it->first - 1;
              changed = true;
            }
          }
        }
        {
          auto it = lower_bound(k.begin(), k.end(), make_pair(dif + 1, -1));
          if (it != k.begin()) {
            it = prev(it);
            if (it->second >= dif) {
              dif = it->first - 1;
              changed = true;
            }
          }
        }
        if (!changed) {
          break;
        }
      }
      tasks.emplace_back(dif, type);
    }
    debug(tasks);
    vector<int> all;
    map<int, int> spec;
    for (auto& [x, y] : tasks) {
      all.push_back(x);
      assert(spec.find(y) == spec.end());
      spec[y] = x;
    }
    sort(all.begin(), all.end());
    vector<int> solved(n);
    for (int i = 0; i < n; i++) {
      solved[i] = int(upper_bound(all.begin(), all.end(), a[i]) - all.begin());
      if (spec.find(c[i]) != spec.end() && spec[c[i]] > a[i] && spec[c[i]] <= b[i]) {
        solved[i] += 1;
      }
    }
    vector<int> min_solved(m, inf);
    vector<int> max_solved(m, -1);
    for (int i = 0; i < m; i++) {
      for (int j : vs[i]) {
        min_solved[i] = min(min_solved[i], solved[j]);
        max_solved[i] = max(max_solved[i], solved[j]);
      }
    }
    bool win = true;
    for (int id = 0; id < m - 1; id++) {
      if (min_solved[id] <= max_solved[id + 1]) {
        win = false;
        break;
      }
    }
    if (win) {
      cout << tasks.size() << '\n';
      for (auto& [x, y] : tasks) {
        cout << x << " " << y << '\n';
      }
    } else {
      cout << -1 << '\n';
    }
  }
  return 0;
}

#pragma GCC optimize("Ofast")
#include <iostream>
#include <cmath>
#include <cstdint>
#include <vector>
#include <string>
#include <iomanip>
#include <set>
#include <map>
#include <unordered_map>
#include <unordered_set>
#include <algorithm>
#include <functional>
#include <queue>
#include <fstream>
#include <random>
//#include <numbers>
#include <optional>
#include <deque>
#include <sstream>
#include <list>
#include <chrono>
#include <thread>
#include <cassert>
 
using namespace std;
using i64 = int64_t;
using ui64 = uint64_t;
#define YN(b) if (b) cout << "YES\n"; else cout << "NO\n";
 
template<typename T>
istream& operator>>(istream& is, vector<T>& v) { for (auto &e: v) { is >> e; } return is; }
 
template<typename T>
ostream& operator<<(ostream& os, vector<T>& v) { for (auto &e: v) { os << e << " "; } return os; }
 
template<typename T, typename V>
istream& operator>>(istream& is, pair<T, V>& v) { return is >> v.first >> v.second; }
 
template<typename T, typename V>
ostream& operator<<(ostream& os, pair<T, V>& v) { return os << v.first << " " << v.second; }
 
const int64_t md = 1e9+7;

int dx[4] = {-1, 0, 1, 0};
 
inline int64_t sqr(int64_t x) {
    return x * x;
}
 
inline int popcount(int64_t x) {
    int c = 0;
    while (x) c += x & 1, x >>= 1;
    return c;
}
 
pair<int64_t, int64_t> inter(pair<int64_t, int64_t> a, pair<int64_t, int64_t> b) {
    return {max(a.first, b.first), min(a.second, b.second)};
}


struct pt {
    using T = int;
    using V = int64_t;
    T x = 0, y = 0;
    pt() = default;
    pt(T x, T y) : x(x), y(y) {}
    inline pt& operator-=(const pt& other) {
        x -= other.x;
        y -= other.y;
        return *this;
    }
    inline pt operator-(const pt& other) const {
        pt copy(*this);
        copy -= other;
        return copy;
    }
    inline pt& operator+=(const pt& other) {
        x += other.x;
        y += other.y;
        return *this;
    }
    inline pt operator+(const pt& other) const {
        pt copy(*this);
        copy += other;
        return copy;
    }
    V operator^(const pt& other) const {
        return (V)x * other.y - (V)y * other.x;
    }
    V operator*(const pt& other) const {
        return (V)x * other.x + (V)y * other.y;
    }
    void print() const {
        cerr << x << " " << y << "\n";
    }
    bool operator==(const pt&) const = default;
};


inline bool in_triangle(const pt& a, const pt& b, const pt& c, const pt& point) {
    int64_t s1 = abs((b - a) ^ (c - a));
    int64_t s2 = abs((a - point) ^ (b - point)) + abs((b - point) ^ (c - point)) + abs((c - point) ^ (a - point));
    return s1 == s2;
}

struct mi {
    size_t i = 0;
    size_t ni = 1;
    const size_t m;
    mi(size_t m) : m(m) {}
    void add() {
        ++i;
        if (++ni == m) ni = 0;
    }
};
int64_t orientation(pt a, pt b, pt c) {
    return -((int64_t)a.x * (b.y - c.y) + (int64_t)b.x * (c.y - a.y) + (int64_t)c.x * (a.y - b.y));
}
inline bool comp(pt a, pt b) {
    auto cp = a ^ b;
    if (!cp) {
        return a * a < b * b;
    }
    return (pt::V)a.x * b.x < 0 ? (a.x > b.x) : cp > 0;
}

struct NMP {
    array<pt, 13> pts;
    int len = 0;
    template<typename... Args>
    void emplace_back(Args&& ...p) {
        new (&pts[len++]) pt(p...);
    }
    void push_back(const pt& x) {
        pts[len++] = x;
    }
    pt& operator[](size_t x) {
        return pts[x];
    }
    size_t size() const {
        return len;
    }

    const pt& operator[](size_t x) const {
        return pts[x];
    }
    pt* begin() {
        return &pts[0];
    }
    pt* end() {
        return &pts[len];
    }
    void resize(size_t x) {
        len = x;
    }
};

struct poly {
    using P = pt;
    NMP pts;
    void add(const P& p) {
        pts.push_back(p);
    }
    
    template<typename... Args>
    void emplace(Args&& ...p) {
        pts.emplace_back(p...);
    }

    void sort() {
        size_t min_id = 0;
        for (size_t i = 1; i < pts.size(); ++i) {
            if (pts[i].y < pts[min_id].y || (pts[i].y == pts[min_id].y && pts[i].x < pts[min_id].x)) {
                min_id = i;
            }
        }
        std::rotate(pts.begin(), pts.begin() + min_id, pts.end());
        auto p0 = pts[0];
        std::sort(pts.begin(), pts.end(), [&](const P& a, const P& b) {
            auto o = orientation(p0, a, b);
            if (!o)
                return (int64_t)(p0.x-a.x)*(p0.x-a.x) + (int64_t)(p0.y-a.y)*(p0.y-a.y)
                    < (int64_t)(p0.x-b.x)*(p0.x-b.x) + (int64_t)(p0.y-b.y)*(p0.y-b.y);
            return o < 0;
        });
    }

    void no_coll() {
        if (pts.size() < 3) {
            return;
        }
        size_t ptr = 1;
        for (size_t j = 2; j < pts.size(); ++j) {
            if ((pts[ptr] - pts[ptr - 1]) ^ (pts[j] - pts[ptr])) {
                pts[++ptr] = pts[j];
                continue;
            }
            pts[ptr] = pts[j];
        }
        pts.resize(ptr + 1);
    }

    poly operator+(const poly& other) const {
        if (pts.size() == 1) {
            poly c(other);
            for (auto& p: c.pts) p += pts[0];
            return c;
        }
        if (other.pts.size() < pts.size()) {
            return other + *this;
        }
        // size at least 2s
        poly res;
        mi i(pts.size()), j(other.pts.size());

        while (i.i < pts.size() && j.i < other.pts.size()) {
            res.emplace(pts[i.i] + other.pts[j.i]);
            auto a = (pts[i.ni] - pts[i.i]);
            auto b = (other.pts[j.ni] - other.pts[j.i]);
            auto cp = a ^ b;
            if (cp < 0) {
                j.add();
            } else if (cp > 0) {
                i.add();
            } else if ((P::V)a.y * b.y >= 0) {
                i.add();
                j.add();
            } else if (a.y > b.y) {
                i.add();
            } else {
                j.add();
            }
        }
        while (i.i < pts.size()) {
            res.emplace(pts[i.i] + other.pts[0]);
            i.add();
        }
        
        while (j.i < other.pts.size()) {
            res.emplace(pts[0] + other.pts[j.i]);
            j.add();
        }
        
        res.no_coll();
        return res;
    }

    void print() {
        for (auto &e: pts) {
            cout << "(" << e.x << " " << e.y << ") ";
        }
        cout << "\n";
    }

    bool in(const pt& p) const {
        if (pts.size() == 1) {
            return pts[0] == p;
        }
        if (pts.size() == 2) {
            return ((pts[0] - p) ^ (pts[1] - p)) == 0 
                && min(pts[0].x, pts[1].x) <= p.x && p.x <= max(pts[0].x, pts[1].x)
                && min(pts[0].y, pts[1].y) <= p.y && p.y <= max(pts[0].y, pts[1].y);
        }
        for (int i = 2; i < pts.size(); ++i) {
            if (in_triangle(pts[i], pts[i - 1], pts[0], p)) {
                return true;
            }
        }
        return false;
    }
};


struct co {
    array<int, 3> cst {};
    poly p;
    co() {
        p.emplace(0, 0);
    }

    co(int l, int a, int b) {
        cst = {
            max(0, 1 + l - (a == 0) - (b == 0)) / 2,
            max(0, 1 + l - (a == 1) - (b == 1)) / 2,
            max(0, 1 + l - (a == 2) - (b == 2)) / 2
        };
        p.emplace(min(cst[0], l - cst[2]), max(0, l - cst[0] - cst[2]));
        p.emplace(min(cst[0], l), max(0, l - cst[0] - cst[2]));
        p.emplace(cst[0], min(cst[1], l - cst[0]));
        p.emplace(min(l - cst[1], cst[0]), cst[1]);
        p.emplace(max(0, l - cst[1] - cst[2]), min(l, cst[1]));
        p.emplace(max(0, l - cst[1] - cst[2]), min(cst[1], l - cst[2]));
        p.sort();
        p.no_coll();
    }

    co operator+(const co& rhs) {
        co res;
        res.p = p + rhs.p;
        for (int j = 0; j < 3; ++j) res.cst[j] = cst[j] + rhs.cst[j];
        return res;
    }

    bool ok(int x, int y, int z) {
        return x <= cst[0] && y <= cst[1] && z <= cst[2]; 
    }

    bool in(int x, int y, int z) {
        return ok(x, y, z) && p.in(pt(x, y));
    }
};

char idx[128]{};
string ydx = "YDX";

struct fenwick {
    fenwick(int x) : t(x), n(x) {}
    vector<int> t;
    int n;
    int sum (int r) {
        int result = 0;
        for (; r >= 0; r = (r & (r+1)) - 1)
            result += t[r];
        return result;
    }

    void inc (int i, int delta) {
        for (; i < n; i = (i | (i+1)))
            t[i] += delta;
    }
};

using S = std::list<pair<short, int>>;

struct cmp {
    bool operator()(S::iterator a, S::iterator b) const {
        return a->second < b->second;
    };
};

auto encode1(auto a, auto b) {
    return a * 256 + b;
};

auto encode(auto it) {
    auto prev = it++;
    return encode1(prev->first, it->first);
};

auto erase_char(auto& curr_pos, S& str, fenwick& alive, auto& pos, auto it) {
    auto curr = it;
    auto prev = --it;
    it = curr;
    auto next = ++it;
    if (next != str.end()) {
        if (!pos[encode(curr)].count(curr)) {
            exit(-1);
        }
        pos[encode(curr)].erase(curr);
    }
    if (prev != str.end()) {
        if (!pos[encode(prev)].count(prev)) {
            exit(-1);
        }
        pos[encode(prev)].erase(prev);
    }
    curr_pos.emplace_back(curr->first, alive.sum(curr->second) - 1);
    alive.inc(curr->second, -1);
    str.erase(curr);
    if (next != str.end() && prev != str.end()) {
        auto p = prev;
        ++p;
        if (p != next) {
            exit(-1);
        }
        pos[encode(prev)].emplace(prev);
    }
};

bool is_ok(S::iterator x, S::iterator end) {
    auto curr = x;
    auto prev = --x;
    auto next = ++curr;
    if (prev != end && next != end) {
        return prev->first != next->first;
    }
    return true;
}

auto got(auto& curr_pos, auto& str, auto& alive, auto& pos, vector<S::iterator> t) {
    for (auto &e: t) {
        erase_char(curr_pos, str, alive, pos, e);
    }
};


auto relax(auto& curr_pos, auto& str, auto& alive, auto& pos, short sym, short co) {
    auto &v = pos[co];
    auto it = *v.begin();
    auto A = it;
    auto prev = --it;
    it = A;
    auto B = ++it;
    auto next = ++it;
    if (prev != str.end() && next != str.end() && prev->first == next->first) {
        if (prev->first != sym) {
            exit(-1);
        }
        got(curr_pos, str, alive, pos, {prev, A, B});
        return false;
    }
    
    got(curr_pos, str, alive, pos, {A, B});
    return true;
};

vector<array<pair<char, int>, 3>> solve_str(const string& s) {
    S str;
    fenwick alive(s.size());

    for (int i = 0; i < s.size(); ++i) {
        str.emplace_back(s[i], i);
        alive.inc(i, 1);
    }

    auto it = str.begin();

    map<int, set<decltype(it), cmp>> pos;
    while (it != str.end()) {
        auto prev = it++;
        if (it == str.end()) break;
        pos[encode(prev)].emplace(prev);   
    }
    vector<pair<char, int>> curr_pos;
    vector<decltype(it)> curr_t;
    vector<array<pair<char, int>, 3>> res;
    while (str.size()) {
        it = str.begin();
        auto curr = it++;
        if (it == str.end()) {
            exit(-1);
        }
        short code = curr->first;
        erase_char(curr_pos, str, alive, pos, curr);

        array<int, 2> candidates;
        if (code == 'Y') {
            candidates[0] = encode1('D', 'X');
            candidates[1] = encode1('X', 'D');
        } else if (code == 'X') {
            candidates[0] = encode1('D', 'Y');
            candidates[1] = encode1('Y', 'D');
        } else {
            candidates[0] = encode1('Y', 'X');
            candidates[1] = encode1('X', 'Y');
        }
        bool ok = 0;
        while (!ok) {
            for (auto &c: candidates) {
                if (!pos[c].size()) {
                    continue;
                }
                if (relax(curr_pos, str, alive, pos, code, c)) {
                    ok = 1;
                    res.emplace_back();
                    res.back()[0] = curr_pos[2];
                    res.back()[1] = curr_pos[1];
                    res.back()[2] = curr_pos[0];
                    curr_pos.clear();
                    break;
                }
                // A...ABCA, ABC removed
                res.emplace_back();
                for (int j = 0; j < 3; ++j) {
                    res.back()[j] = curr_pos.back(); // removed
                    res.back()[j].second += 1;
                    curr_pos.pop_back();
                }
                break;
            }
        }
    }
    reverse(res.begin(), res.end());
    return res;
}

bool check(const string& s) {
    array<int, 3> cnt{};
    char prev = -1;
    for (auto &e: s) {
        if (e == '?') {
            return false;
        }
        if (e != 'Y' && e != 'D' && e != 'X') {
            return false;
        }
        if (e == prev) return false;
        prev = e;
        ++cnt[idx[e]];
    }
    return cnt[0] == s.size() / 3 && cnt[1] == s.size() / 3 && cnt[2] == s.size() / 3;
}

optional<string> solve_fast1(string v) {
    auto sv = v;
    int N = v.size() / 3;
    array<int, 3> rem{N, N, N};
    for (auto &e: v) {
        if (e == '?') continue;
        --rem[idx[e]];
    }
    if (rem[0] < 0 || rem[1] < 0 || rem[2] < 0) return {};
    vector<co> mink;
    vector<pair<int, int>> segs;
    for (int i = 0; i < v.size(); ++i) {
        if (v[i] != '?') continue;
        int j = i + 1;
        while (j < v.size() && v[j] == '?') ++j;
        mink.emplace_back(j - i, i > 0 ? idx[v[i - 1]] : 3, j < v.size() ? idx[v[j]] : 3);
        segs.emplace_back(i, j - 1);
        i = j - 1;
    }
    reverse(mink.begin(), mink.end());
    reverse(segs.begin(), segs.end());
    for (int i = 1; i < mink.size(); ++i) {
        mink[i] = mink[i - 1] + mink[i];
    }
    if (mink.size()) {
        mink.pop_back();
    }
    while (segs.size()) {
        auto seg = segs.back();
        segs.pop_back();
        auto mk = mink.size() ? mink.back() : co();
        if (mink.size()) {
            mink.pop_back();
        }
        char prev = idx[seg.first ? v[seg.first - 1] : '?'];
        char next_r = idx[seg.second + 1 < v.size() ? v[seg.second + 1] : '?'];
        while (seg.first <= seg.second) {
            char next = seg.first == seg.second ? next_r : -1;
            bool found = 0;
            for (int j = 0; j < 3; ++j) {
                if (prev == j || next == j || !rem[j]) {
                    continue;
                }
                --rem[j];
                auto cs = co(seg.second - seg.first, j, seg.second + 1 < v.size() ? idx[v[seg.second + 1]] : 3);
                auto vv = mk + cs;
                if (!vv.in(rem[0], rem[1], rem[2])) {
                    ++rem[j];
                    continue;
                }
                v[seg.first++] = ydx[j];
                prev = j;
                found = 1;
                break;
            }
            if (!found) {
                return {};
            }
        }
    }
    return v;
}

optional<pair<vector<array<pair<char, int>, 3>>, string>> solve(string s) {
    auto ww = solve_fast1(s);
    if (!ww || !check(*ww)) {
        return {};
    }
    return pair{solve_str(*ww), *ww};
}

signed main() {
    ios::sync_with_stdio(0);
    cin.tie(0);
    cout.tie(0);
    idx['Y'] = 0;
    idx['D'] = 1;
    idx['X'] = 2;
    idx['?'] = 99;
    int t;
    cin >> t;
    while (t--) {
        string s;
        cin >> s;
        auto r = solve(s);
        if (r) {
            cout << "YES\n" << r->second << "\n";
            for (auto &x: r->first) {
                for (auto &e: x) {
                    cout << e.first << " " << e.second << " ";
                }
                cout << "\n";
            }
        } else {
            cout << "NO\n";
        }
    }
}

#include <bits/stdc++.h>
#include <ext/pb_ds/assoc_container.hpp>

#define F first
#define S second
#define all(x) x.begin(), x.end()
#define pb push_back
#define FIO ios_base::sync_with_stdio(false); cin.tie(0); cout.tie(0)

using namespace std;
using namespace __gnu_pbds;

typedef long long ll;
typedef pair <int, int> pii;

typedef tree<pii, null_type, less<pii>, rb_tree_tag, tree_order_statistics_node_update> oset;

void task() {
	int n; cin >> n;
	vector <pii> c;
	vector <int> v;
	for (int i = 0; i < n; i++) {
		int x, y; cin >> x >> y;
		c.pb({x, y});
		v.pb(i);
	}
	oset a, b;
	sort(all(v), [&](int x, int y) {return c[x].F < c[y].F;});
	int res = 0, rx = 0, ry = 0;
	for (int i = 0; i < n; i++) b.insert({c[i].S, i});
	for (int i = 0; i < n; i++) {
		int x = v[i];
		a.insert({c[x].S, x});
		b.erase({c[x].S, x});
		if (i < n-1 && c[x].F == c[v[i+1]].F) continue;
		while (1) {
			if (a.size() < res+1 || b.size() < res+1) break;
			int l1 = a.find_by_order(res)->F, r1 = a.find_by_order(a.size()-res-1)->F-1, l2 = b.find_by_order(res)->F, r2 = b.find_by_order(b.size()-res-1)->F-1;
			if (max(l1, l2) <= min(r1, r2)) res++, rx = c[x].F, ry = max(l1, l2);
			else break;
		}
	}
	cout << res << "\n" << rx+1 << " " << ry+1 << "\n";
}

int main () {
	FIO;
	int tt; cin >> tt;
	while (tt--) task();

	return 0;
}


[Editorial - contest/2042]
2042A - Greedy MonocarpConsider several first chests that Monocarp will take before exceeding the limit if we don't add any coins; so, this will be the set of several largest chests such that the sum of this set is s le k, but if the next chest is taken, the sum would exceed k.For this set, the minimum number of coins that should be added is k - s. We can add exactly that amount if we increase the maximum element, the set of chests will include exactly the same elements, but now their sum is equal to k.Now we have to consider the case where we add coins to some chest that is not the part of this set. Suppose Monocarp took some chest i, which initially had a_i coins, but did not take chest j, such that a_j > a_i. In order for chest i to be taken, its final value must be at least a_j, as Monocarp selects the maximum chest from the available ones. Let's suppose that x coins were added to chest i, so that a_i + x ge a_j. However, instead, we could have increased chest j to the value a_i + x, and this would require fewer coins, since a_j > a_i. Thus, we have shown that it is not optimal to "change" the order of the chests, so we can always assume that Monocarp takes several chests that were the largest in the original order.
#include <bits/stdc++.h>
 
using namespace std;

int main() {
  int t;
  cin >> t;
  while (t--) {
    int n, k;
    cin >> n >> k;
    vector<int> a(n);
    for (auto& x : a) cin >> x;
    sort(a.begin(), a.end(), greater<int>());
    int sum = 0;
    for (auto& x : a) {
      if (sum + x <= k) sum += x;
      else break;
    }
    cout << k - sum << '\n';
  }
}
2042B - Game with Colored MarblesIt's fairly intuitive that if there is at least one unique marble available (a marble is unique if there are no other marbles with the same color), taking it is optimal: if Alice takes that marble, she gets 2 points, and if Bob takes that marble, he denies 2 points to Alice. So, initially, both players take unique marbles one by one, until there is none left. Let's denote the number of unique marbles as u; then, Alice takes lceil frac{u}{2} rceil unique marbles and gets 2 points for each of them.After that, all remaining marbles are non-unique; for each remaining color, there are at least two marbles. Let's denote the number of remaining colors as k. We can show that Alice can get k more points no matter how Bob plays, but she can't get more points if Bob plays optimally.There exists a symmetric strategy for each player: if during the previous turn, your opponent took the first marble of some color, respond by taking a marble of the same color; otherwise, play any legal move. This symmetric strategy ensures that Alice gets exactly 1 point for each remaining color, since each color will be shared between two players. So, Alice can always achieve k points, and Bob can make sure she doesn't get more than k.So, to solve this problem, you need to calculate the number of marbles for each color. Then, let the number of colors with exactly one marble be u, and the number of colors with more than 1 marble be k. Alice's score will be 2 cdot lceil frac{u}{2} rceil + k.
#include<bits/stdc++.h>

using namespace std;

int main()
{
    int t;
    scanf("%d", &t);
    for(int _ = 0; _ < t; _++)
    {
        int n;
        scanf("%d", &n);
        vector<int> c(n);
        for(int i = 0; i < n; i++)
        {
            scanf("%d", &c[i]);
            --c[i];
        }
        vector<int> cnt(n);
        for(auto x : c) cnt[x]++;
        int exactly1 = 0, morethan1 = 0;
        for(auto x : cnt)
            if (x == 1)
                exactly1++;
            else if(x > 1)
                morethan1++;
        printf("%d\n", morethan1 + (exactly1 + 1) / 2 * 2);
    }
}
2042C - Competitive FishingThe main idea we need to solve this problem is the following one. For each fish, its value will be equal to the number of groups before its group. So, each "border" between two groups increases the value of every fish after the border by 1.Let s_i be the number of Bob's fishes minus the number of Alice's fishes among the fishes with indices i, i+1, dots, n-1, n; also, let a_j be the index of the fish from which the j-th group starts.Then the difference in scores between Bob and Alice is equal to 0 cdot (s_{a_1} - s_{a_2}) + 1 cdot (s_{a_2} - s_{a_3}) + cdots + (m - 1) cdot s_{a_m}, where m is the number of groups. This sum can be rewritten as: 0 cdot s_{a_1} + (2 - 1) cdot s_{a_2} + (3 - 2) cdot s_{a_3} + cdots + s_{a_m}. So, s_i denotes how the difference between Bob's score and Alice's score changes if we split the i-th fish and the (i-1)-th fish into different groups.From this, it is clear that the final score is the sum of certain elements of the array s. Since we have to minimize the number of groups (the number of selected elements from the array s), it is optimal to choose the maximum elements.So, the solution is the following: construct the array s, sort it, and take the next maximum element until the sum is less than k. The answer to the problem is the number of selected elements plus 1.
#include <bits/stdc++.h>
 
using namespace std;

int main() {
  int t;
  cin >> t;
  while (t--) {
    int n, k;
    string s;
    cin >> n >> k >> s;
    vector<int> vals;
    int sum = 0;
    for (int i = n - 1; i > 0; --i) {
      sum += (s[i] == '1' ? 1 : -1);
      if (sum > 0) vals.push_back(sum);
    }
    sort(vals.begin(), vals.end());
    int ans = 1;
    while (k > 0 && !vals.empty()) {
      k -= vals.back();
      vals.pop_back();
      ++ans;
    }
    cout << (k > 0 ? -1 : ans) << '\n';
  }
}
2042D - RecommendationsFirstly, if several segments are equal, then the answer for all of them is zero. Now let's move to the problem where all segments are distinct.User j is a predictor for user i iff l_j le l_i le r_i le r_j. Also, a track is strongly recommended if it is in all predictor segments, i. e. the track belongs to the intersection [L, R] of all predictors. Since the segment [l_i, r_i] also belongs to [L, R], then the tracks we need to find form two intervals [L, l_i) and (r_i, R].Let's focus on finding interval (r_i, R]. Since the right border of the intersection is the minimum among right borders, then our task is to find the minimum among r_j-s such that r_j ge r_i while l_j le l_i.Let's do it in the following way: let's sort all segments by l_i in increasing order; in case of equal l_i-s, sort them by r_i in decreasing order. If we process segments in the given order, then by the moment we process the i-th segment, all its predictors will be already processed.Let's keep r_i-s of all processed segments so far in an "ordered set" S (std::set, for example). Suppose we process segment i. Since the right borders of all predictors are already in S and their r_j ge r_i, then finding the minimum among them is equivalent to just taking R = S.mathrm{lower_bound}(r_i). Then we can add R - r_i to the answer for the i-th segment.In order to calculate intervals [L, l_i) we can just reflect all segments and solve the same problem.The complexity of the solution is O(n log{n}).
#include<bits/stdc++.h>
using namespace std;

#define fore(i, l, r) for(int i = int(l); i < int(r); i++)
#define sz(a) int((a).size())

struct Seg {
	int l, r;

	bool operator< (const Seg &oth) const {
		if (l != oth.l)
			return l < oth.l;
		return r < oth.r;
	};
};

void solve() {
	int n;
	cin >> n;
	vector<Seg> seg(n);
	for (int i = 0; i < n; i++)
		cin >> seg[i].l >> seg[i].r;
	
	vector<int> ans(n, 0);
	for (int k = 0; k < 2; k++) {
		vector<int> ord(n);
		iota(ord.begin(), ord.end(), 0);

		sort(ord.begin(), ord.end(), [&seg](int i, int j){
			if (seg[i].l != seg[j].l)
				return seg[i].l < seg[j].l;
			return seg[i].r > seg[j].r;
		});

		set<int> bounds;
		for (int i : ord) {
			auto it = bounds.lower_bound(seg[i].r);
			if (it != bounds.end())
				ans[i] += *it - seg[i].r;
			bounds.insert(seg[i].r);
		}

		for (auto &s : seg) {
			s.l = -s.l;
			s.r = -s.r;
			swap(s.l, s.r);
		}
	}

	map<Seg, int> cnt;
	for (auto s: seg)
		cnt[s]++;
	for (int i = 0; i < n; i++)
		if (cnt[seg[i]] > 1)
			ans[i] = 0;
	
	for (int a : ans)
		cout << a << '\n';
}

int main() {
	ios_base::sync_with_stdio(false);
	cin.tie(0);
	
	int t; cin >> t;
	while (t--)
		solve();
	return 0;
}
2042E - Vertex PairsNote that the cost function of a subset actually states the following: you are asked to choose the minimum lexicographic subset if the vertices are ordered in descending order. This can be shown by looking at the binary representations of the subset costs.Intuitively, we want to implement the following process. Iterate over the vertices in descending order and check whether we have to take the current vertex in the subset, or we can skip it. If we can, we skip it; otherwise, we take it.How to write this checking function? I think that it is easier to do this if we root the tree by a vertex that will definitely be in the answer. Finding such a vertex is easy — out of two vertices with the value 1, at least one will definitely be in the answer. Iterate over it and take the best answer from the two options. We can compare the answers by their by binary representations.In the rooted tree, where the root is always taken, it is easier to check connectivity. If a vertex is taken in the subset, then its parent must also be taken. Otherwise, the subset will definitely be disconnected.A vertex must be taken in the subset if there is a value such that both vertices with this value are in its subtree. However, sometimes it happens that one of the two vertices with some value has already been prohibited from being taken. In this case, for this value, we need to check that only the non-prohibited vertex is in the subtree.Let's maintain the state of each vertex:   the vertex must be taken in the subset;  the vertex must not be taken in the subset;  it has not been determined whether to take the vertex or not. Initially, we know that for each value, we must take the vertices that are on both paths from the vertices with this value to the root. So, on the path from their LCA (lowest common ancestor) to the root. If at least one such vertex is not taken, then that value will not appear in the subset.A vertex can be skipped if its state is not determined. When we decide not to take a vertex, the following happens. The vertices in its subtree must also not be taken. And if for some vertex it is marked that it must not be taken in the subset, then another vertex with the same value must now be taken.We will write two auxiliary functions.The first function marks the state as "must take". So, it takes a vertex v and jumps over the parents of vertex v until it either reaches the root or an already marked vertex. In total, this function will make O(n) iterations, as with each successful iteration of the loop, another vertex gets marked.The second function marks the state as "must not take". That is, it takes a vertex v and traverses the subtree of vertex v, marking all descendants as "must not take". I chose to implement this function using a breadth-first search. Again, we can stop the traversal when we see that a vertex is already marked as "must not take". In total, there will also be O(n) iterations. When we mark a vertex, we call the first function from another vertex with its value.Overall complexity: O(n log n) (where everything except LCA works in O(n)).
#include <bits/stdc++.h>
 
#define forn(i, n) for (int i = 0; i < int(n); i++)
 
using namespace std;
 
vector<vector<int>> g;
 
struct LCA {
	vector<vector<pair<int, int>>> st;
	vector<int> pw;
 
	void build(vector<pair<int, int>> a) {
		int n = a.size();
		int lg = 32 - __builtin_clz(n);
		st.resize(lg, vector<pair<int, int>>(n));
		st[0] = a;
		for (int j = 1; j < lg; ++j) {
			for (int i = 0; i < n; ++i) {
				st[j][i] = st[j - 1][i];
				if (i + (1 << (j - 1)) < n)
					st[j][i] = min(st[j][i], st[j - 1][i + (1 << (j - 1))]);
			}
		}
		pw.resize(n + 1);
		for (int i = 2; i <= n; ++i)
			pw[i] = pw[i / 2] + 1;
	}
 
	vector<int> d, fst, par;
	vector<pair<int, int>> ord;
 
	int lca(int v, int u) {
		int l = fst[v], r = fst[u];
		if (l > r) swap(l, r);
		++r;
		int len = pw[r - l];
		assert(len < int(st.size()));
		return min(st[len][l], st[len][r - (1 << len)]).second;
	}
 
	void init(int v, int p = -1) {
		if (fst[v] == -1) fst[v] = ord.size();
		ord.push_back({ d[v], v });
		for (int u : g[v]) if (u != p) {
			par[u] = v;
			d[u] = d[v] + 1;
			init(u, v);
			ord.push_back({ d[v], v });
		}
	}
 
	LCA(int r = 0) {
		int n = g.size();
		d.resize(n);
		fst.assign(n, -1);
		par.assign(n, -1);
		ord.clear();
		init(r);
 
		build(ord);
	}
};

int main() {
	cin.tie(0);
	ios::sync_with_stdio(false);
	int n;
	cin >> n;
	vector<int> a(2 * n);
	forn(i, 2 * n){
		cin >> a[i];
		--a[i];
	}
	g.resize(2 * n);
	forn(i, 2 * n - 1){
		int v, u;
		cin >> v >> u;
		--v, --u;
		g[v].push_back(u);
		g[u].push_back(v);
	}
	vector<int> l(n, -1), r(n, -1);
	forn(i, 2 * n){
		if (l[a[i]] == -1) l[a[i]] = i;
		else r[a[i]] = i;
	}
	vector<char> res(2 * n, 1);
	forn(rt, 2 * n) if (a[rt] == 0){
		LCA d(rt);
		vector<int> state(2 * n, 0);
		
		auto mark = [&](int v){
			while (v != -1 && state[v] != 1){
                state[v] = 1;
				v = d.par[v];
			}
		};
		auto markdel = [&](int v){
			queue<int> q;
			q.push(v);
			state[v] = -1;
			while (!q.empty()){
				int v = q.front();
				q.pop();
				mark(l[a[v]] ^ r[a[v]] ^ v);
				for (int u : g[v]) if (u != d.par[v] && state[u] == 0){
					state[u] = -1;
					q.push(u);
				}
			}
		};
		
		forn(i, n) mark(d.lca(l[i], r[i]));
		for (int i = 2 * n - 1; i >= 0; --i) if (state[i] == 0)
			markdel(i);
		vector<char> cur(2 * n, 0);
        for (int i = 0; i < 2 * n; ++i) if (state[i] == 1)
            cur[i] = 1;
        reverse(cur.begin(), cur.end());
		res = min(res, cur);
	}
	reverse(res.begin(), res.end());
	cout << count(res.begin(), res.end(), 1) << '\n';
	forn(i, 2 * n) if (res[i])
		cout << i + 1 << " ";
	cout << '\n';
	return 0;
}

Tutorial is loading...
#include <bits/stdc++.h>
 
using namespace std;

#define forn(i, n) for (int i = 0; i < int(n); ++i)

const int N = 200 * 1000 + 13;
const int K = 5;

using li = long long;
using mat = array<array<li, K>, K>;

const li INF = 1e18;

int n, q;
li a[N], b[N];
mat t[4 * N];

mat init(li a, li b) {
  mat c;
  forn(i, K) forn(j, i + 1) c[j][i] = -INF;
  c[0][0] = c[2][2] = c[4][4] = 0;
  c[0][1] = c[2][3] = a + b;
  c[0][2] = c[2][4] = a + b + b;
  c[1][1] = c[3][3] = a;
  c[1][2] = c[3][4] = a + b;
  return c;
}

mat combine(mat a, mat b) {
  mat c = init(-INF, -INF);
  forn(i, K) forn(j, i + 1) forn(k, j + 1)
    c[k][i] = max(c[k][i], a[k][j] + b[j][i]);
  return c;
}

void build(int v, int l, int r) {
  if (l + 1 == r) {
    t[v] = init(a[l], b[l]);
    return;
  }
  int m = (l + r) / 2;
  build(v * 2 + 1, l, m);
  build(v * 2 + 2, m, r);
  t[v] = combine(t[v * 2 + 1], t[v * 2 + 2]);
}

void upd(int v, int l, int r, int p) {
  if (l + 1 == r) {
    t[v] = init(a[l], b[l]);
    return;
  }
  int m = (l + r) / 2;
  if (p < m) upd(v * 2 + 1, l, m, p);
  else upd(v * 2 + 2, m, r, p);
  t[v] = combine(t[v * 2 + 1], t[v * 2 + 2]);
}

mat get(int v, int l, int r, int L, int R) {
  if (L >= R) return init(-INF, -INF);
  if (l == L && r == R) return t[v];
  int m = (l + r) / 2;
  return combine(
    get(v * 2 + 1, l, m, L, min(m, R)),
    get(v * 2 + 2, m, r, max(m, L), R)
  );
}

int main() {
  ios::sync_with_stdio(false); cin.tie(0);
  cin >> n;
  forn(i, n) cin >> a[i];
  forn(i, n) cin >> b[i];
  build(0, 0, n);
  cin >> q;
  forn(_, q) {
    int t, x, y;
    cin >> t >> x >> y;
    --x;
    if (t == 1) {
      a[x] = y;
      upd(0, 0, n, x);
    } else if (t == 2) {
      b[x] = y;
      upd(0, 0, n, x);
    } else {
      auto res = get(0, 0, n, x, y);
      cout << res[0][4] << '\n';
    }
  }
}


[Editorial - contest/2045]
No editorial content found.


[Editorial - contest/2034]
 Step 1: Prove that for the minimum value of m, we must have m%a=m%b=0. Step 2: To prove this, show that if m%a=m%b=x>0, then m−1 will also satisfy the problem's requirements. Step 3: Since m≥min(a,b), if x>0, then m>min(a,b) must hold. Therefore, m−1≥min(a,b) implies that m−1 satisfies the requirements. Step 4: Thus, m must be divisible by both a and b. The smallest such m is lcm(a,b) which can be calculated in O(log(max(a,b))). 
#include <bits/stdc++.h>

using namespace std;

int main(){
  int tt;
  cin >> tt;
  while(tt--){
    int a, b;
    cin >> a >> b;
    cout << lcm(a , b) << endl;
  }
}
We will solve the problem using the following approach:  Start from the leftmost spot and move rightwards. Whenever a consecutive segment of m weak spots (i.e., 0's) is found, apply Timar to a segment of length k, starting from the last index of the weak segment. Repeat this process until no segment of m consecutive weak spots remains. The key idea behind this solution is that whenever we encounter a block of m consecutive 0's, we need to strengthen it. Since we can apply Timar to a segment of length k, the optimal strategy is always to apply Timar starting at the last index of the block of m consecutive 0's.Correctness Proof:  For any block of m consecutive 0's, we must apply Timar to at least one index within this block. Hence, the strengthened segment of length k must overlap with the block of weak spots. Suppose an optimal solution exists where Timar is applied to a segment starting leftward within the block. Suppose we shift this segment one step to the right (closer to the end of the block). In that case, the solution remains valid and optimal since it covers all weak spots in the block while reducing unnecessary overlap with already-strengthened areas. By always starting from the last index of a block of m consecutive 0's, this greedy strategy ensures that Timar is used in the minimum number of applications, making it correct and efficient.
# include <bits/stdc++.h>

using namespace std;

const int xn = 2e5 + 10;

int q, n, m, k, ps[xn];
string s;

int main() {
    cin >> q;
    while (q --) {
        cin >> n >> m >> k >> s;
        fill(ps, ps + n, 0);
        int ans = 0, cnt = 0, sum = 0;
        for (int i = 0; i < n; ++ i) {
            sum += ps[i];
            if (sum || s[i] == '1') cnt = 0;
            else {
                cnt++;
                if (cnt == m) {
                    sum++, ans++, cnt = 0;
                    if (i + k < n) ps[i + k]--;
                }
            }
        }
        cout << ans << "\n";
    }
}
 If a cell has a fixed direction (i.e., it points to another cell), and following that direction leads outside the maze, it must eventually exit the maze. Such cells cannot be part of any loop. We can analyze the remaining cells once we identify cells that lead out of the maze. Any undirected cell or ? cell might either lead to the exit or form part of a loop. If all neighboring cells of a ? cell can eventually lead out of the maze, then this ? cell will also lead out of the maze. The state of such ? cells can be determined based on their surroundings. For any remaining cells (directed cells that do not lead out of the maze, or other ? cells that cannot be determined to lead to an exit), we can assign directions such that starting from those cells will eventually lead to a loop. These cells will form the loops. To find how many cells will eventually lead to a loop, we can use a Depth-First Search (DFS) on the reversed graph, where all directions are reversed. By performing DFS starting from the "out-of-maze" cells, we can identify all cells that are reachable from the outside and thus will eventually lead out of the maze. Count the number of cells that can reach the exit. Subtract this number from the total number of cells in the maze to determine how many are part of loops (i.e., cells that cannot reach the exit). 
#include <bits/stdc++.h>
 
using namespace std;
 
int main() 
{
    int tc;
    cin >> tc;
    while(tc--){
        int n, m;
        cin >> n >> m;
        string c[n+1];
        for(int i = 1 ; i <= n ; i++) cin >> c[i] , c[i] = "-" + c[i];
        vector<pair<int,int>> jda[n+2][m+2];
        for(int i = 1 ; i <= n ; i++){
            for(int j = 1 ; j <= m ; j++){
                if(c[i][j] == 'U') jda[i-1][j].push_back({i , j});
                if(c[i][j] == 'R') jda[i][j+1].push_back({i , j});
                if(c[i][j] == 'D') jda[i+1][j].push_back({i , j});
                if(c[i][j] == 'L') jda[i][j-1].push_back({i , j});
            }
        }
        int vis[n+2][m+2] = {};
        queue<pair<int,int>> q;
        for(int j = 0 ; j <= m+1 ; j++) vis[0][j] = 1 , q.push({0 , j});
        for(int i = 1 ; i <= n+1 ; i++) vis[i][0] = 1 , q.push({i , 0});
        for(int j = 1 ; j <= m+1 ; j++) vis[n+1][j] = 1 , q.push({n+1 , j});
        for(int i = 1 ; i <= n ; i++) vis[i][m+1] = 1 , q.push({i , m+1});
        while(q.size()){
            auto [i , j] = q.front();
            q.pop();
            for(auto [a , b] : jda[i][j]){
                if(vis[a][b] == 0){
                    vis[a][b] = 1;
                    q.push({a , b});
                }
            }
        }
        for(int i = 1 ; i <= n ; i++){
            for(int j = 1 ; j <= m ; j++){
                if(c[i][j] == '?' and
                vis[i-1][j] and vis[i][j+1] and vis[i+1][j] and vis[i][j-1]) vis[i][j] = 1;
            }
        }
        int ans = n * m;
        for(int i = 1 ; i <= n ; i++){
            for(int j = 1 ; j <= m ; j++){
                if(vis[i][j] == 1) ans -= 1;
            }
        }
        cout << ans << endl;
    }
    return 0;
}
 Step 1: Using two moves, we can move an element to any arbitrary position in the array. Thus, we can place all 0's in their correct positions with at most 2min(count(0),count(1)+count(2)) moves. Step 2: After placing all 0's, the rest of the array will contain only 1's and 2's. To sort this part of the array, we need at most min(count(1),count(2)) moves. Step 3: The first step takes at most n moves, and the second step takes at most n2 moves. However, it can be proven that the total number of moves is at most 8n7. Step 4: We can assume count(0)≤count(2) without loss of generality (Why?). So, the maximum number of moves are:  2min(count(0),count(1)+count(2))+min(count(1),count(2)) =2⋅count(0)+min(count(1),count(2)) ≤count(0)+max(count(1),count(2))+min(count(1),count(2)) =count(0)+count(1)+count(2)=nBetter approach:  Step 1: Since we are allowed to perform n moves, assign each index one "move" as its "specified cost". Step 2: While there exists an index with a value of 0 or 2 that can be fixed with just one move, fix it using its assigned cost. Step 3: After fixing all 0's, 2's, and all 1's except one, the remaining array will have the following structure and we are now allowed to use 2x+1 moves:  2 2 … 2 (x times) 1 0 0 … 0 (x times),  Step 4: First, swap the 1 with a random element (denote it as r). Then, for 2x−1 moves, swap the index with the value 1 with any index where the correct value must be placed, except r. Finally, swap 1 and r. 
#include <bits/stdc++.h>

using namespace std;

const int N = 200000;
int n, cnt[3], a[N];
vector<int> vip[3][3]; // Value In Position
vector<pair<int, int>> swaps;

inline int Pos(int index) {
    if(index < cnt[0])
        return 0;
    else if(index < cnt[0]+cnt[1])
        return 1;
    else
        return 2; 
}

inline void AddBack(int index) {
    vip[a[index]][Pos(index)].push_back(index);
}

inline void RemoveBack(int index) {
    vip[a[index]][Pos(index)].pop_back();
}

inline void Swap(int i, int j) {
    swaps.push_back({i, j});
    RemoveBack(i);
    RemoveBack(j);
    swap(a[i], a[j]);
    AddBack(i);
    AddBack(j);
}

inline void Fix(int x) {
    while(!vip[1][x].empty() or !vip[2-x][x].empty()) {
        if(vip[1][x].empty()) {
            if(!vip[1][2-x].empty())
                Swap(vip[2-x][x].back(), vip[1][2-x].back());
            else
                Swap(vip[2-x][x].back(), vip[1][1].back());
        }
        if(!vip[x][1].empty()) 
            Swap(vip[1][x].back(), vip[x][1].back());
        else
            Swap(vip[1][x].back(), vip[x][2-x].back());
    }  
}


int main() 
{
    ios_base::sync_with_stdio(false), cin.tie(0);
    int t;
    cin >> t;
    while (t--) {
        cin >> n;
        for(int i = 0; i < n; i++)
            cin >> a[i], cnt[a[i]]++;
        for(int i = 0; i < n; i++)
            AddBack(i);
        if(cnt[0] <= cnt[2]) {
            Fix(0);
            Fix(2);
        } else {
            Fix(2);
            Fix(0);
        }
        cout << swaps.size() << endl;
        for(auto [i, j]: swaps)
            cout << i+1 << ' ' << j+1 << endl;
        cnt[0] = cnt[1] = cnt[2] = 0;
        for(int i = 0; i < 3; i++)
            for(int j = 0; j < 3; j++)
                vip[i][j].clear();
        swaps.clear();
    }
    return 0;
}
// In the name of god
#include <bits/stdc++.h>

using namespace std;

const int N = 200000;
int n, cnt[3], a[N];
vector<int> vip[3][3]; // Value In Position
vector<pair<int, int>> swaps;

inline int Pos(int index) {
    if(index < cnt[0])
        return 0;
    else if(index < cnt[0]+cnt[1])
        return 1;
    else
        return 2; 
}

inline void AddBack(int index) {
    vip[a[index]][Pos(index)].push_back(index);
}

inline void RemoveBack(int index) {
    vip[a[index]][Pos(index)].pop_back();
}

inline void Swap(int i, int j) {
    swaps.push_back({i, j});
    RemoveBack(i);
    RemoveBack(j);
    swap(a[i], a[j]);
    AddBack(i);
    AddBack(j);
}

inline void Fix() {
    bool change;
    do {
        change = false;
        while ((!vip[1][0].empty()) && (!vip[0][1].empty()))
            Swap(vip[1][0].back(), vip[0][1].back()), change = true;
        while ((!vip[1][0].empty()) && (!vip[0][2].empty()))
            Swap(vip[1][0].back(), vip[0][2-0].back()), change = true;
        while ((!vip[1][2].empty()) && (!vip[2][1].empty()))
            Swap(vip[1][2].back(), vip[2][1].back()), change = true;
        while ((!vip[1][2].empty()) && (!vip[2][0].empty()))
            Swap(vip[1][2].back(), vip[2][0].back()), change = true;
    } while (change);    
}

inline void PingPong() {
    if(vip[0][2].empty())
        return;
    Swap(vip[1][1].back(), vip[0][2].back());
    while (true){
        Swap(vip[1][2].back(), vip[2][0].back());
        if(vip[0][2].empty())
            break;
        Swap(vip[1][0].back(), vip[0][2].back());
    }
    Swap(vip[1][0].back(), vip[0][1].back());
}

int main() 
{
    ios_base::sync_with_stdio(false), cin.tie(0);
    int t;
    cin >> t;
    while (t--) {
        cin >> n;
        for(int i = 0; i < n; i++)
            cin >> a[i], cnt[a[i]]++;
        for(int i = 0; i < n; i++)
            AddBack(i);
        Fix();
        PingPong();
        cout << swaps.size() << endl;
        for(auto [i, j]: swaps)
            cout << i+1 << ' ' << j+1 << endl;
        // reset
        cnt[0] = cnt[1] = cnt[2] = 0;
        for(int i = 0; i < 3; i++)
            for(int j = 0; j < 3; j++)
                vip[i][j].clear();
        swaps.clear();
    }
    return 0;
}
 Step 1: There are n positions that must be equal, and their sum is n⋅(n+1)⋅k2. Hence, each position must be (n+1)⋅k2. Additionally, there must be k distinct permutations, so k≤n!. Step 2: For even k, we can group n! permutations into n!2 double handles, where each group corresponds to a solution for k=2. Then, pick k2 handles. The match for permutation a1,a2,…,an is (n+1)−a1,(n+1)−a2,…,(n+1)−an. Step 3: For k=1, n must be 1. Symmetrically, k cannot be n!−1. Solutions for other odd k will now be provided. Step 4: To construct an answer for k=3 and n=2x+1, consider the following derived using a greedy approach:     p1  p2  p3  p4  p5  …  p2x−1  p2x  p2x+1      1  2  3  4  5  …  2x−1  2x  2x+1    x+1  2x+1  x  2x  x−1  …  2  x+2  1    2x+1  x  2x  x−1  2x−1  …  x+2  1  x+1      Step 5: Now, combine the solution for even k and the k=3 solution by selecting the 3 permutations and k−32 other handles. 
// In the name of God
#include <bits/stdc++.h>
using namespace std;
 
int main() {
    ios_base::sync_with_stdio(false), cin.tie(0);
    int t;
    cin >> t;
    int f[8] = {1,1,2,6,24,120,720,5040};
    while(t--) {
        int n, k;
        cin >> n >> k;
        if(min(n, k) == 1) {
            if(n*k == 1) {
                cout << "Yes\n1\n";
            } else cout << "No\n";
        } else if(n < 8 and (f[n] < k or f[n] == k+1)) {
            cout << "No\n";
        } else if(n % 2 == 0 and k % 2 == 1) {
            cout << "No\n";
        } else {
            vector<vector<int>> base, all;
            vector<int> per(n);
            for(int i = 0; i < n; i++) per[i] = i+1;
            if(k % 2) {
                vector<int> p1(n), p2(n);
                for(int i = 0; i < n; i += 2) p1[i] = (n+1)/2-i/2, p2[i] = n-i/2;
                for(int i = 1; i < n; i += 2) p1[i] = n-i/2, p2[i] = n/2-i/2;
                all = base = {per, p1, p2};
                k -= 3;
            }
            do {
                if(k == 0)
                    break;
                vector<int> mirror(n);
                for(int i = 0; i < n; i++)
                    mirror[i] = n+1-per[i];
                if(per < mirror) {
                    bool used = false;
                    for(auto &p: base) used |= (p == per), used |= (p == mirror);
                    if(not used) {
                        k -= 2;
                        all.push_back(per);
                        all.push_back(mirror);
                    }
                }
            } while (next_permutation(per.begin(), per.end()));
            cout << "Yes\n";
            for(auto p: all) {
                for(int i = 0; i < n; i++)
                    cout << p[i] << (i+1==n?'\n':' ');
            }
        }
    }
 
    return 0;
}
 
// Thanks God

 Step 1: For simplicity, redefine the special conditions for the number of rubies and sapphires in your satchel (not chest). Add two dummy states, (0,0) and (n,m) for convenience (the first one indexed as 0 and the second one indexed as k+1). Note that these dummy states won’t involve doubling the value. Step 2: Order the redefined conditions (x,y) in increasing order based on the value of x+y. Step 3: Define waysi,j as the number of ways to move from state i to state j without passing through any other special condition. This can be computed using inclusion-exclusion in O(k3). Step 4: Define costi,j, the increase in value for moving directly from state i to state j without intermediate doubling, as:  costi,j=2|xi−xj|+|yi−yj|  Step 5: Define dpi as the total sum of the value of your satchel across all ways to reach the state defined by the i-th condition. This can be computed recursively as:  dpi=2∑0≤j<iwaysj,i×(dpj+(xj+yjxj)×costj,i)  Step 6: Compute the final answer as the value of dpk+1 divided by the total number of ways to move from (0,0) to (n,m), which is (n+mn). 
#include <bits/stdc++.h>
using namespace std;
 
#define nl "\n"
#define nf endl
#define ll long long
#define pb push_back
#define _ << ' ' <<
 
#define INF (ll)1e18
#define mod 998244353
#define maxn 400010
 
ll fc[maxn], nv[maxn];
 
ll fxp(ll b, ll e) {
    ll r = 1, k = b;
    while (e != 0) {
        if (e % 2) r = (r * k) % mod;
        k = (k * k) % mod; e /= 2;
    }
    return r;
}
 
ll inv(ll x) {
    return fxp(x, mod - 2);
}
 
ll bnm(ll a, ll b) {
    if (a < b || b < 0) return 0;
    ll r = (fc[a] * nv[b]) % mod;
    r = (r * nv[a - b]) % mod;
    return r;
}
 
int main() {
    ios::sync_with_stdio(0);
    cin.tie(0);
 
    fc[0] = 1; nv[0] = 1;
    for (ll i = 1; i < maxn; i++) {
        fc[i] = (i * fc[i - 1]) % mod; nv[i] = inv(fc[i]);
    }
 
    ll t; cin >> t;
    while (t--) {
        ll n, m, k; cin >> n >> m >> k;
        vector<array<ll, 2>> a(k + 2, {0, 0});
        for (ll i = 1; i <= k; i++) {
            cin >> a[i][0] >> a[i][1];
            a[i][0] = n - a[i][0]; a[i][1] = m - a[i][1];
        }
        a[k + 1] = {n, m}; k++;
        sort(a.begin() + 1, a.end());
 
        auto paths = [&](ll i, ll j) {
            ll dx = a[j][0] - a[i][0], dy = a[j][1] - a[i][1];
            return bnm(dx + dy, dx);
        };
 
        auto add = [&](ll &x, ll y) {
            x = (x + y) % mod;
            x = (x + mod) % mod;
        };
 
        vector direct(k + 1, vector<ll>(k + 1, 0));
        for (ll i = 1; i <= k; i++) {
            for (ll j = i - 1; j >= 0; j--) {
                direct[j][i] = paths(j, i);
                for (ll l = j + 1; l < i; l++) {
                    add(direct[j][i], -paths(j, l) * direct[l][i]);
                }
            }
        }
 
        vector<ll> dp(k + 1, 0);
        for (ll i = 1; i <= k; i++) {
            for (ll j = 0; j < i; j++) {
                if (direct[j][i] == 0) continue;
                ll partial = dp[j];
                ll delta = 2 * (a[i][0] - a[j][0]) + (a[i][1] - a[j][1]);
                add(partial, paths(0, j) * delta);
                add(dp[i], partial * direct[j][i]);
            }
            if (i != k) dp[i] = (2 * dp[i]) % mod;
        }
 
        ll ans = (dp[k] * inv(bnm(n + m, m))) % mod;
        cout << ans << nl;
    }
 
    return 0;
}
 Step 1: For simplicity, redefine the special conditions for the number of rubies and sapphires in your satchel (not chest). Step 2: Order the redefined conditions (x,y) in increasing order based on the value of x+y. Step 3: Define totali,j as the total number of ways to move from state i to state j (ignoring special condition constraints). This can be computed as:  totali,j=(|xi−xj|+|yi−yj||xi−xj|)  Step 4: Define weighti as the total contribution of all paths passing through condition i to reach the final state (n,m). This can be computed recursively as:  weighti=∑i<j≤ktotali,j×weightj  Step 5: The main insight is to account for the doubling effect of passing through multiple scrolls. If a path passes through a sequence of conditions s1,…,sc, each gem collected before entering s1 is counted with multiplicity 2c. Instead of explicitly multiplying by 2c, consider the number of subsets q1,…,qd of s1,…,sc. By summing over all subsets, the correct multiplicity is automatically handled. Step 6: Define dpi as the total value of all paths passing through condition i, considering the contribution of each state’s rubies and sapphires. This can be computed as:  dpi=(2xi+yi)×total0,i×weighti  Step 7: Compute the final answer as ∑dpi divided by the total number of ways to move from (0,0) to (n,m), which is equal to (n+mn). Clarification: The approach hinges on the insight that 2i can be derived from the structure of subsets of scrolls s1,…,sc. Generalizations to 3i or other multiplicative factors are possible by appropriately modifying weighti and adjusting the factor in Step 5. For example, a factor of 3 can be applied by multiplying path contributions by 2 at the relevant steps.
#include <bits/stdc++.h>
using namespace std;
 
#define nl "\n"
#define nf endl
#define ll long long
#define pb push_back
#define _ << ' ' <<
 
#define INF (ll)1e18
#define mod 998244353
#define maxn 400010
 
ll fc[maxn], nv[maxn];
 
ll fxp(ll b, ll e) {
    ll r = 1, k = b;
    while (e != 0) {
        if (e % 2) r = (r * k) % mod;
        k = (k * k) % mod; e /= 2;
    }
    return r;
}
 
ll inv(ll x) {
    return fxp(x, mod - 2);
}
 
ll bnm(ll a, ll b) {
    if (a < b || b < 0) return 0;
    ll r = (fc[a] * nv[b]) % mod;
    r = (r * nv[a - b]) % mod;
    return r;
}
 
int main() {
    ios::sync_with_stdio(0);
    cin.tie(0);
 
    fc[0] = 1; nv[0] = 1;
    for (ll i = 1; i < maxn; i++) {
        fc[i] = (i * fc[i - 1]) % mod; nv[i] = inv(fc[i]);
    }
 
    ll t; cin >> t;
    while (t--) {
        ll n, m, k; cin >> n >> m >> k;
        vector<array<ll, 2>> a(k + 2, {0, 0});
        for (ll i = 1; i <= k; i++) {
            cin >> a[i][0] >> a[i][1];
            a[i][0] = n - a[i][0]; a[i][1] = m - a[i][1];
        }
        a[k + 1] = {n, m}; k++;
        sort(a.begin() + 1, a.end());
 
        auto paths = [&](ll i, ll j) {
            ll dx = a[j][0] - a[i][0], dy = a[j][1] - a[i][1];
            return bnm(dx + dy, dx);
        };
 
        auto add = [&](ll &x, ll y) {
            x = (x + y) % mod;
            x = (x + mod) % mod;
        };
 
        vector<ll> cnt_weighted(k + 1, 0);
        cnt_weighted[k] = 1;
        for (ll i = k - 1; i >= 1; i--) {
            for (ll j = i + 1; j <= k; j++) {
                add(cnt_weighted[i], paths(i, j) * cnt_weighted[j]);
            }
        }
 
        ll ans = 0;
        for (ll i = 1; i <= k; i++) {
            ll delta = 2 * a[i][0] + a[i][1];
            add(ans, delta * paths(0, i) % mod * cnt_weighted[i]);
        }
 
        ans = (ans * inv(bnm(n + m, m))) % mod;
        cout << ans << nl;
    }
 
    return 0;
}
 It is easy to check if the solution can be achieved with only one color. For any time point x, there must be at most one interval containing x, since if multiple intervals contain x, they must be colored differently. A simple strategy is to solve the problem using three colors. First, we color some intervals with colors 1 and 2, then color others with color 3.    For each step, we find the leftmost point that has not been colored yet and color the segment that contains this point. We always choose the interval with the largest endpoint that contains the current point. By coloring the intervals alternately with colors 1 and 2, we ensure that all points are covered by exactly one of these colors.  Now, we check if we can color the intervals with just two colors using a greedy algorithm:    We iterate over the intervals sorted by start (increasingly) and then by end (decreasingly). At each point, we keep track of the number of colors used in previous intervals that are not yet closed. Let this number be I, and suppose we are currently at interval i. We color the current interval based on the value of I:      If I=0, color interval i with color 1. If I=1, color interval i with the opposite color of the current used color. If I=2, color interval i with the opposite color of the interval with the greatest endpoint among the currently open intervals.  If it is impossible to assign a unique color between overlapping intervals at any point, it can be shown that coloring the intervals using only 2 colors is impossible.  Solving G1 using G2:  It’s sufficient to check the integer points and half-points (e.g., 1.5, 2.5, …) to verify whether the coloring is valid (Why?). To handle this, we can multiply all the given points by two, effectively converting the problem into one in which only integer points exist. After this transformation, we solve the problem in the integer system of G2, where the intervals and coloring rules are defined using integer boundaries! Note: A brief explanation of why this greedy algorithm works can be found here.
/* In the name of Allah */
// Welcome to the Soldier Side!
// Where there's no one here, but me...
#include<bits/stdc++.h>
using namespace std;

const int N = 2e5 + 5;
int t, n, l[N], r[N], col[N];
vector<int> st[N << 1], en[N << 1];

void compress_points() {
    vector<int> help;
    for (int i = 0; i < n; i++) {
        help.push_back(l[i]);
        help.push_back(r[i]);
    }

    sort(help.begin(), help.end());
    help.resize(unique(help.begin(), help.end()) - help.begin());
    for (int i = 0; i < n; i++) {
        l[i] = lower_bound(help.begin(), help.end(), l[i]) - help.begin();
        r[i] = lower_bound(help.begin(), help.end(), r[i]) - help.begin();
    }
}

void record_points() {
    for (int i = 0; i < n; i++) {
        st[l[i]].push_back(i);
        en[r[i] + 1].push_back(i);
    }
    for (int i = 0; i < 2 * n; i++)
        sort(st[i].begin(), st[i].end(), [](int i, int j) {
            return r[i] > r[j];
        });
}

void try3_points() {
    fill(col, col + n, 0);
    int cur = -1, nxt = -1, c = 2;
    for (int i = 0; i < 2 * n; i++) {
        if (st[i].empty())
            continue;

        if (!~cur || i > r[cur]) {
            if (cur ^ nxt && r[nxt] < i) {
                col[nxt] = (c ^= 3);
                cur = nxt;
            }

            if (cur ^ nxt)
                cur = nxt;
            else {
                cur = st[i][0];
                for (int p: st[i])
                    if (r[p] > r[cur])
                        cur = p;
                nxt = cur;
            }
            col[cur] = (c ^= 3);
        }
        
        for (int p: st[i])
            if (r[p] > r[nxt])
                nxt = p;
    }
    if (cur ^ nxt)
        col[nxt] = c ^ 3;
}

bool is_bad(set<pair<int, int>> s[2]) {
    int cnt1 = s[0].size(), cnt2 = s[1].size();
    return cnt1 + cnt2 && cnt1 ^ 1 && cnt2 ^ 1;
}

void try2_points() {
    set<pair<int, int>> s[2];
    for (int i = 0; i <= 2 * n; i++) {
        for (int p: en[i])
            s[col[p]].erase({r[p], p});
        if (is_bad(s)) {
            try3_points();
            return;
        }

        for (int p: st[i]) {
            int cnt1 = s[0].size();
            int cnt2 = s[1].size();
            if (!cnt1 || !cnt2)
                col[p] = cnt1 > 0;
            else if (cnt1 ^ cnt2)
                col[p] = cnt1 < cnt2;
            else
                col[p] = s[0].begin()->first > s[1].begin()->first;

            s[col[p]].insert({r[p], p});
            if (is_bad(s)) {
                try3_points();
                return;
            }
        }
    }
}

void read_input() {
    cin >> n;
    for (int i = 0; i < n; i++)
        cin >> l[i] >> r[i];
}

void solve() {
    compress_points();
    record_points();
    try2_points();
}

void write_output() {
    cout << *max_element(col, col + n) + 1 << endl;
    for (int i = 0; i < n; i++)
        cout << col[i] + 1 << "\n "[i < n - 1];
}

void reset_variables() {
    for (int i = 0; i < n; i++) {
        col[i] = 0;
        st[l[i]].clear();
        en[r[i] + 1].clear();
    }
}

int main() {
    ios:: sync_with_stdio(0), cin.tie(0), cout.tie(0);
    for (cin >> t; t--; reset_variables())
        read_input(), solve(), write_output();
    return 0;
}
 Step 1: It is easy to check if the solution can be achieved with only one color. For any time point x, there must be at most one interval containing x, since if multiple intervals contain x, they must be colored differently. Step 2: A simple strategy is to solve the problem using three colors; First, we color some intervals with colors 1 and 2, then color others with color 3. For each step, we find the leftmost point that has not been colored yet and color the segment that contains this point. We always choose the interval with the largest endpoint that contains the current point. By coloring the intervals alternately with colors 1 and 2, we ensure that all points are covered by exactly one of these colors. Step 3: Now, we check if we can color the intervals with just two colors. For some point, x, suppose we have already colored the intervals [li,ri] with li≤x, such that all points before x have a unique color. At each step, we only need to determine which of the intervals like p that lp≤x≤rp can have a unique color. The key observation is that if an interval can be uniquely colored at time x, it can also remain uniquely colored for all times t such that x≤t≤ri.    Lemma: If an interval [li,ri] can be uniquely colored at time x, it can also be uniquely colored at all subsequent times x≤t≤ri. Proof: Consider coloring the intervals at time x. Intervals starting at x+1 will be colored with the opposite color to interval i, ensuring that the interval remains uniquely colored at time x+1. With this lemma, we can conclude that the changes in the coloring are O(n). It suffices to track the intervals that are added and removed at each point in time.  Step 4: To efficiently move from time x to x+1, we perform the following steps:    Remove the intervals that have ri=x (since they no longer contain x+1). Add the intervals that have li=x+1. Update the set of intervals that can be uniquely colored at time x+1.  Step 5: Finally, we observe that only the following points are important for the coloring:  li and ri for each interval. li−1 and ri+1, since these points mark the boundaries where intervals start or end.  Thus, we can compress the numbers to reduce the range of values we need to process.
/* In the name of Allah */
// Welcome to the Soldier Side!
// Where there's no one here, but me...
#include<bits/stdc++.h>
using namespace std;

const int N = 2e5 + 5;
vector<int> st[N << 2], en[N << 2];
int t, n, k, l[N], r[N], dp[N], col[N], prv[N];

void compress_numbers() {
    vector<int> help;
    for (int i = 0; i < n; i++) {
        help.push_back(l[i] - 1);
        help.push_back(l[i]);
        help.push_back(r[i]);
        help.push_back(r[i] + 1);
    }

    sort(help.begin(), help.end());
    help.resize(k = unique(help.begin(), help.end()) - help.begin());
    for (int i = 0; i < n; i++) {
        l[i] = lower_bound(help.begin(), help.end(), l[i]) - help.begin();
        r[i] = lower_bound(help.begin(), help.end(), r[i]) - help.begin();
    }
}

void save_checkpoints() {
    for (int i = 0; i < n; i++) {
        st[l[i]].push_back(i);
        en[r[i]].push_back(i);
    }
}

bool check_one() {
    for (int i = 0, open = 0; i < k; i++) {
        open += st[i].size();
        if (open > 1)
            return false;
        open -= en[i].size();
    }
    return true;
}

void color_with_two() {
    for (int i = k - 1, cur = -1; ~i; i--) {
        if (en[i].empty())
            continue;

        while (!~cur || i < dp[cur])
            if (~cur && ~prv[cur]) {
                col[prv[cur]] = col[cur];
                if (r[prv[cur]] >= l[cur])
                    col[prv[cur]] ^= 1;
                cur = prv[cur];
            }
            else
                for (int p: en[i])
                    if (~dp[p] && (!~cur || dp[p] < dp[cur]))
                        cur = p;

        for (int p: en[i])
            if (p ^ cur)
                col[p] = col[cur] ^ 1;
    }
}

bool check_two() {
    set<int> goods, bads;
    fill(dp, dp + n, -1);
    fill(prv, prv + n, -1);
    for (int i = 0; i < k; i++) {
        int prev = -1;
        if (i)
            for (int p: en[i - 1]) {
                bads.erase(p), goods.erase(p);
                if (~dp[p] && (!~prev || dp[p] < dp[prev]))
                    prev = p;
            }
        int open = goods.size() + bads.size();

        if (open == 1 || (open == 2 && !goods.empty())) {
            for (int p: bads) {
                if (open == 1)
                    prv[p] = prev;
                else
                    prv[p] = *goods.begin();
                goods.insert(p);
                dp[p] = i;
            }
            bads.clear();
        }

        if (open == 1)
            prev = *goods.begin();
        for (int p: st[i])
            if (!open || open == 1 || ~prev) {
                goods.insert(p);
                prv[p] = prev;
                dp[p] = i;
            }
            else
                bads.insert(p);
        open += st[i].size();

        if (open && goods.empty())
            return false;
    }

    color_with_two();
    return true;
}

void color_with_three() {
    int cur = -1, nxt = -1;
    for (int i = 0; i < k; i++) {
        if (st[i].empty())
            continue;

        if (~cur && i > r[cur] && nxt ^ cur) {
            col[nxt] = col[cur] ^ 3;
            cur = nxt;
        }
        if (!~cur || i > r[cur]) {
            for (int p: st[i])
                if (!~cur || r[p] > r[cur])
                    cur = p;
            col[nxt = cur] = 1;
        }

        for (int p: st[i])
            if (r[p] > r[nxt])
                nxt = p;
    }

    if (cur ^ nxt)
        col[nxt] = col[cur] ^ 3;
}

void read_input() {
    cin >> n;
    for (int i = 0; i < n; i++)
        cin >> l[i] >> r[i];
}

void solve() {
    compress_numbers();
    save_checkpoints();
    if (check_one())
        return;
    if (check_two())
        return;
    color_with_three();
}

void write_output() {
    cout << *max_element(col, col + n) + 1 << endl;
    for (int i = 0; i < n; i++)
        cout << col[i] + 1 << "\n "[i < n - 1];
}

void reset_variables() {
    fill(col, col + n, 0);
    for (int i = 0; i < k; i++) {
        st[i].clear();
        en[i].clear();
    }
}

int main() {
    ios:: sync_with_stdio(0), cin.tie(0), cout.tie(0);
    for (cin >> t; t--; reset_variables())
        read_input(), solve(), write_output();
    return 0;
}
 Step 1: According to Bézout's Identity, we can compute gcd(x1,…,xt) and all its multipliers as an integer linear combination of x1,x2,…,xt. Step 2: A set {a1,…,ak} is good (integer linearly independent) if for every i, gcd({aj∣j≠i})∤ai. Step 3: A set {a1,…,ak} is good if and only if there exists a set {p1q1,p2q2,…,pkqk} such that piqi∣aj for j≠i and piqi∤ai. Step 4: The set {a1,…,ak} can be identified by determining {p1q1,p2q2,…,pkqk}. Assume pq11<pq22<…<pqkk, where pi≠pj and pi is prime. Step 5: Let G=p1q1⋅p2q2…⋅pkqk. Then {a1,…,ak} is good if and only if Gpiqi∣ai and G∤ai for every i. Step 6: The answer is a singleton if, for every pair of numbers x and y in the array, x∣y or y∣x. Since the numbers are distinct, a good subset {a1,a2} can always be found by searching the first logM+2 elements. Step 7: Define CM[i] (count multipliers of i) as the number of x such that i∣ax. This can be computed in O(n+MlogM). Step 8: A corresponding set {a1,…,ak} exists for a set {p1q1,p2q2,…,pkqk} if and only if CM[Gpiqi]>CM[G]≥0 for all i. Step 9: Iterate over all valid sets of the form {p1q1,p2q2,…,pkqk}, and check if a corresponding {a1,a2,…,ak} exists. Note that k≥3 since a good subset {a1,a2} is found using another method. Step 10: We know Gp1q1≤M and also p1q1≤√M, as p1q1≤√p2q2⋅p3q3≤√Gp1q1≤√M. Step 11: There are ∑logM2i=1P[⌊2i√M⌋] numbers in the form p1q1, where P[i] denotes the number of primes in the range [1,i]. This count is O(√MlogM). Step 12: The value of k is at most 6 (denoted as K), as p2q2…pkqk=Gp1q1≤M, and 3⋅5⋅7⋅11⋅13≤M<3⋅5⋅7⋅11⋅13⋅17. Step 13: We can determine {a1,…,ak} from {p1q1,p2q2,…,pkqk} in O(n⋅K). The total time complexity is O(T⋅M⋅√MlogM⋅K+T⋅M⋅logM+∑Ti=0ni⋅K).
/// In the name of God the most beneficent the most merciful

#pragma GCC optimize("Ofast,no-stack-protector,unroll-loops,fast-math,O3")
#include <bits/stdc++.h>
using namespace std;
typedef long long ll;

constexpr int T = 100;
constexpr int M = 100001;
constexpr int SQM = 320;
constexpr int LGM = 20;
vector<pair<int,int>> factor;
int t, n[T], count_multipliers[T][M];
bitset<M> is_composite;
vector<int> ans[T], a[T];

inline void calculate_importants() {
    for(int i = 2; i < SQM; i++)
        if(!is_composite[i]) {
            for(int j = i; j < M; j *= i)
                factor.push_back({j,i});
            for(int j = i*i; j < M; j += i)
                is_composite.set(j);
        }
    for(int i = SQM; i < M; i++)
        if(!is_composite[i])
            factor.push_back({i,i});
    sort(factor.begin(), factor.end());
}

void check(vector<int> &factors, int G) {
    if(factors.size() > 2u) {
        for(int i = 0; i < t; i++) 
            if(ans[i].size() < factors.size()) {
                int count_product = (G < M? count_multipliers[i][G] : 0);
                bool can = true;	
                for(auto u: factors)
                    if(count_multipliers[i][G/factor[u].first] == count_product) {
                        can = false;
                        break;
                    }
                if(can)
                    ans[i] = factors;
            }
    }
    int bound = (factors.size() == 1 ? SQM : M);
    if(1LL*G/factor[factors[0]].first*factor[factors.back()].first > bound)
        return;
    for(int new_factor = factors.back(); G/factor[factors[0]].first*factor[new_factor].first <= bound; new_factor++) 
        if(G%factor[new_factor].second) {
            factors.push_back(new_factor);
            check(factors, G*factor[new_factor].first);
            factors.pop_back();
        }
}

int main() {
    ios_base :: sync_with_stdio(false); cin.tie(nullptr);
    calculate_importants();
    cin >> t;
    for(int i = 0; i < t; i++) {
        cin >> n[i];
        a[i].resize(n[i]);
        for(int j = 0; j < n[i]; j++) {
            cin >> a[i][j];
            count_multipliers[i][a[i][j]]++;
        }
        ans[i] = {a[i][0]};
        sort(a[i].begin(), a[i].begin()+min(n[i], LGM));
        for(int c = 0; c+1 < n[i]; c++)
            if(a[i][c+1]%a[i][c]) {
                ans[i] = {a[i][c], a[i][c+1]};
                break;
            }
        for(int c = 1; c < M; c++)
            for(int j = c+c; j < M; j += c)
                count_multipliers[i][c] += count_multipliers[i][j];
    }
    for(int i = 0; factor[i].first < SQM; i++) {
        vector<int> starter = {i};
        check(starter, factor[i].first);
    }
    for(int i = 0; i < t; i++) {
        int k = ans[i].size();
        cout << k << '\n';
        if(k == 1u) {
            cout << ans[i][0] << '\n';
        } else if(k == 2u) {
            cout << ans[i][0] << ' ' << ans[i][1] << '\n';
        } else {
            int subset[k];
            for(auto u: a[i]) {
                int ls = -1;
                for(int j = 0; j < (int)k; j++)
                    if(u%factor[ans[i][j]].first)
                        ls = (ls == -1? j: -2);
                if(ls >= 0)
                    subset[ls] = u;
            }
            for(int j = 0; j < k; j++)
                cout << subset[j] << (j+1 == k? '\n' : ' ');
        }
    }
    return 0;
}

/// Thank God . . .
 Handle: orzdevinwang, Country: China Handle: tourist, Country: Belarus Handle: jqdai0815, Country: Samoa Handle: maspy, Country: Japan Handle: hyman00, Country: China Handle: ksun48, Country: Canada Handle: ugly2333, Country: China Handle: errorgorn, Country: Singapore Handle: hos.lyric, Country: Japan Handle: Benq, Country: United States Handle: Um_nik, Country: United Kingdom Handle: Golovanov399, Country: Russia Handle: gamegame, Country: Hong Kong Handle: A_G, Country: United States Handle: antontrygubO_o, Country: Ukraine Handle: Crystally, Country: United States Handle: maroonrk, Country: Japan Handle: cmk666, Country: Antarctica Handle: 79brue, Country: South Korea Handle: junie, Country: South Korea Handle: arvindf232, Country: Hong Kong Handle: QwertyPi, Country: Hong Kong Handle: Radewoosh, Country: Poland Handle: 244mhq, Country: Belarus Handle: Amoo_Safar, Country: Iran Handle: SomethingNew, Country: Serbia Handle: phoenix0423, Country: Taiwan Handle: daubi, Country: Russia Handle: Karuna, Country: South Korea Handle: kostylevGO, Country: Russia Handle: oleh1421, Country: Ukraine Handle: alireza_kaviani, Country: Iran Handle: Tlatoani, Country: Mexico Handle: ymmparsa, Country: Iran Handle: KevinWan, Country: Canada Handle: OIer_kzc, Country: Spain Handle: win114514, Country: France Handle: JettyOller, Country: Vietnam Handle: Swistakk, Country: Poland Handle: Dominater069, Country: India Handle: MridulAhi, Country: India Handle: tkacper, Country: Poland Handle: PedroBigMan, Country: Portugal Handle: Thienu, Country: Thailand Handle: Egor, Country: Germany Handle: lmqzzz, Country: Vietnam Handle: Farhod, Country: Tajikistan Handle: kevinyang, Country: Canada Handle: busamate, Country: Hungary Handle: CDuongg, Country: Vietnam Handle: bthero, Country: Kazakhstan Handle: InternetPerson10, Country: Philippines Handle: Kaey, Country: Italy Handle: sstrong, Country: Kazakhstan Handle: Misuki, Country: Taiwan Handle: sevlll777, Country: Wallis and Futuna Handle: Kilani, Country: Jordan Handle: Xellos, Country: Slovakia Handle: aimoon, Country: Kyrgyzstan Handle: Kira_1234, Country: India 


[Editorial - contest/2041]
No editorial content found.


[Editorial - contest/2039]
 Great: 




183





 Good: 

    


261



 Average: 

    


69



 Bad: 

    


79



 Trash: 

    


75



 
 A: 

    


27



 B: 

    


65



 C1: 

    


62



 C2: 

    


58



 D: 

    


234



 E: 

    


45



 F1: 

    


8



 F2: 

    


4



 G: 

    


5



 H1: 

    


7



 H2: 

    


5



 
 A: 

    


10



 B: 

    


20



 C1: 

    


49



 C2: 

    


451



 D: 

    


13



 E: 

    


49



 F1: 

    


13



 F2: 

    


2



 G: 

    


1



 H1: 

    


2



 H2: 

    


1



 
2039A - Shohag Loves ModTHOUGHT: A general approach to tackle ad-hoc problems is to play around with the conditions and see if we can add more constraints to limit the search space.ACTION: Let's analyze the modular condition aimodi.We know that aimodi<i, and all aimodi values are distinct. Let's explore this step by step:  a1mod1 is always 0.  a2mod2 can be 0 or 1. But since all aimodi values must be distinct, a2mod2 must be 1 (otherwise, it would equal a1mod1).  a3mod3 can be 0, 1, or 2. Similarly, a3mod3 must be 2 (to avoid duplication with a1mod1 or a2mod2).  …  anmodn must be n−1. OBSERVATION: This leads to the constraint aimodi=i−1.THOUGHT: Next, let's consider the increasing sequence condition.OBSERVATION: Since the sequence must be increasing, we add the constraint ai≥i.THOUGHT: To further limit the search space, note that n can be up to 50, and ai must be ≤100.OBSERVATION: This suggests that we can restrict ai to values up to 2⋅n.THOUGHT: Let's compile the constraints:   aimodi=i−1.  ai≥i.  ai≤2⋅n. Now we need to build the sequence that satisfies these conditions.ACTION: Let's build the sequence starting from the end.  anmodn=n−1. Thus, an can be n−1 or 2⋅n−1. Since an≥n, an must be 2⋅n−1.  an−1mod(n−1)=n−2. So an−1 can be n−2 or (n−2)+(n−1)=2⋅n−3. Since an−1≥n−1, an−1 must be 2⋅n−3.  …  aimodi=i−1. Thus, ai can be i−1 or 2⋅i−1 or 3⋅i−1…. Since ai≥i and the odd numbers greater than 2⋅i have already been used, ai must be 2⋅i−1. OBSERVATION: If we limit the elements to 2⋅n, there is exactly one sequence that satisfies all conditions.CONCLUSION: The sequence is ai=2⋅i−1, which is 1,3,5,…,2⋅n−1.VALIDATION: We can validate the solution by checking if it satisfies all the constraints. aimodi=(2⋅i−1)modi=i−1. So all aimodi are distinct and values are under 2⋅n. So the sequence is valid.Time Complexity: O(n).
#include<bits/stdc++.h>
using namespace std;

const int N = 3e5 + 9;
using ll = long long;

void solve() {
  int n; cin >> n;
  for (int i = 1; i <= n; i++) {
    cout << 2 * i - 1 << ' ';
  }
  cout << '\n';
}

int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
 Amazing problem: 

    


270



 Good problem: 

    


56



 Average problem: 

    


39



 Bad problem: 

    


12



 Didn't solve: 

    


10



 
2039B - Shohag Loves StringsTHOUGHT: The condition seems hard to track. So a good way is to play around with smaller cases and see if we can make some observations.ACTION: Let's start with the smallest string. When s= a, the number of unique substrings f(s)=1, so it's odd and not valid.OBSERVATION: No one length strings are valid.ACTION: Let's try the next smallest strings. When s= aa, f(s)=2, so it's even and valid. When s= ab, f(s)=3, so it's odd and not valid.OBSERVATION: Two length strings are valid if the adjacent characters are same.THOUGHT: So if s contains two consecutive same characters, we can print it right away. All that remains is to consider strings without two consecutive same characters.ACTION: Let's try the next smallest strings with adjacent different characters. When s= aba, f(s)=5, so it's odd and not valid. When s= abc, f(s)=6, so it's even and valid.OBSERVATION: Three length strings are valid if all characters are different.THOUGHT: So if s contains three consecutive different characters, we can print it right away. All that remains is to consider strings without two adjacent same characters but no three consecutive different characters.So all the remaining strings are of the form s= abababababa...Let's try to see if we can make some observations about these strings.ACTION: Let's try to calculate the number of unique substrings for a string of the form s= abababababa...  There are exactly 2 unique substrings of length 1: a and b.  There are exactly 2 unique substrings of length 2: ab and ba.  There are exactly 2 unique substrings of length 3: aba and bab.  …  There are exactly 2 unique substrings of length n−1.  However, the length n substring occurs exactly once. OBSERVATION: The number of unique substrings of any length is 2. But only the length n substring occurs exactly once. So total number of unique substrings is 2n−1. And this is always odd! So there is no solution for these strings.THOUGHT: We have covered all the cases. CONCLUSION: If there are adjacent same characters, we can print it right away. If there are three consecutive different characters, we can print it right away. Otherwise there is no solution.Time Complexity: O(n).
#include<bits/stdc++.h>
using namespace std;

const int N = 3e5 + 9;
using ll = long long;

void solve() {
  string s; cin >> s;
  int n = s.size();
  for (int i = 0; i + 1 < n; i++) {
    if (s[i] == s[i + 1]) {
      cout << s.substr(i, 2) << '\n';
      return;
    }
  }
  for (int i = 0; i + 2 < n; i++) {
    if (s[i] != s[i + 1] and s[i] != s[i + 2] and s[i + 1] != s[i + 2]) {
      cout << s.substr(i, 3) << '\n';
      return;
    }
  }
  cout << -1 << '\n';
}

int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
 Amazing problem: 

    


326



 Good problem: 

    


55



 Average problem: 

    


34



 Bad problem: 

    


30



 Didn't solve: 

    


22



 
2039C1 - Shohag Loves XOR (Easy Version)THOUGHT: Here x>0 and y>0. So x⊕y is neither equal to x nor y. So x⊕y is a divisor of x or y and x⊕y<x or x⊕y<y.OBSERVATION: Any divisor d of p such that d<p we know that d≤⌊p2⌋. Also, the highest bits of d and p are different when d≤⌊p2⌋.THOUGHT: Wait but x⊕y has the same highest bit as y if y≥2⋅x.CONCLUSION: So if y≥2⋅x, then x⊕y can not be a divisor of y.THOUGHT: But can it be a divisor of x?OBSERVATION: If y≥2⋅x, then x⊕y>x because the highest bit in x⊕y is greater than that in x. So x⊕y can not be a divisor of x.CONCLUSION: If y≥2⋅x, then x⊕y can not be a divisor of x or y. So no solution in this case.THOUGHT: Now we need to consider the case when y<2⋅x. But x is small in this problem, making it feasible to iterate over all possible values of y.ACTION: Iterate over all possible values of y<2⋅x and check if x⊕y is a divisor of either x or y.Time Complexity: O(x).
#include<bits/stdc++.h>
using namespace std;

using ll = long long;

void solve() {
  int x; ll m; cin >> x >> m;

  int ans = 0;
  for (int y = 1; y <= min(2LL * x, m); y++) {
    if (x != y and ((x % (x ^ y)) == 0 or (y % (x ^ y) == 0))) {
      ++ans;
    }
  }
  cout << ans << '\n';
}

int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
 Amazing problem: 

    


280



 Good problem: 

    


84



 Average problem: 

    


41



 Bad problem: 

    


61



 Didn't solve: 

    


29



 
2039C2 - Shohag Loves XOR (Hard Version)THOUGHT: Consider the three cases of when x⊕y is divisible by x, y, or both separately.Case 1: x⊕y is divisible by x.THOUGHT: Let p=x⊕y. So y=p⊕x. So we can rephrase the problem as counting the number of integers p such that p is divisible by x and 1≤p⊕x≤m.OBSERVATION: p⊕x≤p+x, because xor is just addition without carry.THOUGHT: So it feels like almost all values of p≤m might work! And it's actually true because p⊕x≤p+x≤m, so if p+x≤m i.e. p≤m−x then p⊕x≤m is always true.CONCLUSION: All multiples of x under m−x always work! So the count is ⌊m−xx⌋.THOUGHT: But how about when p>m−x?OBSERVATION: if p>x, then p⊕x≥p−x, because xor is like subtraction without borrowing.THOUGHT: So if p−x>m i.e. p>m+x then p⊕x≥p−x>m is always true.CONCLUSION: So no values of p work when p>m+x.THOUGHT: And there are two multiples of x in the range (m−x,m+x]. So we can just check them manually.CONCLUSION: Answer is ⌊m−xx⌋ plus manually checking the two multiples of x in the range (m−x,m+x].Case 2: x⊕y is divisible by y.THOUGHT: As we already know that x⊕y≤x+y, and when x<y, x⊕y≤x+y<y+y=2⋅y.But as x>0 and y>0, so x⊕y is neither x nor y, so the smallest multiple of y that can work is 2⋅y. But x⊕y<2⋅y, so no solution here.CONCLUSION: No solution when x<y. And as x is small in this problem, so we can just iterate over all values of y≤x and manually check if x⊕y is divisible by y.Case 3: x⊕y is divisible by both x and y.THOUGHT: So the xor is divisible by lcm(x,y). So when x≠y, lcm(x,y)≥2⋅max(x,y) but x⊕y<2⋅max(x,y), so no solution here.CONCLUSION: Only works when y=x.FINAL CONCLUSION: So we just implement the above cases and the answer is the sum of case 1 and case 2 subtracted by case 3.Time Complexity: O(x).
#include<bits/stdc++.h>
using namespace std;

using ll = long long;

void solve() {
  int x; ll m; cin >> x >> m;

  // divisible by x
  ll p = m - m % x;
  ll ans = p / x - (x < p);
  if ((x ^ p) >= 1 and (x ^ p) <= m) ++ans;
  p += x;
  if ((x ^ p) >= 1 and (x ^ p) <= m) ++ans;

  // divisibly by y
  for (int y = 1; y <= min(1LL * x, m); y++) {
    ll cur = x ^ y;
    if (cur % y == 0) {
      ++ans;
    }
  }

  // divisible by both
  if (x <= m) {
    --ans;
  }

  cout << ans << '\n';
}

int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
 Amazing problem: 

    


138



 Good problem: 

    


36



 Average problem: 

    


49



 Bad problem: 

    


307



 Didn't solve: 

    


41



 
2039D - Shohag Loves GCDTHOUGHT: For problems where we need to construct something under some conditions, then a good idea is to first see the nature of the sequences that satisfy the conditions. And to find the properties of such sequences we can try to find some necessary conditions that must have to be met for the sequence to satisfy the conditions.ACTION: The given condition is that agcd(i,j)≠gcd(ai,aj) all i<j. As the given operation is gcd on indices and values, it's hard to directly find the properties of the sequence.But what happens when i divides j? Then agcd(i,j)=ai. So the condition becomes ai≠gcd(ai,aj) which translates to ai can not divide aj because otherwise gcd(ai,aj)=ai.So we have found a necessary condition: for any pair i<j where i divides j, ai can not divide aj.THOUGHT: Hmm, but is the condition sufficient? One way to check the sufficiency is to find a contradiction.ACTION: Imagine two indices i and j where i does not divide j but the condition is violated: agcd(i,j)=gcd(ai,aj).Then g=gcd(i,j) is a divisor of both i and j and as ag divides both ai and aj, so for pair (g,i) we have agcd(g,i)=ag and gcd(ag,ai)=ag because ag divides ai. So for this pair the condition is violated!So if the condition is violated for some pair (i,j) then it is violated for the pair (g,i) and (g,j) as well where g=gcd(i,j).So if there is no pair (i,j) where i divides j and the condition is violated, then all the pairs also satisfy the condition. This proves the sufficiency of the condition.THOUGHT: So we have found a necessary and sufficient condition. Now we need to construct the lexicographically largest sequence that satisfies the condition.Solution 1:Consider a multiple chain i1<i2<…<ik. Such that i1 divides i2, i2 divides i3, ..., ik−1 divides ik.Then we know that we have to put distinct values for all the indices in the multiple chain otherwise one number will be divisible by another which will violate the condition.And as we are aiming for the lexicographically largest sequence, it makes sense to put the values in decreasing order in a multiple chain i.e. ai1>ai2>…>aik. This way we don't have to care about the divisibility condition, as the numbers are in decreasing order.Now, we definitely will try to put the largest number possible for each index. So what is the largest number that we can put for the index x?Consider a directed graph where there is an edge from i to j if i divides j. Then the question is what is the length of the longest path in this graph ending at x.You can find it using a simple DP on this directed acyclic graph in O(nlogn) time.But if you think about it, the answer is actually simple. Let p(x) the number of prime factors of x counted with multiplicity. Then the answer is p(x)+1. For example, if x=2⋅32⋅5, then one of the longest chains ending at x is 1→2→2⋅3→2⋅32→2⋅32⋅5 which has length 4.We can precalculate the values p(x) for all 1≤x≤n in O(nlogn) time using sieve.So at index i we will put the (p(i)+1)-th largest number from the set S. And the largest value of p(i) for 1≤i≤n is ⌊log2n⌋ for the chain 1→2→22→…→2⌊log2n⌋.So if m<⌊log2n⌋+1, then we can't construct the sequence and the answer is −1. Otherwise set ai=sm−p(i) for all i.Also, unless you have noticed already, the actual numbers don't matter!Time Complexity: O(nlogn)Solution 2:As we are trying to construct the lexicographically largest sequence, it's always better to take larger values first. Let si be the i-th smallest number in the set S.  So, initially set a1=sm. Then we can't use sm for any other index as it will violate the condition. Then set a2=sm−1 (because we can't use sm). Then we can't use sm−1 for any other index j where j is divisible by 2 as it will violate the condition. Then set a3=sm−1 (because we can't use sm). Then we can't use sm−1 for any other index j where j is divisible by 3 as it will violate the condition. Now set a4=sm−2 (because we can't use sm−1 or sm). Then we can't use sm−2 for any other index j where j is divisible by 4 as it will violate the condition. Then for a5 we can actually use sm−1 as 5 is not divisible by 2,3, or 4 so the only constraint is that a5≠a1. ... Notice that this is a sieve-like process where we are using the maximum number that we can use for the current index and then we are remembering that in the multiples of the current index, the current number can't be used. We can use sets to simulate the process.So this process will always construct a valid lexicographically largest sequence. If it is not possible to construct the sequence, then the answer is −1.Also, if you notice the construction process carefully, the actual numbers don't matter!Time Complexity: O(nlog2n)
#include<bits/stdc++.h>
using namespace std;

const int N = 1e5 + 9;
int p[N];
void solve() {
  int n, m; cin >> n >> m;
  vector<int> s(m + 1);
  for (int i = 1; i <= m; i++) {
    cin >> s[i];
  }
  if (m < __lg(n) + 1) {
    cout << -1 << '\n';
    return;
  }
  for (int i = 1; i <= n; i++) {
    cout << s[m - p[i]] << ' ';
  }
  cout << '\n';
}

int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  for (int i = 2; i < N; i++) {
    if (p[i]) continue;
    for (int j = i; j < N; j += i) {
      int x = j;
      while (x % i == 0) x /= i, ++p[j];
    }
  }
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
#include<bits/stdc++.h>
using namespace std;

const int N = 1e5 + 9;
using ll = long long;

vector<int> d[N];
void solve() {
  int n, m; cin >> n >> m;
  vector<int> s(m + 1);
  for (int i = 1; i <= m; i++) {
    cin >> s[i];
  }
  vector<int> a(n + 1, -1);
  for (int i = 1; i <= n; i++) {
    set<int> banned;
    for (int j: d[i]) {
      banned.insert(a[j]);
    }
    for (int k = m; k >= 1; k--) {
        if (banned.find(s[k]) == banned.end()) {
            a[i] = s[k];
            break;
        }
    }
    if (a[i] == -1) {
        cout << -1 << '\n';
        return;
    }
  }
  for (int i = 1; i <= n; i++) {
    cout << a[i] << ' ';
  }
  cout << '\n';
}

int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  for (int i = 1; i < N; i++) {
    for (int j = i + i; j < N; j += i) {
        d[j].push_back(i);
    }
  }
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
 Amazing problem: 

    


248



 Good problem: 

    


32



 Average problem: 

    


16



 Bad problem: 

    


28



 Didn't solve: 

    


10



 
2039E - Shohag Loves InversionsIt's hard to track the array when we insert new inversions as the inversion number can quickly become very large.The key observation here is to notice what happens when the inversion count becomes more than 1. As the initial array has only 0 and 1 as elements when we insert an inversion count that is more than 1, the inversion count will be larger than any element of the array. And this gives us a way to control everything!Let dpi be the number of final arrays of length n we can get from the current array of length i if the current number of inversions in it is larger than any element of the array.Let k be the number of inversions in the current array and k>max(a). Then  If we insert k not in the end, then the new inversion count will be more than k, so we get the same situation for dpi+1  Or if we insert k in the end then the number of inversions will still be k. So if we inserted it j times in the end and once somewhere else (i ways to do so) then we will get the situation for dpi+j+1 So dpi=(i⋅∑j>idpj)+1, here 1 is added as we can end the sequence here by inserting k in the end (n−i) times.This can be computed with simple dp in O(n) time using suffix sums.Now we just need to deal with the starting array when it starts to have more than 1 inversion.There are (n−1) ways to finish the sequence having ≤1 inversion. And they are of the form 0,0,…,0,[0,1,0],1,…,1,1 this is because we first insert 0 at the beginning for some time and then we get 1 inversion count when we insert 0 at the end for the first time and then we will have to insert 1 at the end every time after that.And to count the ways to get the starting array of length m with more than 1 inversion, we can notice that it's just the sum of ways where we insert 1 before the first 1 in any sequence of the form like above 0,0,…,0,[0,1,0],1,…,1,1. And if the position of the first 1 is j then we have (j−1) ways to do so. So total ways is ∑m−1j=2(j−1)=(m−2)⋅(m−1)2−1So the answer is just n−1+∑nm=3((m−2)⋅(m−1)2−1)⋅dpmTime Complexity: O(n)Note that there are ways to write the dp so that you don't have to handle the starting array separately. Also in this problem, we have limited the total sum of n over all test cases. But there exists solutions where the solution works even without the limit but we decided to let both solutions pass.Also, I am extremely sorry that during the contest we found out that some people found the second difference/derivative of the sequence on OEIS. We searched on OEIS before but couldn't find it, otherwise we would have modified the problem. Again, sorry for this issue.
#include<bits/stdc++.h>
using namespace std;

const int N = 1e6 + 9, mod = 998244353;
using ll = long long;

int dp[N]; // count of arrays that we can get if the current number of inversions is > max element of the array
void solve() {
  int n; cin >> n;
  int sum = 0;
  for (int i = n; i >= 1; i--) {
    dp[i] = (1LL * i * sum % mod + 1) % mod;
    sum = (sum + dp[i]) % mod;
  }
  int ans = n - 1; // arrays having 0 and 1 inversions
  for (int k = 3; k <= n; k++) {
    int ways = (1LL * (k - 1) * (k - 2) / 2 - 1 + mod) % mod; // count of arrays achievable such that > 1 inversion count was inserted for the first time
    ans += 1LL * ways * dp[k] % mod;
    ans %= mod;
  }
  cout << ans << '\n';
}

int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
#include <bits/stdc++.h>

#include <chrono>
std::mt19937 eng(std::chrono::steady_clock::now().time_since_epoch().count());
int rnd(int l, int r) { return std::uniform_int_distribution<int>(l, r)(eng); }

namespace FastIO {
//	char buf[1 << 21], *p1 = buf, *p2 = buf;
//	#define getchar() (p1 == p2 && (p1 = buf, p2 = (p1 + fread(buf, 1, 1 << 21, stdin))) == p1 ? EOF : *p1++)
	template <typename T> inline T read() { T x = 0, w = 0; char ch = getchar(); while (ch < '0' || ch > '9') w |= (ch == '-'), ch = getchar(); while ('0' <= ch && ch <= '9') x = x * 10 + (ch ^ '0'), ch = getchar(); return w ? -x : x; }
	template <typename T> inline void write(T x) { if (!x) return; write<T>(x / 10), putchar((x % 10) ^ '0'); }
	template <typename T> inline void print(T x) { if (x > 0) write<T>(x); else if (x < 0) putchar('-'), write<T>(-x); else putchar('0'); }
	template <typename T> inline void print(T x, char en) { print<T>(x), putchar(en); }
//	inline char rChar() { char ch = getchar(); while (!isalpha(ch)) ch = getchar(); return ch; }
}; using namespace FastIO;

using i32 = int32_t;
using u32 = uint32_t;
using u64 = uint64_t;
template <uint32_t MOD> struct mint {
	static constexpr u32 get_r() {
		u32 ret = MOD;
		for (i32 i = 0; i < 4; ++i) ret *= 2 - MOD * ret;
		return ret;
	}
	static constexpr u32 r = get_r();
	static constexpr u32 n2 = -u64(MOD) % MOD;
	static_assert(r * MOD == 1, "invalid, r * MOD != 1");
	static_assert(MOD < (1 << 30), "invalid, MOD >= 2 ^ 30");
	static_assert((MOD & 1) == 1, "invalid, MOD % 2 == 0");
	u32 a;
	constexpr mint() : a(0) {}
	constexpr mint(const int64_t &b) : a(reduce(u64(b % MOD + MOD) * n2)){};
	static constexpr u32 reduce(const u64 &b) { return (b + u64(u32(b) * u32(-r)) * MOD) >> 32; }
	 constexpr mint &operator += (const mint &b) { if (i32(a += b.a - 2 * MOD) < 0) a += 2 * MOD; return *this; }
	constexpr mint &operator -= (const mint &b) { if (i32(a -= b.a) < 0) a += 2 * MOD; return *this; }
	constexpr mint &operator *= (const mint &b) { a = reduce(u64(a) * b.a); return *this; }
	constexpr mint &operator /= (const mint &b) { *this *= b.inverse(); return *this; }
	constexpr mint operator + (const mint &b) const { return mint(*this) += b; }
	constexpr mint operator - (const mint &b) const { return mint(*this) -= b; }
	constexpr mint operator * (const mint &b) const { return mint(*this) *= b; }
	constexpr mint operator / (const mint &b) const { return mint(*this) /= b; }
	constexpr bool operator == (const mint &b) const { return (a >= MOD ? a - MOD : a) == (b.a >= MOD ? b.a - MOD : b.a); }
	constexpr bool operator != (const mint &b) const { return (a >= MOD ? a - MOD : a) != (b.a >= MOD ? b.a - MOD : b.a); }
	constexpr mint operator-() const { return mint() - mint(*this); }
	constexpr mint pow(u64 n) const { mint ret(1), mul(*this); while (n > 0) { if (n & 1) ret *= mul; mul *= mul, n >>= 1; } return ret; }
	constexpr mint inverse() const { return pow(MOD - 2); }
	friend std::ostream &operator<< (std::ostream &os, const mint &b) { return os << b.get(); }
	friend std::istream &operator>> (std::istream &is, mint &b) { int64_t t; is >> t; b = mint<MOD>(t); return (is); }
	constexpr u32 get() const { u32 ret = reduce(a); return ret >= MOD ? ret - MOD : ret; }
	static constexpr u32 get_MOD() { return MOD; }
    explicit operator u32() const { return get(); }
}; using modint = mint<998244353>;

// Let's write some brute first
// dp[i][j] := current length is i, current number of inversions is j (not inserted)
// dp[i][j] -> dp[>= i + 1][[j + 1, j + i]]
// this is true for j >= 1, so let's do something when j = 0
// we can generate [0, (0 ... ), 1, 0] -> dp[>= 3][1]
// this is still kinda annoying because 1 > 1 does not hold, we process it till j >= 2
// [0, 0, ..., 0, 1, 0] -> [0, 0, ..., 0, 1, 0, 1, ..., 1]
// after that we insert an 1 before some numbers of 0 and we get dp[i][1] -> dp[>= i + 1][[j + 1, j + i - 1]]
// the answer is sum dp[i][j] for all 1 <= i <= n, j >= 1, plus 1 ([0, 0, 0 ... 1])
// actually we care nothing 'bout, j so let's say f[i] = sum dp[i][j]
// (f[i] * i - 1) -> f[i + 1], f[i + 2], ..., f[n]

#define MAXN 1000001
modint f[MAXN];
void solve() {
	int n = read<int>(); modint ans = 1, pre = 2;
	f[3] = 1;
	for (int i = 4; i <= n; ++i) 
		f[i] = pre + modint(1), pre += f[i] * modint(i) - modint(1);
	for (int i = 3; i <= n; ++i) ans += f[i];
	// f[3] : [0, 1, 0]
	// f[4] : [0, 0, 1, 0] (+1), [0, 1, 1, 0], [1, 0, 1, 0] (dp[3][1] * 2)
	print<int>(ans.get(), '\n');
}

int main() { int T = read<int>(); while (T--) solve(); return 0; }
 Amazing problem: 

    


49



 Good problem: 

    


31



 Average problem: 

    


29



 Bad problem: 

    


90



 Didn't solve: 

    


20



 
2039F1 - Shohag Loves Counting (Easy Version)Let s_k be the sequence of k length subarray maximums of the array. Then s_{k + 1} is just the adjacent maximum sequence of s_k.Also, let g_k be the GCD of the elements of s_k. Then notice that every element of s_{k + 1} is also divisible by g_k. That is g_k divides g_{k + 1}.For the array to be good, g_k must be different for all k. So g_k < g_{k + 1} and g_k divides g_{k + 1}. This means if the length of the array is n, then n le lfloor log_2 m rfloor + 1.Now consider a non-decreasing sequence of integers a of length n such that 1 le a_i le m for all i. Then the k length subarray maximums of a are just the last k elements of a. So g_k is the GCD of the last k elements of a. Then for g_k to be different for all k, all the elements of a must be distinct. So the condition for a to be good is that the elements are distinct and all suffix GCDs are distinct as well.Next the question is how many permutations of this increasing sequence a is good as well? To count this, lets start from s_n. s_n is just [a_n]. Now consider s_{n - 1}. We need to put a_{n - 1} in the sequence such that the adjacent maximum sequence of s_{n-1} becomes s_n. For this we clearly have 2 ways: [a_{n - 1}, a_n] and [a_n, a_{n - 1}].Now consider s_{n - 2}. We need to put a_{n - 2} in the sequence such that the adjacent maximum sequence of s_{n-2} becomes s_{n-1}. For this we again have 2 ways because a_{n - 2} can be inserted in 2 places: before a_{n - 1} or after a_{n - 1}.Similarly for all other s_k we have 2 ways to insert it: putting it before a_{k + 1} or after a_{k + 1}. So the total number of good permutations of a is 2^{n - 1}.So our problem reduces to the following:  Select a length n such that 1 le n le lfloor log_2 m rfloor + 1.  Count the number of strictly increasing sequences of length n such that all suffix GCDs are distinct.  Multiply the answer by 2^{n - 1}.  Sum up the answer for all valid n. For a fixed n, let's count the number of strictly increasing sequences of length n such that all suffix GCDs are distinct.Let text{dp}_{i, g} be the number of strictly increasing sequences of length n such that the starting element is i and the GCD of the elements is g.Now iterate from i = m to 1. Then the transition is to iterate over the next suffix GCD h such that g divides h, g < h le m and g = text{gcd}(i, h) and then add text{dp}_{*, h} to text{dp}_{i, g}. Here text{dp}_{*, h} is the sum of all text{dp}_{j, h} for all j > i.Another way to look at the transition is that for a fixed i, we iterate over all h and if text{gcd}(i, h) < h, then we add text{dp}_{*, h} to text{dp}_{i, text{gcd}(i, h)}.But doing everything like this would still be O(m^2 log m) which is too slow.Notice that all g are the divisors of i. Here the main difficulty is that we need update at the index text{gcd}(i, h) over all h but it is hard to track the exact gcd but what's easier is to track the multiple of the gcd.So for each g, let's say we know the sum of all text{dp}_{*, h} over all h such that g divides h. So this sums up all text{dp}_{*, h} such that g divides text{gcd}(i, h). Then using inclusion exclusion on the divisors of i we can get the sum of all text{dp}_{*, h} for all h such that g is exactly text{gcd}(i, h). This will take O(sigma(i)^2) time for each i where sigma(i) is the number of divisors of i.And once we calculate the text{dp}_{i, g} for some i and g, then before transitioning to i - 1, we can add the value of text{dp}_{i, g} to all divisors of g to get the value of text{dp}_{*, h} faster in the future. To keep track of this, we can use a separate array.So for a fixed n, the time complexity is O(sum_{i = 1}^{m} sigma(i)^2). And we need to do this for all n from 1 to lfloor log_2 m rfloor + 1.So the overall time complexity is O(log m cdot sum_{i = 1}^{m} sigma(i)^2). We actually allowed this to pass in F1.We can make the time complexity much better with a simple modification in the dp. Note that we don't need to use the length of array in the dp state. As we need to sum up after multiplying by 2^{text{length of array} - 1} at the end, we can modify the dp to directly store the sum of 2^{text{length of array} - 1}. So we can just multiply the dp by 2 during each transition.So the time complexity becomes O(sum_{i = 1}^{m} sigma(i)^2). This is very fast for F1.
#include<bits/stdc++.h>
using namespace std;

const int N = 2e5 + 9, mod = 998244353;
using ll = long long;

int add(int a, int b){
	a += b;
	if(a > mod) a -= mod;
	if(a < 0) a += mod;
	return a;
}

// dp[i][j] = number of arrays where starting element is i and gcd of the array is j
int dp[N], cur[N], uni[N];
int sum[N];
vector<int> d[N];
void solve() {
  int m; cin >> m;
  for (int i = 1; i <= m; i++) {
    dp[i] = cur[i] = 0;
	uni[i] = 0;
	sum[i] = 0;
  }
  int ans = 0;
  ans = 0;
  for (int i = m; i >= 1; i--) {
    for (int j: d[i]) {
      cur[j] = 0;
    }
	int sz = d[i].size();
	for(int idj = sz-1; idj >= 0; idj--){
		int j = d[i][idj];
		uni[j] = add(sum[j],sum[j]);
		for(int idk = idj+1; idk < sz; idk++){
			int k = d[i][idk];
			if(k%j) continue;
			uni[j] = add(uni[j],-uni[k]);
		}
		cur[j] = add(uni[j], - add(dp[j],dp[j]));
	}

    cur[i] += 1;

    for (int j : d[i]) {
	  dp[j] = add(dp[j],cur[j]);
	  for(auto k : d[j]){
	  	sum[k] = add(sum[k],cur[j]);
	  }
	  ans = add(ans,cur[j]);
    }
	
  }
  cout << ans << '\n';
}

int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  for (int i = 1; i < N; i++) {
    for (int j = i; j < N; j += i) {
      d[j].push_back(i);
    }
  }
  int t = 1;
  cin >> t;
  while (t--) {
    solve();
  }
  return 0;
}
 Amazing problem: 

    


37



 Good problem: 

    


8



 Average problem: 

    


2



 Bad problem: 

    


9



 Didn't solve: 

    


13



 
2039F2 - Shohag Loves Counting (Hard Version)First, check the editorial of F1.Note that for F2 there is no limit on the sum of m, so we need to change the approach a bit.And for F2 you need to remove the length from the dp state (which I described at the end of the editorial of F1).Now instead of iterating i from m to 1, we iterate from 1 to m. And reformulate the dp as follows.Let's say we are building the strictly increasing sequence a from left to right and we are fixing what the suffix GCD of the final array a starting from each element will be.Let dpj,h be the sum of 2length of array so far−1 for all a such that we are at element j and the suffix GCD of the final array a starting from element j is h.Then the transition is to iterate over the previous suffix GCD g at element i such that g divides h, g<h and g=gcd(i,h) and then add dpi,g to dpj,h.Just like F1, we can speed up the transitions by tracking some prefix sums and doing inclusion-exclusion on the divisors of i. We can use the Mobius Inversion Formula to do it in O(∑d|iσ(d)). Another way to make it faster is to do SOS DP on the divisors of i which will take O(σ(i)⋅p(i)) where p(i) is the number of unique prime factors of i.It is hard to describe all the little details of the implementation here, please refer to the code for more details.The overall time complexity is O(∑Mi=1σ(i)⋅p(i)) or O(∑Mi=1∑d|iσ(d)) where M is the maximum value of m. Both work fast enough. 
#include<bits/stdc++.h>
using namespace std;
 
const int N = 1e6 + 9, mod = 998244353;
 
inline void add(int &x, int y) {
  x = x + y >= mod ? x + y - mod : x + y;
}
int mob[N];
void mobius() {
  mob[1] = 1;
  for (int i = 2; i < N; i++){
    mob[i]--;
    for (int j = i + i; j < N; j += i) {
      mob[j] -= mob[i];
    }
  }
  for (int i = 1; i < N; i++) {
    mob[i] = (mob[i] % mod + mod) % mod;
  }
}
vector<int> divs[N];
int dp[N];
int f[N];
int tmp[N], ans[N];
void solve() {
  for (int i = 1; i < N; i++) {
    for (int d: divs[i]) {
      tmp[d] = (mod - f[d]) % mod;
      for (int c: divs[d]) {
        add(tmp[d], dp[c]);
      }
      tmp[d] = (2 * tmp[d] + 1) % mod;
    }

    // apply mobius inversion formula
    for (int d: divs[i]) {
      for (int c: divs[d]) {
        add(dp[d], 1LL * mob[c] * tmp[d / c] % mod);
      }
      add(f[d], tmp[d]);
    }

    ans[i] = ans[i - 1];
    add(ans[i], f[i]);
  }
}
 
int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  for (int i = 1; i < N; i++) {
    for (int j = i; j < N; j += i) {
      divs[j].push_back(i);
    }
  }
  mobius();
  solve();
  int t = 1;
  cin >> t;
  while (t--) {
    int m; cin >> m;
    cout << ans[m] << '\n';
  }
  return 0;
}

#include<bits/stdc++.h>
using namespace std;
 
const int N = 1e6 + 9, mod = 998244353;
 
inline void add(int &x, int y) {
  x = x + y >= mod ? x + y - mod : x + y;
}
int spf[N];
void sieve() {
  vector<int> p;
  for(int i = 2; i < N; i++) {
    if (spf[i] == 0) spf[i] = i, p.push_back(i);
    int sz = p.size();
    for (int j = 0; j < sz && i * p[j] < N && p[j] <= spf[i]; j++) {
      spf[i * p[j]] = p[j];
    }
  }
}
int mob[N];
void mobius() {
  mob[1] = 1;
  for (int i = 2; i < N; i++){
    mob[i]--;
    for (int j = i + i; j < N; j += i) {
      mob[j] -= mob[i];
    }
  }
  for (int i = 1; i < N; i++) {
    mob[i] = (mob[i] % mod + mod) % mod;
  }
}
int c[N];
vector<int> divs[N];
void gen_divs(int n) { // not sorted
  int id = 1, x = n;
  divs[n][0] = 1;
  while (n > 1) {
    int k = spf[n];
    int cur = 1, sz = id;
    while (n % k == 0) {
      cur *= k;
      n /= k;
      for (int i = 0; i < sz; i++) {
        divs[x][id++] = divs[x][i] * cur;
      }
    }
  }
}

void prec() {
  sieve();
  // generate divisors without using push_back as its really slow on Codeforces
  for (int i = 1; i < N; i++) {
    for (int j = i; j < N; j += i) {
      c[j]++;
    }
    divs[i].resize(c[i]);
    gen_divs(i);
  }
  mobius();
}
int dp[N];
int f[N];
int tmp[N], ans[N];
void solve() {
  for (int i = 1; i < N; i++) {
    for (int d: divs[i]) {
      tmp[d] = (mod - f[d]) % mod;
      for (int c: divs[d]) {
        add(tmp[d], dp[c]);
      }
      tmp[d] = (2 * tmp[d] + 1) % mod;
    }

    // apply mobius inversion formula
    for (int d: divs[i]) {
      for (int c: divs[d]) {
        add(dp[d], 1LL * mob[c] * tmp[d / c] % mod);
      }
      add(f[d], tmp[d]);
    }

    ans[i] = ans[i - 1];
    add(ans[i], f[i]);
  }
}
 
int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  prec();
  solve();
  int t = 1;
  cin >> t;
  while (t--) {
    int m; cin >> m;
    cout << ans[m] << '\n';
  }
  return 0;
}

 Amazing problem: 

    


18



 Good problem: 

    


1



 Average problem: 

    


3



 Bad problem: 

    


25



 Didn't solve: 

    


12



 
2039G - Shohag Loves PebaeLet's say we assign au to the node u. Let hu be the maximum length of a simple path that passes through u. Then a necessary condition is that au can not be a multiple of any number ≤hu. Because if au is a multiple of k≤hu and v is a node such that the unique simple path from u to v has length k, then the LCM of the values of the nodes from u to v is a multiple of k, which is a contradiction.The condition also means that au can not be a multiple of any prime number p≤hu.Is this a sufficient condition? Yes, and the proof is also simple.So now the problem is to count the number of assignments such that for each node u, au is not a multiple of any prime number p≤hu and gcd(a1,a2,…,an)=1.Let   fw,p be the count of numbers from 1 to w that are not divisible by any prime ≤p,  D be the diameter of the tree,  A number x is good if x is not divisible by any prime ≤D,  μ(g) be the Mobius function,  π(x) be the number of primes ≤x. Then the answer to our problem is ∑mg=1μ(g)⋅[g is good]⋅∏ni=1f⌊mg⌋,hi.As ⌊mg⌋ is a non-decreasing function and has at most 2√m distinct values, we can iterate over ⌊mg⌋ and calculate range sums of μ(g)⋅[g is good].For calculating prefix sums of a multiplicative function (like μ(g)), it's a standard task and can be solved using Dirichlet convolution, Min25 sieve or multiple other methods.Here, we need a slight variant of the method as we need the prefix sums of μ(g)⋅[g is good]. This can be achieved using Dirichlet convolution in O(m2/3) if we just imagine the prime numbers ≤D do not exist in the number system. Refer to my code for more details.But for each fixed ⌊mg⌋, how do we calculate ∏ni=1f⌊mg⌋,hi fast enough? Trivially doing it will make the total complexity around O(n√m) which is too slow.The key observation is to not forget that the values of hi are not random, they are the maximum length of a simple path that passes through the node i. So hi≥⌈D2⌉ for all i because from each node, the endpoints of the diameter are at least ⌈D2⌉ away.So now consider two cases:Case 1: D>2√mIn this case, all hi≥⌈D2⌉≥√m for all i. So only primes or 1 are the good numbers. So instead of going with the mobius route, we can just directly solve it by calculating the total number of ways and subtracting the number of ways where the gcd is a prime.We can calculate the total number of ways by first calculating the number of primes ≤m and then fm,hi is just π(m)−π(hi)+1.And the number of ways where the gcd is a prime is just 1 for all primes >D and 0 otherwise.Counting primes under m is also a standard task and can be done in O(m2/3logm) or faster.Case 2: D≤2√mWe can convert each hi to the maximum prime ≤hi and then group hi by their values. Then the maximum number of groups will be O(π(√m)). So for each fixed k=⌊mg⌋, if the sum of the mobius function in the range (⌊mk+1⌋,⌊mk⌋] is non-zero (keep in mind that when all numbers in the range are bad numbers, then the sum will definitely be 0), then we can calculate the product of fk,hi directly. Then the upper bound of the complexity will be around O(mlog2m⋅log(nπ(3√m))). The proof will be added later. This works fast enough.
#include<bits/stdc++.h>
using namespace std;
#include<ext/pb_ds/assoc_container.hpp>
#include<ext/pb_ds/tree_policy.hpp>
using namespace __gnu_pbds;

struct custom_hash {
  static uint64_t splitmix64(uint64_t x) {
    x += 0x9e3779b97f4a7c15;
    x = (x ^ (x >> 30)) * 0xbf58476d1ce4e5b9;
    x = (x ^ (x >> 27)) * 0x94d049bb133111eb;
    return x ^ (x >> 31);
  }
  size_t operator()(uint64_t x) const {
    static const uint64_t FIXED_RANDOM = chrono::steady_clock::now().time_since_epoch().count();
    return splitmix64(x + FIXED_RANDOM);
  }
};

const int N = 1e6 + 9, T = 1e7 + 9, RT = 33333, mod = 998244353; 
using ll = long long;

int power(int n, long long k) {
  int ans = 1 % mod;
  while (k) {
    if (k & 1) ans = (long long) ans * n % mod;
    n = (long long) n * n % mod;
    k >>= 1;
  }
  return ans;
}

int SQRT(int n) {
  int x = sqrt(n);
  while (x * x < n) ++x;
  while (x * x > n) --x;
  return x;
}

int spf[T], id[T], DIAMETER, mu[T];
vector<int> primes; // 1 indexed
int prefix_prime_count[T], prefix_sum_mu[T];
void init() {
  mu[1] = 1;
  for(int i = 2; i < T; i++) {
    if (spf[i] == 0) spf[i] = i, mu[i] = i <= DIAMETER ? 0 : -1, primes.push_back(i);
    int sz = primes.size();
    for (int j = 0; j < sz && i * primes[j] < T && primes[j] <= spf[i]; j++) {
      spf[i * primes[j]] = primes[j];
      if (i % primes[j] == 0) mu[i * primes[j]] = 0;
      else mu[i * primes[j]] = mu[i] * (primes[j] <= DIAMETER ? 0 : -1);
    }
  }
  primes.insert(primes.begin(), 0);
  for (int i = 1; i < primes.size(); i++) {
    id[primes[i]] = i;
  }
  for (int i = 2; i < T; i++) {
    prefix_prime_count[i] = prefix_prime_count[i - 1] + (spf[i] == i);
  }
  for (int i = 1; i < T; i++) prefix_sum_mu[i] = prefix_sum_mu[i - 1] + mu[i];
}
int cnt[N]; // count of nodes having each diameter
int m;
namespace GoodNumbers { // numbers which aren't divisible by the first k primes
  gp_hash_table<int, int, custom_hash> mp[RT << 1];
  int count_num(int n, int k) { // n is a floor value, returns good numbers <= n
    if (k == 0 or n == 0) return n;
    if (primes[k] >= n) return 1;
    if (n < T and 1LL * primes[k] * primes[k] > n) {
      return 1 + prefix_prime_count[n] - k;
    }
    if (mp[k].find(n) != mp[k].end()) return mp[k][n];
    int ans;
    if (1LL * primes[k] * primes[k] > n) {
      int x = upper_bound(primes.begin(), primes.begin() + k, (int)SQRT(n)) - primes.begin() - 1;
      ans = count_num(n, x) - (k - x);
    }
    else ans = count_num(n, k - 1) - count_num(n / primes[k], k - 1);
    mp[k][n] = ans;
    return ans;
  }
};

vector<pair<int, int>> v;
namespace Dirichlet {
  // good number = numbers that aren't divisible by any prime <= DIAMETER
  // we will run dirichlet imagining there exists no prime <= DIAMETER
  gp_hash_table<int, int, custom_hash> mp;
  int p_c(int n) {
    return n < 1 ? 0 : 1;
  }
  int p_g(int n) {
    return GoodNumbers::count_num(n, v.back().first);
  }
  int solve (int x) { // sum of mob[i] over 1 <= i <= x and i is a good number
    if (x < T) return prefix_sum_mu[x];
    if (mp.find(x) != mp.end()) return mp[x];
    int ans = 0;
    for (int i = 2, last; i <= x; i = last + 1) {
      last = x / (x / i);
      ans += solve(x / i) * (p_g(last) - p_g(i - 1));
    }
    ans = p_c(x) - ans;
    return mp[x] = ans;
  }
};

int count_primes(int n) {
  if (n < T) return prefix_prime_count[n];
  int x = SQRT(n);
  int k = upper_bound(primes.begin(), primes.end(), x) - primes.begin() - 1;
  return GoodNumbers::count_num(n, k) + k - 1;
}


// diameter > 2 * sqrt(m)
void solve_large() {
  // only primes are good, so count total ways
  // and subtract where gcd is prime (means all nodes have a fixed prime)
  int total_ways = 1;
  int primes_under_m = count_primes(m);
  for (auto [k, c]: v) {
    if (m <= primes[k]) break;
    total_ways = 1LL * total_ways * power((primes_under_m - k + 1) % mod, c) % mod; // 1 or a prime > k
  }
  int bad_ways = (max(0, primes_under_m - v.back().first)) % mod;
  int ans = (total_ways - bad_ways + mod) % mod;
  cout << ans << '\n';
}

// diameter <= 2 * sqrt(m)
void solve_small() {
  int ans = 0;
  for (int l = 1, r; l <= m; l = r + 1) {
    int x = m / l;
    r = m / x;
    int cur = ((Dirichlet::solve(r) - Dirichlet::solve(l - 1)) % mod + mod) % mod;
    if (cur) {
      int mul = 1;
      for (auto [k, c]: v) {
        if (x <= primes[k]) break;
        mul = 1LL * mul * power(GoodNumbers::count_num(x, k) % mod, c) % mod;
      }
      ans += 1LL * cur * mul % mod;
      ans %= mod;
    }
  }
  cout << ans << '\n';
}

vector<int> g[N];
int dp[N], up[N];
void dfs(int u, int p = 0) {
  dp[u] = 0;
  if (p) g[u].erase(find(g[u].begin(), g[u].end(), p));
  for (auto v: g[u]) {
    if (v ^ p) {
      dfs(v, u);
      dp[u] = max(dp[u], dp[v] + 1);
    }
  }
}
int pref[N], suf[N];
void dfs2(int u) {
  int sz = g[u].size();
  for (int i = 0; i < sz; i++) {
    int v = g[u][i];
    pref[i] = dp[v] + 1;
    if (i) pref[i] = max(pref[i], pref[i - 1]);
  }
  for (int i = sz - 1; i >= 0; i--) {
    int v = g[u][i];
    suf[i] = dp[v] + 1;
    if (i + 1 < sz) suf[i] = max(suf[i], suf[i + 1]);
  }
  for (int i = 0; i < sz; i++) {
    int v = g[u][i];
    int cur = up[u];
    if (i) cur = max(cur, pref[i - 1]);
    if (i + 1 < sz) cur = max(cur, suf[i + 1]);
    up[v] = cur + 1;
  }
  for (auto v: g[u]) {
    dfs2(v);
  }
}
int mx_d[N];
int32_t main() {
  ios_base::sync_with_stdio(0);
  cin.tie(0);
  int n; cin >> n >> m;
  for (int i = 1; i < n; i++) {
    int u, v; cin >> u >> v;
    g[u].push_back(v);
    g[v].push_back(u);
  }
  dfs(1);
  dfs2(1);
  for (int u = 1; u <= n; u++) {
    vector<int> vec;
    if (u != 1) vec.push_back(up[u]);
    for (auto v: g[u]) {
      vec.push_back(dp[v] + 1);
    }
    sort(vec.rbegin(), vec.rend());
    mx_d[u] = vec[0];
    if (vec.size() > 1) {
      mx_d[u] += vec[1];
    }
    mx_d[u] += 1;
  }
  for (int i = 1; i <= n; i++) {
    cnt[mx_d[i]]++;
    DIAMETER = max(DIAMETER, mx_d[i]);
  }

  init();

  int last_prime = 0;
  for (int i = 2; i <= DIAMETER; i++) {
    if (spf[i] == i) last_prime = i;
    if (cnt[i]) {
      int k = id[last_prime];
      if (!v.empty() and v.back().first == k) {
        v.back().second += cnt[i];
      } else {
        v.push_back({k, cnt[i]});
      }
    }
  }

  if (DIAMETER > 2 * SQRT(m)) solve_large();
  else solve_small();
  return 0;
}
 Amazing problem: 

    


15



 Good problem: 

    


1



 Average problem: 

    


1



 Bad problem: 

    


12



 Didn't solve: 

    


14



 
We can observe that this kind of path is imporatnt — when we are in (x,x)(x,x), we only perform one of the following two kind of moves:Move 1 (x,x)→(x,x+1)→(x+1,x+1)(x,x)→(x,x+1)→(x+1,x+1)This move transforms […,ax,ax+1,…][…,ax,ax+1,…] into […,ax+1,ax,…][…,ax+1,ax,…].Move 2 (x,x)→(x,x+1)→(x,x+2)→(x+1,x+2)→(x+2,x+2)(x,x)→(x,x+1)→(x,x+2)→(x+1,x+2)→(x+2,x+2)This move transforms […,ax,ax+1,ax+2,…][…,ax,ax+1,ax+2,…] into […,ax+2,ax+1,ax,…][…,ax+2,ax+1,ax,…].Summary of the path:Note the arrays before and after the path as aa and a′a′, respectively. We can see a′n=a1an′=a1, and [a′1,…,a′n−1][a1′,…,an−1′] can be obtained from [a2,…,an][a2,…,an] through the following transformation:  Swap any two adjacent numbers of [a2,…,an][a2,…,an], but each number can be swapped at most once. This inspires us to use Odd-Even Sort algorithm.Steps to Achieve the Sorted Array:Step 11: Initialize a1=mna1=mn:  If a1≠mna1≠mn, where mnmn is the minimum of the array, use the following path: (1,1)→(1,p1)→(p1,p1)→(p1,n)→(n,n)(1,1)→(1,p1)→(p1,p1)→(p1,n)→(n,n)This sequence ensures that a1=mna1=mn.Then, repeat steps 22 and 33 until the array is sorted.Step 22: Perform Odd-Even Sorting:  Perform an  Odd-Even Sort (a round of comparison) using the key path above on the subarray a2,…,ana2,…,an.Step 33: Maintain the orderliness of [a2,…,an][a2,…,an] while repeatedly making a1=mna1=mn:  After step 22, we want mnmn back to the head of the array. To achieve this, perform the following operations: (1,1)→(1,n)→(n,n)(1,1)→(1,n)→(n,n)This sequence transforms the array as follows: [a1,a2,…,an(an=mn)]→[a′1,a′2,…,a′n]=[an,an−1,a1,a2,…,an−2][a1,a2,…,an(an=mn)]→[a1′,a2′,…,an′]=[an,an−1,a1,a2,…,an−2]When this is performed after an odd-even sort, it ensures that:  mnmn is back to the head of the array. The subarray a1,…,an−1a1,…,an−1 has been cyclically shifted. Handling Continuous Cyclic Shifts in Odd-Even Sort:  Even Length (n−1n−1 is even):  Cyclic shifting does not affect the odd-even sort. You can continue applying the sort as usual. Odd Length (n−1n−1 is odd):  A small modification is needed. Specifically, First compare (a3,a4),(a5,a6),…(a3,a4),(a5,a6),… instead of (a2,a3),(a4,a5),…(a2,a3),(a4,a5),… This adjustment ensures that the odd-even sort operates correctly despite the continuous cyclic shifts. Overall, we obtained a sorted array using 2n2n walks.
#include <map>
#include <set>
#include <cmath>
#include <ctime>
#include <queue>
#include <stack>
#include <cstdio>
#include <cstdlib>
#include <vector>
#include <cstring>
#include <algorithm>
#include <iostream>
#include <bitset>
using namespace std;
typedef double db;
typedef long long ll;
typedef unsigned long long ull;
const int N=2010;
int T,n,mn,tot;
int a[N];
vector<int> X[N],Y[N];

void path1(int num) //(1,1)->(1,2)->(2,2)->(2,3)->(3,3)->...
{
	for(int i=1;i<=n;i++)
	{
		X[num].push_back(i),Y[num].push_back(i);
		if(i!=n)
		{
			X[num].push_back(i),Y[num].push_back(i+1);
			swap(a[i],a[i+1]);
		}
	}
}

void path2(int num) //(1,1)->(1,n)->(n,n)
{
	for(int i=1;i<=n;i++)
	{
		X[num].push_back(1),Y[num].push_back(i);
		swap(a[1],a[i]);
	}
	for(int i=2;i<=n;i++)
	{
		X[num].push_back(i),Y[num].push_back(n);
		swap(a[i],a[n]);
	}
}

void walk1(int j)
{
	X[tot].push_back(j-1),Y[tot].push_back(j);
	X[tot].push_back(j-1),Y[tot].push_back(j+1);
    X[tot].push_back(j),Y[tot].push_back(j+1);
	X[tot].push_back(j+1),Y[tot].push_back(j+1);
    swap(a[j-1],a[j+1]);
}

void walk2(int j)
{
	X[tot].push_back(j-1),Y[tot].push_back(j);
	X[tot].push_back(j),Y[tot].push_back(j);
	X[tot].push_back(j),Y[tot].push_back(j+1);
	X[tot].push_back(j+1),Y[tot].push_back(j+1);
	swap(a[j-1],a[j]);
	swap(a[j],a[j+1]);
}

int main()
{
	scanf("%d",&T);
	while(T--)
	{
		scanf("%d",&n);
		for(int i=1;i<=n;i++) scanf("%d",&a[i]);
		mn=n;tot=0;
		for(int i=1;i<=n;i++)   mn=min(mn,a[i]);
		for(int i=1;i<=3*n;i++) X[i].clear(),Y[i].clear();
		int p1;
		for(int i=1;i<=n;i++) if(a[i]==mn) p1=i;
		if(p1!=1)
		{
		    tot++;
		    for(int i=1;i<=p1;i++) X[tot].push_back(1),Y[tot].push_back(i),swap(a[1],a[i]);
		    for(int i=2;i<=p1;i++) X[tot].push_back(i),Y[tot].push_back(p1),swap(a[i],a[p1]);
		    for(int i=p1+1;i<=n;i++) X[tot].push_back(p1),Y[tot].push_back(i),swap(a[p1],a[i]);
		    for(int i=p1+1;i<=n;i++) X[tot].push_back(i),Y[tot].push_back(n),swap(a[i],a[n]);
		}
		for(int i=2;i<=n;i++)
		{
			tot++;
			X[tot].push_back(1),Y[tot].push_back(1);
			if(n&1)
			{
				if(i&1)
				{
					for(int j=2;j<=n;j+=2)
					{
						if(j+1==i) walk2(j);
						else if(a[j]>a[j+1]) walk1(j);
						else walk2(j);
					}
				}
				else
				{
					for(int j=2;j<=n;j+=2)
					{
						if(a[j]>a[j+1]) walk1(j);
						else walk2(j);
					}
				}
			}
			else
			{
				if(i&1)
				{
					for(int j=2;j<=n;j+=2)
					{
						if(j==i-1)
						{
							X[tot].push_back(j-1),Y[tot].push_back(j);
							X[tot].push_back(j),Y[tot].push_back(j);
							swap(a[j-1],a[j]);
							j--;
						}
						else if(a[j]>a[j+1]) walk1(j);
						else walk2(j);
					}
				}
				else
				{
					for(int j=2;j<=n;j+=2)
					{
						if(j==i)
						{
							X[tot].push_back(j-1),Y[tot].push_back(j);
							X[tot].push_back(j),Y[tot].push_back(j);
							swap(a[j-1],a[j]);
							j--;
						}
						else if(a[j]>a[j+1]) walk1(j);
						else walk2(j);
					}
				}
			}
			path2(++tot);
		}
		printf("%d\n",tot);
		for(int i=1;i<=tot;i++)
		{
			for(int j=1;j<2*n-1;j++)
			{
			    if(X[i][j]==X[i][j-1]) printf("R");
			    else printf("D");
			}
			printf("\n");
		}

	}

	return 0;
}
 Amazing problem: 

    


13



 Good problem: 

    


0



 Average problem: 

    


1



 Bad problem: 

    


4



 Didn't solve: 

    


15



 
First, read the editorial of the easy version. We can see that the bottleneck lies in the fact that after every round of odd-even sorting, we need to perform a walk operation to ensure that a1=mna1=mn.The following method can break through this bottleneck: for simplicity, let's assume nn is even. Define the numbers smaller than or equal to n2n2 as SS, and the numbers bigger than n2n2 as BB. If we have a=[S,…,S,B,…,B]a=[S,…,S,B,…,B], we can repeatedly perform key path operations to get the following sequence:  [S,…,S,B,…,B]→[S,…,S,B,…,B,S]→[S,…,S,B,…,B,S,S]→…→[B,…,B,S,…,S][S,…,S,B,…,B]→[S,…,S,B,…,B,S]→[S,…,S,B,…,B,S,S]→…→[B,…,B,S,…,S]  In this process, we only perform odd-even sorting for the subarray [B,…,B][B,…,B]. [B,…,B,S,…,S]→[B,…,B,S,…,S,B]→[B,…,B,S,…,B,B]→…→[S,…,S,B,…,B][B,…,B,S,…,S]→[B,…,B,S,…,S,B]→[B,…,B,S,…,B,B]→…→[S,…,S,B,…,B]  In this process, we only perform odd-even sorting for the subarray [S,…,S][S,…,S]. After that, the array is sorted.Finally, the only remaining problem is how to arrange a=[S,…,S,B,…,B]a=[S,…,S,B,…,B].Assume we have kk positions p1,p2,…,pkp1,p2,…,pk such that 1<p1<p2<…<pk≤n1<p1<p2<…<pk≤n. Consider what the following operations are doing:(1,1)→(1,p1)→(2,p1)→(2,p2)→(3,p2)→…→(k,pk)(1,1)→(1,p1)→(2,p1)→(2,p2)→(3,p2)→…→(k,pk)If we ignore the other numbers，these operations correspond to:swap(a1,ap1),swap(a2,ap2),…swap(a1,ap1),swap(a2,ap2),…Then, we can take any path from (k,pk)(k,pk) to (n,n)(n,n).At first, we perform one operation to set a1=na1=n, then choose n2n2 positions p1,p2,…,pn2p1,p2,…,pn2 to obtain a=[S,…,S,B,…,B]a=[S,…,S,B,…,B].For nn being odd, we need two additional operations for some little adjustments.Overall, we obtained a sorted array using n+4n+4 walks.
#include <map>
#include <set>
#include <cmath>
#include <ctime>
#include <queue>
#include <stack>
#include <cstdio>
#include <cstdlib>
#include <vector>
#include <cstring>
#include <algorithm>
#include <iostream>
#include <bitset>
using namespace std;
typedef double db;
typedef long long ll;
typedef unsigned long long ull;
const int N=2010;
int T,n,tot;
int a[N];
vector<int> X[N],Y[N];

void path1(int num)  //(1,1)->(1,2)->(2,2)->(2,3)->(3,3)->...
{
	for(int i=1;i<=n;i++)
	{
		X[num].push_back(i),Y[num].push_back(i);
		if(i!=n)
		{
			X[num].push_back(i),Y[num].push_back(i+1);
			swap(a[i],a[i+1]);
		}
	}
}

void path2(int num) //(1,1)->(1,n)->(n,n)
{
	for(int i=1;i<=n;i++)
	{
		X[num].push_back(1),Y[num].push_back(i);
		swap(a[1],a[i]);
	}
	for(int i=2;i<=n;i++)
	{
		X[num].push_back(i),Y[num].push_back(n);
		swap(a[i],a[n]);
	}
}

void path3(int num,vector<int> p) //swap(1,p[0]),(2,p[1]),... note p[0]!=1
{
	for(int i=1;i<=p[0];i++)
	{
		X[num].push_back(1),Y[num].push_back(i);
		swap(a[1],a[i]);
	}
	for(int i=1;i<p.size();i++)
	{
		for(int j=p[i-1];j<=p[i];j++)
		{
			X[num].push_back(i+1),Y[num].push_back(j);
		    swap(a[i+1],a[j]);
		}
	}
	int x=p.size(),y=p.back();
	while(x!=n)
	{
	    x++;
	    X[num].push_back(x),Y[num].push_back(y);
		swap(a[x],a[y]);
	}
	while(y!=n)
	{
	    y++;
	    X[num].push_back(x),Y[num].push_back(y);
		swap(a[x],a[y]);
	}
}

void walk1(int j)
{
	X[tot].push_back(j-1),Y[tot].push_back(j);
	X[tot].push_back(j-1),Y[tot].push_back(j+1);
    X[tot].push_back(j),Y[tot].push_back(j+1);
	X[tot].push_back(j+1),Y[tot].push_back(j+1);
    swap(a[j-1],a[j+1]);
}

void walk2(int j)
{
	X[tot].push_back(j-1),Y[tot].push_back(j);
	X[tot].push_back(j),Y[tot].push_back(j);
	X[tot].push_back(j),Y[tot].push_back(j+1);
	X[tot].push_back(j+1),Y[tot].push_back(j+1);
	swap(a[j-1],a[j]);
	swap(a[j],a[j+1]);
}

void walk3(int j)
{
	X[tot].push_back(j-1),Y[tot].push_back(j);
	X[tot].push_back(j),Y[tot].push_back(j);
	swap(a[j-1],a[j]);
}

void init()
{
	scanf("%d",&n);
	for(int i=1;i<=n;i++) scanf("%d",&a[i]);
	tot=0;
	for(int i=1;i<=3*n;i++) X[i].clear(),Y[i].clear();
	vector<pair<int,int> > pr;
	for(int i=1;i<=n;i++) pr.push_back(make_pair(a[i],i));
	sort(pr.begin(),pr.end());
	for(int i=1;i<=n;i++) a[pr[i-1].second]=i;
}

void step1()
{
	int p1,pn;
	vector<int> p;
	for(int i=1;i<=n;i++) if(a[i]==1) p1=i;
	if(p1!=1)
	{
        p.push_back(p1);
        path3(++tot,p);
	}
	if(n==2) return ;
	tot++;
	X[tot].push_back(1),Y[tot].push_back(1);
	for(int j=2;j<=n;j+=2)
	{
	    if(j+1>n) walk3(j);
	    else if(a[j]==n) walk1(j);
		else walk2(j);
	}
	p1=n;
	for(int i=1;i<=n;i++) if(a[i]==n) pn=i;
    p.clear();
    p.push_back(pn);p.push_back(p1);
    path3(++tot,p);
    p.clear();
    for(int i=1;i<=n;i++) if(a[i]<=(n+1)/2) p.push_back(i);
    path3(++tot,p);
}

void step2()
{
	int head;
	if(n&1)
	{
	    for(int t=1;t<=2;t++)
		{
            head=n/2+2;
            for(int i=1;i<=n/2+(t==1);i++)
            {
                tot++;
                X[tot].push_back(1),Y[tot].push_back(1);
                for(int j=2;j<=n;j++)
                {
                    if(!(head<=j&&j<=head+n/2-1)) walk3(j);
                    else if(j==head&&(head&1)) walk3(j);
                    else
                    {
                        if(!(head<=j+1&&j+1<=head+n/2-1)) walk3(j);
                        else if(a[j]>a[j+1]) walk1(j),j++;
                        else walk2(j),j++;
                    }
                }
                head--;
            }
		}
	}
	else
	{
		for(int t=1;t<=2;t++)
		{
            head=n/2+1;
            for(int i=1;i<=n/2;i++)
            {
                tot++;
                X[tot].push_back(1),Y[tot].push_back(1);
                for(int j=2;j<=n;j++)
                {
                    if(!(head<=j&&j<=head+n/2-1)) walk3(j);
                    else if(j==head&&(head&1)) walk3(j);
                    else
                    {
                        if(!(head<=j+1&&j+1<=head+n/2-1)) walk3(j);
                        else if(a[j]>a[j+1]) walk1(j),j++;
                        else walk2(j),j++;
                    }
                }
                head--;
            }
		}
	}
}

void output()
{
	printf("%d\n",tot);
	for(int i=1;i<=tot;i++)
	{
		for(int j=1;j<2*n-1;j++)
		{
		    if(X[i][j]==X[i][j-1]) printf("R");
		    else printf("D");
		}
		printf("\n");
	}
}

int main()
{
	scanf("%d",&T);
	while(T--)
	{
		init();
		step1();
		step2();
		output();
	}

	return 0;
}

 Amazing problem: 

    


12



 Good problem: 

    


1



 Average problem: 

    


0



 Bad problem: 

    


4



 Didn't solve: 

    


21



 
// this is code

int main() {
fastio();
int tc;cin>>tc;

while(tc--){
 int n,m;cin>>n>>m;
 vector<int> a(m);
 for(int i=0;i<m;i++)cin>>a[i];

 sort(a.begin(),a.end(),greater<int>());
 vector<int> fa(n+1);
 vector<int> t(n+1);int flag=1;
 for(int i=1;i<=n;i++){
    if(i==1){fa[i]=a[0];t[i]=0;}
    else{
        //find all factors of this
        vector<int> f;
        f.push_back(1);
        for(int x=2;x*x<=i;x++){
            if(i%x==0){
                f.push_back(x);
                if(x*x!=i){
                    fa.push_back(i/x);
                }
            }
        }

        int mx=0;
        for(auto it:f){
            mx=max(mx,t[it]);
        }

    mx++;
    if(mx>=m){
        flag=0;break;
    }
    else{
        fa[i]=a[mx];
        t[i]=mx;
    }
    }
 }
 if(!flag)cout<<-1<<endl;
 else{
    for(int i=1;i<=n;i++)cout<<fa[i]<<" ";
    cout<<endl;
 }
  }
}


[Editorial - contest/2038]
No editorial content found.


[Editorial - contest/2037]









[Editorial - contest/2031]
The Highschool CPers (HSCP) Discord server was created in April 2022 by pwned, which over time grew into a close-knit community of highschool competitive programmers. I joined in the same month of its creation, and in the next month I approached pwned about the possibility of setting a contest. Thus the HSCP round concept was born.Over the next month or so, the initial problems were born; the current problems A and F were produced in June-July 2022. We had several problem ideas by then, enough to set a div.2 round. However, as I was going to be busy in my 5th year of high school, and may not be that responsive to coordinators, the contest was in the ownership of pwned, who needed to wait until he reached master in order to propose the set on Codeforces.However, this step took almost 1.5 years as he would stay at candidate master for 57 consecutive contests, even hitting 2099 rating. Eventually, in January 2024, pwned finally reached master and submitted the round, and in May, the round began to be reviewed by our dear coordinator maomao90.It took 3 months (totally not procrastinating) to prepare all the problems, and testing commenced in August. However, the difficulty gap between problems quickly became apparent. The original problems A, C, E became the current A, D, F, and three new problems (for B, C, and E) had to be devised. Therefore, I started coming up with problems in the dead of night, hoping to finish the contest as soon as possible.Eventually, in October, all the gaps were filled, and thus the current problem set was born.Originally, I wanted to theme this round based on the game Hatsune Miku: Colorful Stage!, and in particular the current problem E was inspired by the song Hatsune Creation Myth by cosMo@Bousou-P. Go give it a listen!Ultimately, less than a week before the round, we chose to settle on a "geographical" theme, since the authors of this contest hail from different nations. We also chose Penchick, a traveling penguin chick, as the main character, but we kept a essence of the game Hatsune Miku: Colorful Stage!: Kohane (Azusawa Kohane, appearing in problem B and C) is one of the game characters, and was featured on one of my early profile pictures (before I even started playing the game). Nowadays, Kohane has been immortalized in the HSCP server as an "anime character", receiving a dedicated emoji :kohane:. 
Consider the maximum number of pillars that can be left untouched instead.
Under what conditions can k>1k>1 pillars be untouched?
Note that if pillars ii and jj with different heights are both untouched, then the first pillar must be taller than the second, which contradicts the fact that the heights must be non-decreasing after the adjustment. Thus, all unadjusted pillars must be of the same height.Therefore, the required number of pillars to adjust is n−kn−k, where kk is the maximum number of pillars with the same height hh. This bound is reachable by, for example, adjusting all pillars to height hh.To find kk, we can go through each index ii and find the number of pillars with the same height as ii; this gives O(n2)O(n2) time complexity, which is good enough for this problem. Alternatively, you can use a frequency array or std::map, or sequentially go through the list and find the longest sequence of equal terms, all of which have better time complexities.Implementation: O(n2)O(n2): (by ACGN) 291675590 Frequency array: (by pavement) 291676291 Map: (by newb_programmer) 291676566 Sequential approach: (by AlperenT) 291676646
 Good problem: 




279





 Okay problem: 

    


72



 Bad problem: 

    


55



 Did not attempt: 

    


1



 
Consider which permutations you can get by reversing the operations and starting from the identity permutation
After pipi and pi+1pi+1 have been swapped, i.e. pi=i+1pi=i+1 and pi+1=ipi+1=i, neither of them can then be involved in another different swap.
Suppose we begin with the identity permutation. Consider what happens after swapping pi=ipi=i and pi+1=i+1pi+1=i+1. After this swap, elements p1p1 to pi−1pi−1 will consist of 11 to i−1i−1, and pi+2pi+2 to pnpn will consist of i+2i+2 to nn. Thus, it is impossible for pi=i+1pi=i+1 to swap with pi−1<ipi−1<i, or for pi+1=ipi+1=i to swap with pi+2>i+1pi+2>i+1.Therefore, the swaps made must be independent of each other; in other words, the indices ii chosen in the process must differ from each other than at least 22. These permutations satisfy the following: for each index ii,  pi=ipi=i, or pi=i+1pi=i+1 and pi+1=ipi+1=i, or pi=i−1pi=i−1 and pi−1=ipi−1=i. One way to check for this is to iterate for ii from 11 to nn. If pi=ipi=i then continue, and if pi=i+1pi=i+1 then check if pi+1=ipi+1=i, then swap pipi and pi+1pi+1. Otherwise, the permutation cannot be sorted.Time complexity: O(n)O(n)Implementation: (by AlperenT) 291676758
 Good problem: 

    


307



 Okay problem: 

    


70



 Bad problem: 

    


35



 Did not attempt: 

    


7



 
Solve the problem for n=2n=2 and for even nn in general.
For odd nn, there exists a color that appears at least thrice. What does this mean?
Note that 11 is a square number; thus, for even nn, the construction 1 1 2 2 3 3…n2 n21 1 2 2 3 3…n2 n2 works. For odd nn, note that there exists a color that appears at least thrice, say at positions x<y<zx<y<z. Then y−xy−x, z−yz−y and z−xz−x are all square numbers. Note that z−x=(z−y)+(y−x)z−x=(z−y)+(y−x), which has the smallest solution being z−x=52=25z−x=52=25, and z−y,y−x=9,16z−y,y−x=9,16. Therefore, there is no solution if n≤25n≤25. We devise a solution for n=27n=27. By the above, we have the following posts filled in:1 (8 blanks) 1 (15 blanks) 1 –1 (8 blanks) 1 (15 blanks) 1 _We can use the same color for positions 1111 and 2727, to obtain the following:1 (8 blanks) 1 2 (14 blanks) 1 21 (8 blanks) 1 2 (14 blanks) 1 2The remaining even-length blanks can be filled in similar to above. The result is as follows and can be hard-coded:1 3 3 4 4 5 5 6 6 1 2 7 7 8 8 9 9 10 10 11 11 12 12 13 13 1 21 3 3 4 4 5 5 6 6 1 2 7 7 8 8 9 9 10 10 11 11 12 12 13 13 1 2Then, for odd n≥27n≥27, add n−272n−272 pairs with distance 11 to complete the construction.Note that there are different ways to construct this starting array for n=27n=27 as well.Time complexity: O(n)O(n)Implementation: (by ACGN) 291676952
 Good problem: 

    


529



 Okay problem: 

    


65



 Bad problem: 

    


297



 Did not attempt: 

    


12



 
Suppose that you have found the maximum height reachable from tree i+1i+1. How do you find the maximum height reachable from tree ii?
Let pp be the highest height among trees indexed from 11 to ii, and ss be the lowest height among trees indexed from i+1i+1 to nn. When can tree ii be reachable from tree i+1i+1? 
First, observe that a rabbit at tree nn can reach the highest tree; if the tree has index i<ni<n, then the rabbit can jump from tree nn to ii. Let anskansk denote the tallest height reachable from tree kk, then ansn=max(a1,a2,…an)ansn=max(a1,a2,…an).We iteratively look at trees n−1n−1 to 11. Suppose we have found the tallest height ansi+1ansi+1 reachable from tree i+1i+1. Note that from tree ii we can reach the tallest tree with index between 11 and ii, and from tree i+1i+1 we can reach the shortest tree with index between i+1i+1 and nn. Let ax=pi=max(a1,a2,…ai)ax=pi=max(a1,a2,…ai) and ay=si=min(ai+1,ai+1,…an)ay=si=min(ai+1,ai+1,…an). Then if pi>sipi>si then tree i+1i+1 is reachable from tree ii by the sequence i↔x↔y↔i+1i↔x↔y↔i+1. Thus, any tree reachable from tree ii is reachable from tree i+1i+1, and vice versa; thus, ansi=ansi+1.ansi=ansi+1.On the other hand, if pi≤sipi≤si, then for any r≤ir≤i and s≥i+1s≥i+1, we have r<sr<s and ar≤pi≤si≤asar≤pi≤si≤as. Thus, no tree between index i+1i+1 and nn inclusive is reachable from any tree from 11 and ii inclusive. Similar to the first paragraph, we have ansi=max(a1,a2,…ai)=piansi=max(a1,a2,…ai)=pi.Time complexity: O(n)O(n)Implementation: (by ACGN) 291677082
 Good problem: 

    


506



 Okay problem: 

    


36



 Bad problem: 

    


42



 Did not attempt: 

    


30



 
Consider the tree where root 11 has kk children which are all leaves. What is its minimum depth?
Consider undoing the operations from the given tree back to the perfect binary tree. Where can each child of the tree go? 
As in Hint 2, suppose that there exists a finite sequence of operations that convert a perfect binary tree TdTd of depth dd to our target tree TT. We consider where each child of vertex 11 in TT is mapped to the binary tree; specifically, for each such child cc, let c′c′ be the highest vertex in TdTd that maps to cc under the operations. Then we can see that the subtree rooted at c′c′ in TdTd maps to the subtree rooted at cc in TT.Suppose that the minimum depth required for the subtree rooted at cc in TT is dcdc. Claim 1: 2d≥∑c2dc2d≥∑c2dc, where the sum is taken across all children cc of 11. ProofNote that no two of the vcvc are ancestors or descendants of each other; otherwise, if vc1vc1 is an ancestor of vc2vc2, then c1c1 would be an ancestor of c2c2.Consider the 2d2d leaves of TdTd. Of them, for each cc, 2dc2dc of them are descendants of vcvc. As no leaf can be descendants of two vcvc's, the inequality follows.Claim 2: If 11 has only one child cc, then d=dc+1d=dc+1; otherwise, dd is the least integer that satisfies the inequality of Claim 1. ProofSuppose 11 only has one child cc. Then d≤dcd≤dc clearly does not suffice, but d=dc+1d=dc+1 does as we can merge the entire right subtree into the root 11.Suppose now that 11 has multiple children c1,c2,…ckc1,c2,…ck, sorted by descending dcdc. For each child cici from c1c1 to ckck, allocate vcivci to be the leftmost possible vertex at a height of dcidci. Then the leaves that are ancestors of cici form a contiguous segment, so this construction ensures that each child cici can be placed on the tree.Thus, we can apply tree dp with the transition function from dcidci to dd described by Claim 2. However, naively implementing it has a worst-case time complexity of O(n2).O(n2). Example of worst-case time complexityConsider a tree constructed this way: 22 and 33 are children of 11, 44 and 55 are children of 33, 66 and 77 are children of 55, and so on; the odd-numbered vertices form a chain with the even-numbered vertices being leaves. In such a graph, the depth dd is the length of the odd-numbered chain. Thus, during the computation of dd, we would have to evaluate 2x+12x+1 for xx from 11 to d≈n2.d≈n2. However, evaluating 2x+12x+1 naively requires at least O(x)O(x) time, so the algorithm runs in O(n2)O(n2).There are several ways to improve the time complexity of the dp transition.For example, sort dcidci in increasing order, then maintain the sum as a×2ba×2b, where initially a=b=0a=b=0. For each cici in order, replace aa by ⌈a2dci−b⌉⌈a2dci−b⌉ and replace bb by dcidci, which essentially serves to round up the sum to the nearest 2dci2dci. Then, increment aa to add 2dci2dci to the sum. At the end of these operations, we have d=⌈log2a⌉+bd=⌈log2⁡a⌉+b.Implementation: (by ACGN) 291677229Another way to do so is to "merge" terms from smallest to largest; importantly, since we just need to crudely bound S=∑c2dcS=∑c2dc, we can replace 2x+2y2x+2y by 2max(x,y)+12max(x,y)+1. Then we can repeat this process until only one element remains. Why does this work?Suppose that x>yx>y. Then the above operation rounds up SS to the nearest 2x2x. Since 2d≥S>2x2d≥S>2x, rounding up SS will not cause it to exceed the next power of 22, so 2d≥S2d≥S remains true after the operation.Implementation: (by Dominater069) 291677365Both transitions work in O(klogk)O(klog⁡k), leading to an overall time complexity of O(nlogn)O(nlog⁡n).UPD: Thanks to sleepyessheep for an O(n)O(n) solution, refer to this thread. Thanks!!
Note that no two of the vcvc are ancestors or descendants of each other; otherwise, if vc1vc1 is an ancestor of vc2vc2, then c1c1 would be an ancestor of c2c2.Consider the 2d2d leaves of TdTd. Of them, for each cc, 2dc2dc of them are descendants of vcvc. As no leaf can be descendants of two vcvc's, the inequality follows.
Suppose 11 only has one child cc. Then d≤dcd≤dc clearly does not suffice, but d=dc+1d=dc+1 does as we can merge the entire right subtree into the root 11.Suppose now that 11 has multiple children c1,c2,…ckc1,c2,…ck, sorted by descending dcdc. For each child cici from c1c1 to ckck, allocate vcivci to be the leftmost possible vertex at a height of dcidci. Then the leaves that are ancestors of cici form a contiguous segment, so this construction ensures that each child cici can be placed on the tree.
Consider a tree constructed this way: 22 and 33 are children of 11, 44 and 55 are children of 33, 66 and 77 are children of 55, and so on; the odd-numbered vertices form a chain with the even-numbered vertices being leaves. In such a graph, the depth dd is the length of the odd-numbered chain. Thus, during the computation of dd, we would have to evaluate 2x+12x+1 for xx from 11 to d≈n2.d≈n2. However, evaluating 2x+12x+1 naively requires at least O(x)O(x) time, so the algorithm runs in O(n2)O(n2).
Suppose that x>yx>y. Then the above operation rounds up SS to the nearest 2x2x. Since 2d≥S>2x2d≥S>2x, rounding up SS will not cause it to exceed the next power of 22, so 2d≥S2d≥S remains true after the operation.
The idea of the problem came from thinking about the "creation of the world" while vibing to Hatsune Creation Myth; in particular, our rooted tree is the "world" now, and the binary tree was the "original world" yet to be refined by compressing its edges.The problem came to life during a break in my lecture, when I was experimenting with "creating" a tree. Hope you liked it!
 Good problem: 

    


166



 Okay problem: 

    


10



 Bad problem: 

    


15



 Did not attempt: 

    


28



 
Querying n−2n−2 elements is very powerful.
Try to find two indices xx and yy such that one of px,pypx,py is strictly smaller than n2n2 and the other is strictly greater than n2+1n2+1. What can you do after finding these two elements?
This solution is non-deterministic and uses n2+O(1)n2+O(1) queriesPart 1Suppose we select all elements except for two indices 1≤i,j≤n1≤i,j≤n to be used in the query. Let the result we receive be (a,b)(a,b) where a<ba<b. If a=n2a=n2 and b=n2+1b=n2+1, it means that one of pi,pjpi,pj is strictly smaller than n2n2 and the other is strictly larger than n2n2.If we do the above query randomly, there is around 50%50% chance of getting the above outcome. So we can just randomly select two indices to exclude from the query until we get the above result.Part 2Now that we have two elements xx and yy such that one of px,pypx,py is strictly smaller than n2n2 and the other is strictly greater than n2+1n2+1, we can query [x,y,i,j][x,y,i,j]. The median of [px,py,pi,pj][px,py,pi,pj] will include n2n2 if and only if one of pi,pjpi,pj is equal to n2n2. The same is true for n2+1n2+1. We can iterate through all n2−1n2−1 pairs to find the two pairs that contain the median, then iterate through all (42)(42) combinations of median to find the answer.Implementation: (by ACGN) 291677579
This solution is deterministic and uses 3n43n4 queriesTo make the solution deterministic, we need to find a deterministic solution to Part 1. Part 2 is already deterministic so we can just use the same solution.Let us analyse all the possible cases if we select all elements except for two indices 1≤i,j≤n1≤i,j≤n to be used in the query. Let the result we receive be (a,b)(a,b) where a<ba<b.  a=n2a=n2 and b=n2+1b=n2+1. In this case, one of pi,pjpi,pj is strictly smaller than n2n2 and the other is strictly larger than n2n2, which is exactly what we wanted to find. a=n2a=n2 and b=n2+2b=n2+2. In this case, one of pi,pjpi,pj is strictly smaller than n2n2 and the other is equal to n2+1n2+1. a=n2−1a=n2−1 and b=n2+1b=n2+1. In this case, one of pi,pjpi,pj is strictly larger than n2+1n2+1 and the other is equal to n2n2. a=n2−1a=n2−1 and b=n2b=n2. In this case, both of pi,pjpi,pj are larger than or equal to n2+1n2+1. a=n2+1a=n2+1 and b=n2+2b=n2+2. In this case, both pi,pjpi,pj are smaller than or equal to n2n2. a=n2−1a=n2−1 and b=n2+2b=n2+2. In this case, pipi and pjpj are the two medians. \end{enumerate} If we have two queries such that one query is type 4 and another is type 5, then we can use one element from each pair to form the desired xx and yy. We have to use one additional query to make sure that the chosen elements are not part of the median. We will only ask at most n4n4 queries before there is at least one query of type 4 and one query of type 5. Types 2 and 3 can be treated together with types 4 and 5 with some careful handling. Implementation: (by ACGN) 291677671
This solution is deterministic and uses n2+log2nn2+log2⁡n queries. Special thanks to SHZhang for discovering this solution.Call the elements of the permutation less than or equal to n2n2 lower elements, and call the rest upper elements. Pair up the permutation's elements (we can just pair index 1 with index 2, index 3 with index 4, and so on). Do n2n2 queries where the ii-th query consists of all elements except those in the ii-th pair. This lets us determine whether (1) both elements in the pair are lower elements, (2) both are upper elements, or (3) there is one lower and one upper element in the pair. In case (3), we can also tell if the pair contains one or both of the desired medians (Take a look at solution 2 for a more in-depth case analysis).Our goal now is to identify the pairs that the lower and upper medians belong to. It suffices to be able to find them from the pairs of type (1) and (2), since we have already found the ones in type (3) pairs. This can be done with binary search on the type (1) and (2) pairs, by balancing the number of pairs of both types and checking if the median is in the result (The two binary searches can be performed simultaneously). This is similar to Part 2 of solution 1, but instead of just using 44 elements, we can generalise to use more elements if there is an equal number of lower and upper elements.After figuring out which pair each median is in, there are four possibilities remaining for the answer. For each one, make a query consisting of all the elements but the two candidates for the two medians that we are checking. When we see (n2−1,n2+2)(n2−1,n2+2) as the response, we know we found the answer.Implementation: (by SHZhang) 291677713
Code an adaptive grader that can kill the following solution: Use the same solution as "Solution 1". However, before the start of the actual algorithm, ask a few (around 10) random queries.This problem originally used an adaptive grader, but I didn't know how to kill the above scam as the random queries added too much restriction to the permutation that I can no longer force the randomised solution to use more queries.I think you will probably need to solve the following problem in polynomial time in order to kill the solution: Determine whether there exists a permutation that satisfies all the given queries and results so far.
 Good problem: 

    


63



 Okay problem: 

    


6



 Bad problem: 

    


7



 Did not attempt: 

    


57



 
Note that all of these have been written before the contest.When I reached master in 2022, I had a bunch of problem ideas that I compiled as unpublished problem proposals — around 30 of them. I looked through my old proposals — problems written by me 2 years ago.After 2 years of essentially quitting CP, and focusing on studies and math, I concluded that a lot of them were... garbage, or what might be most aptly described as "uninsightful mashups of number theory with random stuff".Yet more of them were too straightforward applications or "routine problems", and simply didn't feel interesting enough to me. Again, I'm on my own.Over the course of these 2 years, I've been a bit more strict with myself in terms of problem ideas. To create a good problemset requires a lot of time, effort, energy, possibly coffee. And still, the problemset might not be good enough.Throughout problemsetting, I've always had the concern of the round potentially being "mathforces". In particular, after I set a math-related problem C, my choices were B were limited. It's not easy to balance problem types, especially when I tend to lean towards math problems.Before the review process started, I was hoping for this contest to have the most ideal, interesting problems — just as every problemsetter would. However, issues happen in testing, and the final problemset wasn't exactly what I hoped for. While I still hope you all enjoyed the contest thoroughly, I've learnt just how difficult coming up with a round is — not only does a problem have to get through coordinators, it also can't create a too large or small difficulty gap — it's a very delicate balance.So, thank you to everyone on this 2-year journey towards creating these problems, and we hope you enjoyed the culmination of our efforts.- ACGN
the 3ish years of my CP journey has been nothing but fun. From making it to the IOI within my first year, to meeting amazing people online and getting to know (part of) the community, it has been an amazing ride with all of you. Even as I continue to study medicine and embark on another journey, I will never forget the thrills of coming up with an idea to solve a problem, debugging the code for literally days, frantically reloading the judge for a verdict, and seeing the green sacred "Accepted" texts. Now that this might very well be my formal retirement, I don't know if I'll come back to bring more joy (and problems) to the CF community. I sure have some treats left in store, but it's perhaps time to cherish the memories I've made with all of you: doing surprisingly well in Codeton 1, "grinding" math 3500s and such for fun, to ACing IOI22-circuit to save a bronze medal, solving difficult problems have always been extremely stimulating, thrilling, and exciting for me. That's why I've had so much fun in the CP world, even though I've only been here for a short time, and still don't really know how to code DFS. So, thank you to everyone on this journey, and I wish you all peace.
#pragma GCC optimize("Ofast,unroll-loops")
#pragma GCC target("avx,avx2,fma")

#include <bits/stdc++.h>
#include <ext/pb_ds/assoc_container.hpp>
#include <ext/pb_ds/tree_policy.hpp>
using namespace std;
using namespace __gnu_pbds;

typedef tree<int, null_type, less<int>, rb_tree_tag, tree_order_statistics_node_update> ordered_set;
mt19937 rng(chrono::steady_clock::now().time_since_epoch().count());

const int MAX = 1e6 + 2;
int n;
vector<int> a[MAX];

int dfs(int x) {
    if (int(a[x].size()) == 0) return 0;
    priority_queue<int, vector<int>, greater<int>> pq;
    for (auto i : a[x]) pq.push(dfs(i));
    for (int i = 1; i <= int(a[x].size()) - 2; i++) {
        int x = pq.top();
        pq.pop();
        int y = pq.top();
        pq.pop();
        x++; y++;
        pq.push(x); pq.push(y);
    }
    while (int(pq.size()) > 1) pq.pop();
    return pq.top() + 1;
}

void solve() {
    cin >> n;
    for (int i = 1; i <= n; i++) a[i].clear();
    for (int i = 2; i <= n; i++) {
        int p;
        cin >> p;
        a[p].push_back(i);
    }
    cout << dfs(1) << "\n";
}

int main() {
    ios_base::sync_with_stdio(false);
    cin.tie(nullptr);
    int t;
    cin >> t;
    while (t--) solve();
}


[Editorial - contest/2028]
How many times do you have to repeat the string until you know for certain whether Alice will ever reach the Red Queen?
2028A - Alice's Adventures in ''Chess''We can run the whole pattern 100≫max(a,b,n)100≫max(a,b,n) times, which gives a total runtime of O(100tn)O(100tn) (be careful in that running the pattern only 10 times is not enough!)To prove that 100100 repeats suffices, suppose that Alice's steps on the first run of the pattern are (0,0),(x1,y1),(x2,y2),…,(xn,yn)(0,0),(x1,y1),(x2,y2),…,(xn,yn) (we will take x0=0,y0=0x0=0,y0=0 for convenience) Then, Alice ends up at position (a,b)(a,b) if there exists a t≥0t≥0 (the number of extra repeats) such that for some ii, xi+txn=axi+txn=a and yi+tyn=byi+tyn=b. Certainly, if xn=yn=0xn=yn=0, we only need one repeat so assume WLOG that xn≠0xn≠0. Then, it must be the case that t=a−xixnt=a−xixn. However, a−xi≤20a−xi≤20 (since xi≥−10xi≥−10) and |xn|≥1|xn|≥1, so t≤20t≤20 and therefore 2121 repeats always suffice.In fact, the above proof shows that we can solve each testcase in time O(n)O(n).
def solve():
    [n, a, b] = list(map(int, input().split()))
    s = str(input())
    x, y = 0, 0
    for __ in range(100):
        for c in s:
            if c == 'N':
                y += 1
            elif c == 'E':
                x += 1
            elif c == 'S':
                y -= 1
            else:
                x -= 1
            if x == a and y == b:
                print("YES")
                return
    print("NO")
 
t = int(input())
 
for _ in range(t):
    solve()
Do casework on whether b=0b=0 or not.
2028B - Alice's Adventures in PermutingSuppose that b=0b=0. Then, if c≥nc≥n, the answer is nn; if c=n−1c=n−1 or c=n−2c=n−2, the answer is n−1n−1; and otherwise, it is −1−1 (for example, consider c=n−3c=n−3, in which case we will end up with a=[0,1,…,n−4,n−3,n−3,n−3]→[0,1,…,n−4,n−3,n−3,n−2]→[0,1,…,n−4,n−3,n−3,n−1]a=[0,1,…,n−4,n−3,n−3,n−3]→[0,1,…,n−4,n−3,n−3,n−2]→[0,1,…,n−4,n−3,n−3,n−1] and the last two steps alternate)Otherwise, since aa has distinct elements, we claim that the answer is n−mn−m, where mm is the number of elements in 0,1,…,n−10,1,…,n−1 already present in the array. Equivalently, it is the number of steps until max(a)<nmax(a)<n since we always preserve the distinctness of the elements of aa.So, we want to find the maximum ii such that ai<nai<n. This happens exactly when i<n−cbi<n−cb. The expected complexity is O(1)O(1) per testcase.
#include <bits/stdc++.h>
using namespace std;
 
using ll = long long;
using ld = long double;
using pii = pair<int, int>;
using vi = vector<int>;
#define rep(i, a, b) for(int i = a; i < (b); ++i)
#define all(x) (x).begin(), (x).end()
#define sz(x) (int)(x).size()
#define smx(a, b) a = max(a, b)
#define smn(a, b) a = min(a, b)
#define pb push_back
#define endl '\n'
 
const ll MOD = 1e9 + 7;
const ld EPS = 1e-9;
 
mt19937 rng(time(0));
 
int main() {
	cin.tie(0)->sync_with_stdio(0);
 
	int t; cin >> t;
	while (t--) {
		ll n, b, c; cin >> n >> b >> c;
		if (b == 0) {
			if (c >= n) {
				cout << n << "\n";
			} else if (c >= n - 2) {
				cout << n - 1 << "\n";
			} else {
				cout << -1 << "\n";
			}
		} else {
		    if (c >= n) cout << n << "\n";
			else cout << n - max(0ll, 1 + (n - c - 1) / b) << "\n";
		}
	}
}
How can you quickly determine if Alice can ever receive the piece a[i:j]=[ai,ai+1,…,aj−1]a[i:j]=[ai,ai+1,…,aj−1]? 
For a given ii, how can you quickly check the maximum jj such that Alice can receive the piece a[i:j]a[i:j]?
2028C - Alice's Adventures in Cutting CakeAlice's piece of cake will be some subsegment a[i:j]a[i:j]. For a fixed ii, how large can jj be? To determine this, let pfx[i]pfx[i] be the maximum number of creatures that can be fed on a[:i]a[:i] and sfx[j]sfx[j] the maximum number of creatures on a[j:]a[j:]. Then, for a given ii, the maximum possible jj is exactly the largest jj such that pfx[i]+sfx[j]≥mpfx[i]+sfx[j]≥m. If we compute the pfxpfx and sfxsfx arrays, we can then compute these largest jj for all ii with two pointers in O(n)O(n) (or with binary search in O(nlogn)O(nlog⁡n), since sfxsfx is monotonically non-increasing).To compute pfx[i]pfx[i], we can use prefix sums and binary search to find the maximum k<ik<i such that ∑iℓ=ka[ℓ]≥v∑ℓ=kia[ℓ]≥v: then pfx[i]=1+pfx[k]pfx[i]=1+pfx[k]. We can compute sfxsfx similarly by reversing aa. This takes time O(nlogn)O(nlog⁡n) (it is also possible to do this with two pointers in O(n)O(n), which you can see in the model solution).Expected complexity: O(n)O(n) or O(nlogn)O(nlog⁡n).
#include <bits/stdc++.h>
using namespace std;
 
using ll = long long;
using ld = long double;
using pii = pair<int, int>;
using vi = vector<int>;
#define rep(i, a, b) for(int i = a; i < (b); ++i)
#define all(x) (x).begin(), (x).end()
#define sz(x) (int)(x).size()
#define smx(a, b) a = max(a, b)
#define smn(a, b) a = min(a, b)
#define pb push_back
#define endl '\n'
 
const ll MOD = 1e9 + 7;
const ld EPS = 1e-9;
 
mt19937 rng(time(0));
 
int main() {
	cin.tie(0)->sync_with_stdio(0);
 
	int t; cin >> t;
	while (t--) {
		int n, m; cin >> n >> m;
		ll v; cin >> v;
		vector<ll> a(n);
		rep(i,0,n) cin >> a[i];
 
		vector<ll> sums(n + 1);
		rep(i,0,n) sums[i + 1] = sums[i] + a[i];
 
		auto query = [&](int i, int j) { // [i, j)
			return sums[j] - sums[i];
		};
 
		auto compute_pfx = [&]() -> vector<int> {
			vector<int> pfx(n + 1, 0);
			int end = 0, val = 0;
			ll sum = 0;
			for (int start = 0; start < n; start++) {
				while (end < n && sum < v) {
					sum += a[end];
					++end;
					pfx[end] = max(pfx[end], pfx[end - 1]);
				}
				if (sum >= v) {
					pfx[end] = 1 + pfx[start];
				}
				sum -= a[start];
			}
			rep(i,1,n+1) {
				pfx[i] = max(pfx[i], pfx[i - 1]);
			}
			return pfx;
		};
 
		auto pfx = compute_pfx();
		reverse(all(a));
		auto sfx = compute_pfx();
		reverse(all(a));
		reverse(all(sfx));
 
		if (pfx[n] < m) {
			cout << "-1\n";
			continue;
		}
 
		int end = 0;
		ll ans = 0;
		for (int start = 0; start < n; start++) {
			while (end < n && pfx[start] + sfx[end + 1] >= m) ++end;
			if (pfx[start] + sfx[end] >= m)
				ans = max(ans, query(start, end));
		}
		cout << ans << "\n";
	}
}
This is not a graph problem. Try to think about for each card ii whether Alice can ever trade up from ii to nn.
2028D - Alice's Adventures in CardsWe will use DP to answer the following question for each aa from nn down to 11: is it possible to trade up from card aa to card nn?To answer this question efficiently, we need to determine for each of the three players whether there exists some b>ab>a such that p(b)<p(a)p(b)<p(a) and it is possible to trade up from card bb to card nn. We can do this efficiently by keeping track for each player the minimum value x=p(b)x=p(b) over all bb that can reach nn: then, for a given aa we can check for each player if p(a)p(a) exceeds xx. If it does for some player, we can then update the values xx for each of the three players. Alongside these minimum values xx we can keep track of the bb achieving them to be able to reconstruct a solution.This takes time O(n)O(n) since each iteration takes time O(1)O(1).
#include <bits/stdc++.h>
using namespace std;
 
using ll = long long;
using ld = long double;
using pii = pair<int, int>;
using vi = vector<int>;
#define rep(i, a, b) for(int i = a; i < (b); ++i)
#define all(x) (x).begin(), (x).end()
#define sz(x) (int)(x).size()
#define smx(a, b) a = max(a, b)
#define smn(a, b) a = min(a, b)
#define pb push_back
#define endl '\n'
 
const ll MOD = 1e9 + 7;
const ld EPS = 1e-9;
 
mt19937 rng(time(0));
 
int main() {
	cin.tie(0)->sync_with_stdio(0);
 
	int t; cin >> t;
	std::string s = "qkj";
	while (t--) {
		int n; cin >> n;
		vector p(3, vector<int>(n + 1));
		rep(i,0,3) rep(j,1,n + 1) cin >> p[i][j];
		vector<pair<char, int>> sol(n + 1, {'\0', -1});
		array<int, 3> mins = {n, n, n}; // minimizing index
		for (int i = n - 1; i >= 1; i--) {
			int win = -1;
			rep(j,0,3) if (p[j][i] > p[j][mins[j]]) win = j;
			if (win == -1) continue;
			sol[i] = {s[win], mins[win]};
			rep(j,0,3) if (p[j][i] < p[j][mins[j]]) mins[j] = i;
		}
		if (sol[1].second == -1) {
			cout << "NO\n";
			continue;
		}
		cout << "YES\n";
		vector<pair<char, int>> ans = {sol[1]};
		while (ans.back().second >= 0) {
			ans.push_back(sol[ans.back().second]);
		}
		ans.pop_back();
		cout << sz(ans) << "\n";
		for (auto && [c, i] : ans) {
			cout << c << " " << i << "\n";
		}
	}
}
Solve the same problem, but now with the additional requirement that the solution must use the minimum number of trades (same constraints).
What are Alice's and the Red Queen's optimal moves at a given position?
Solve the problem for a path (bamboo) of length nn first.
Solve Hint 2 first. Now, generalize the solution to an arbitrary tree.
2028E - Alice's Adventures in the Rabbit HoleNote that Alice should always aim to move to the root, as this maximizes her probability of escaping (i.e., for any path from leaf to root, Alice's probability of escaping increases moving up the path). Furthermore, the Queen should always move downward for the same reason as above. Furthermore, the Queen should always move to the closest leaf in the subtree rooted at the current node.There are now a few ways to compute this, but basically all of them are O(n)O(n). For one such slick way, define d(v)d(v) to be the distance to the closest leaf of the subtree of vv, p(v)p(v) to be the parent of vv, and t(v)t(v) to be the probability Alice gets the treasure starting at node vv. Then, we claim that t(v)=d(v)d(v)+1⋅t(p(v))t(v)=d(v)d(v)+1⋅t(p(v)) for all vertices except the root. We can populate these values as we DFS down the tree.Indeed, suppose that the tree is just a path with d+1d+1 vertices, labelled from 11 through d+1d+1. Then, Alice's probability of getting the treasure at node ii is 1−i−1d1−i−1d (this comes from solving a system of linear equations). This lines up with the above t(v)t(v) calculation.Now, we can construct the answer inductively. Let PP be a shortest root-to-leaf path in TT and consider the subtrees formed by removing the edges of PP from TT. Each such subtree is rooted at some node v∈Pv∈P. Then, in a subtree T′T′ rooted at vv, the probability of Alice getting the treasure is exactly the probability that Alice gets to node vv and then to node 11 from vv, by the chain rule of conditioning and noting that the Queen will never re-enter the subtree T′T′ and the game will only play out along PP from this point forward. Therefore, it suffices to deconstruct TT into shortest root-to-leaf paths and note that at a given vertex vv, we only have to play along the sequence of shortest root-to-leaf paths leading from vv to 11. Along each of these paths, the above probability calculation holds, so we are done.
#include <bits/stdc++.h>
using namespace std;
 
using ll = long long;
using ld = long double;
using pii = pair<int, int>;
using vi = vector<int>;
#define rep(i, a, b) for(int i = a; i < (b); ++i)
#define all(x) (x).begin(), (x).end()
#define sz(x) (int)(x).size()
#define smx(a, b) a = max(a, b)
#define smn(a, b) a = min(a, b)
#define pb push_back
#define endl '\n'
 
const ll MOD = 1e9 + 7;
const ld EPS = 1e-9;
 
// mt19937 rng(time(0));
 
ll euclid(ll a, ll b, ll &x, ll &y) {
	if (!b) return x = 1, y = 0, a;
	ll d = euclid(b, a % b, y, x);
	return y -= a/b * x, d;
}
 
const ll mod = 998244353;
struct mint {
	ll x;
	mint(ll xx) : x(xx) {}
	mint operator+(mint b) { return mint((x + b.x) % mod); }
	mint operator-(mint b) { return mint((x - b.x + mod) % mod); }
	mint operator*(mint b) { return mint((x * b.x) % mod); }
	mint operator/(mint b) { return *this * invert(b); }
	mint invert(mint a) {
		ll x, y, g = euclid(a.x, mod, x, y);
		assert(g == 1); return mint((x + mod) % mod);
	}
	mint operator^(ll e) {
		if (!e) return mint(1);
		mint r = *this ^ (e / 2); r = r * r;
		return e&1 ? *this * r : r;
	}
};
 
void solve() {
	int n; cin >> n;
	vector<vector<int>> t(n);
	rep(i,0,n-1) {
		int x, y; cin >> x >> y; --x, --y;
		t[x].push_back(y);
		t[y].push_back(x);
	}
 
	vector<int> d(n, n + 1);
	function<int(int, int)> depths = [&](int curr, int par) {
		for (auto v : t[curr]) {
			if (v == par) continue;
			d[curr] = min(d[curr], 1 + depths(v, curr));
		}
		if (d[curr] > n) d[curr] = 0;
		return d[curr];
	};
 
	depths(0, -1);
 
	vector<mint> ans(n, 0);
	function<void(int, int, mint)> dfs = [&](int curr, int par, mint val) {
		ans[curr] = val;
		for (auto v : t[curr]) {
			if (v == par) continue;
			dfs(v, curr, val * d[v] / (d[v] + 1));
		}
	};
 
	dfs(0, -1, mint(1));
	for (auto x : ans) {
		cout << x.x << " ";
	}
	cout << "\n";
}
 
int main() {
	cin.tie(0)->sync_with_stdio(0);
 
	int t; cin >> t;
	while (t--) solve();
}
Come up with a DP algorithm running in time O(n2m)O(n2m).
Try optimizing the Hint 1 DP to run in time O(nmlogm)O(nmlog⁡m) when ai≥2ai≥2 for all ii.
Do some casework to extend Hint 2 to ai≥0ai≥0.
Bitset
2028F - Alice's Adventures in AdditionLet dp[i][j]dp[i][j] be whether a1∘a2∘…∘ai=ja1∘a2∘…∘ai=j can be satisfied. Then, let's case on aiai.  If ai=0ai=0, then dp[i][j]=dp[i−1][j]∨dp[i−2][j]∨⋯∨dp[0][j]dp[i][j]=dp[i−1][j]∨dp[i−2][j]∨⋯∨dp[0][j] (where we will take dp[0][j]=1[j=0]dp[0][j]=1[j=0], the indicator that j=0j=0). This is because we can multiply together any suffix to form 00. We can do this in time O(1)O(1) by keeping these prefix ORs. If ai=1ai=1, then dp[i][j]=dp[i−1][j]∨dp[i−1][j−1]dp[i][j]=dp[i−1][j]∨dp[i−1][j−1] (since m≥1m≥1 we don't have to worry about accidentally allowing 00s). This is because we can either multiply ai−1ai−1 by 11 or add 11. Otherwise, note that we can only multiply together at most log2(j)log2⁡(j) many ai>1ai>1 before the result exceeds jj. So, for each ii let back(i)back(i) denote the biggest k<ik<i such that ak≠1ak≠1. Then, we can write dp[i][j]=dp[i−1][j−ai]∨dp[back(i)−1][j−ai⋅aback(i)]∨⋯dp[i][j]=dp[i−1][j−ai]∨dp[back(i)−1][j−ai⋅aback(i)]∨⋯ where we continue until we either reach i=0i=0, hit 00, or exceed jj. There is one special case: if ak=0ak=0 for any k<ik<i, then we should also allow dp[i][j]|=dp[k−1][j]∨dp[k−2][j]∨⋯∨dp[0][j]dp[i][j]|=dp[k−1][j]∨dp[k−2][j]∨⋯∨dp[0][j]. We can keep track of the last time ak=0ak=0 and use the same prefix OR idea as above.Note that all of these operations are "batch" operations: that is, we can do them for all jj simultaneously for a given ii. Thus, this gives a bitset solution in time O(nmlogmw)O(nmlog⁡mw) and with space complexity O(nmw)O(nmw). However, this uses too much space. We can optimize the space complexity to only store log2(m)+4log2⁡(m)+4 bitsets (with some extra integers) instead. To do this, note that for the 00 case we only require one bitset which we can update after each ii, for the 11 case we only have to keep the previous bitset, and for the >1>1 case we only need to store the most recent log2(m)log2⁡(m) bitsets for indices ii with ai+1>1ai+1>1. We can keep this in a deque and pop from the back if the size exceeds log2(m)log2⁡(m). For the special case at the end, we can keep track of a prefix bitset for the last occurrence of a 00. Overall, this uses space complexity O(mlog2mw)O(mlog2⁡mw) which is sufficient (interestingly, we don't even have to store the input!)
#include <bits/stdc++.h>
using namespace std;

using ll = long long;
using ld = long double;
using pii = pair<int, int>;
using vi = vector<int>;
#define rep(i, a, b) for(int i = a; i < (b); ++i)
#define all(x) (x).begin(), (x).end()
#define sz(x) (int)(x).size()
#define smx(a, b) a = max(a, b)
#define smn(a, b) a = min(a, b)
#define pb push_back
#define endl '\n'

const ll MOD = 1e9 + 7;
const ld EPS = 1e-9;

mt19937 rng(time(0));

const int LOG = 14;
const int MAX = 10000 + 1;

int main() {
    cin.tie(0)->sync_with_stdio(0);
 
    int t; cin >> t;
    while (t--) {
        int n, m; cin >> n >> m;
        bitset<MAX> prev(1), pfx(1), zero(0);
        list<pair<int, bitset<MAX>>> q;
        rep(i,0,n) {
            int x; cin >> x;
            bitset<MAX> curr = zero;

            if (x == 0) {
                curr |= pfx;
                zero = curr;
                q.push_front({0, prev});
            } else if (x == 1) {
                curr |= prev | (prev << 1);
            } else {
                int prod = 1;
                q.push_front({x, prev});
                for (auto const& val : q) {
                    if (prod == 0 || prod * val.first > m) break;
                    prod *= val.first;
                    curr |= val.second << prod;
                }
            }
            pfx |= curr;
            prev = curr;
            if (sz(q) > LOG) q.pop_back();
        }

        cout << (prev[m] ? "YES" : "NO") << "\n";
    }
}
Let f(x)f(x) = max number of monsters we can satisfy using the first x pieces for all x in [0,n].Let g(x)g(x) = same as f(x)f(x) but using the last x pieces. We create a function that takes a vector and V ( min value to deem partition good), and it return f(x).To compute g(x), we just need to make a copy of aa, reverse it and use the same function. if f(n) < m then we cannot feed all monsters even with all the pieces and ans = -1. Now that we have f(x)f(x) and g(x)g(x), it's a very straight forward two pointers algorithm.We consider a segment a[l:r]a[l:r] good, if after giving it to Alice, the rest suffices to feed all of m monsters.It's easy to notice that if some segment is good, then any segment inside it is also good. And if a segment is bad, then any segment that contains it is also bad.This is a very strong indication that the two pointers methods may be used here.I learned this for the course in Codeforces under Edu section. Check it out. It's good. Now for each r in [0,n) we find the longest good segment that ends at r, and among all of there, we pick the best of course..For this problem specifically, it was helpful to deem a segment to be good if it's empty to avoid some troubling bugs. How to check whether a segment[l, r] is good?we use all pieces in a[0:l), (l pieces) to feed monsters and max num of monsters we can feed with first l pieces is f(l),and pieces in [r+1,n) are also available, their count is n−r−1n−r−1, and clearly we can now an extra g(n−r−1)g(n−r−1), if the sum >= m, segment is good so segment is good <=> segment is empty or f(l)+g(n−r−1)>=mf(l)+g(n−r−1)>=mN.B. an empty segment is indeed good because we have already checked that f(n)>=mf(n)>=m. But if use f(l)+g(n−r−1)>=mf(l)+g(n−r−1)>=m to check if an empty segment is good, I think we can get in trouble, so it's better to use a different condition, simple r−l+1==0=>goodr−l+1==0=>good Here is the code291149416 


[Editorial - contest/2029]
     A B C D E F G H I     Error_Yuan 800 1200 1600 2100 2300 2600 3000 3400 3500   sszcdjr 800 1100 1600 2000 2300 2600 2900 3300 3500   wyrqwq 800 1000 1400 2200 2300 2600 3000 3500 3500   Otomachi_Una 800 1000 1600 2200 2400 2600 3200 3500 3500   dXqwq 900 1100 1700 2200 2400 2600 3200 3500 3500   Kubic 800 1000 1600 2400 2200 2800 3000 3500 3300   wsc2008qwq 800 1100 1600 1900 2200 2700 3100       chromate00 800 1000 1600 1900             rui_er 800 1000 1500 1800 2200 2500 3000       abc864197532 800 1100 1600 2200 2300 2500 2900             A B C D E F G H I     Average 810  1060  1580  2090  2289 2611  3033  3450  3467    Actual 800  1100  1700  1900  2100  2500  3000  3500  3400 (Thank you, rainboy)    
Greedy from small to large.
We can delete the numbers from small to large. Thus, previously removed numbers will not affect future choices (if x<yx<y, then xx cannot be a multiple of yy). So an integer xx (l≤x≤rl≤x≤r) can be removed if and only if k⋅x≤rk⋅x≤r, that is, x≤⌊rk⌋x≤⌊rk⌋. The answer is max(⌊rk⌋−l+1,0)max(⌊rk⌋−l+1,0).Time complexity: O(1)O(1) per test case.
#include <bits/stdc++.h>
#define all(s) s.begin(), s.end()
using namespace std;
using ll = long long;
using ull = unsigned long long;
 
const int _N = 1e5 + 5;
 
int T;
 
void solve() {
	int l, r, k; cin >> l >> r >> k;
	cout << max(r / k - l + 1, 0) << endl;
	return;
}
 
int main() {
	ios::sync_with_stdio(false), cin.tie(0), cout.tie(0);
	cin >> T;
	while (T--) {
		solve();
	}
}
for _ in range(int(input())):
    l, r, k = map(int, input().split())
    print(max(r // k - l + 1, 0))
 Amazing problem: 




35





 Good problem: 

    


150



 Average problem: 

    


119



 Bad problem: 

    


11



 Didn't solve: 

    


18



 
(0101 or 1010 exists) ⟺⟺ (both 00 and 11 exist).
Each time we do an operation, if ss consists only of 00 or 11, we surely cannot find any valid indices. Otherwise, we can always perform the operation successfully. In the ii-th operation, if ti=0ti=0, we actually decrease the number of 11-s by 11, and vice versa. Thus, we only need to maintain the number of 00-s and 11-s in ss. If any of them falls to 00 before the last operation, the answer is NO, otherwise, the answer is YES.Time complexity: O(n)O(n) per test case.
#include <bits/stdc++.h>
#define all(s) s.begin(), s.end()

using namespace std;
using ll = long long;

const int _N = 1e5 + 5;

void solve() {
	int n; cin >> n;
	string s, t; cin >> s >> t;
	int cnt0 = count(all(s), '0'), cnt1 = n - cnt0;
	for (int i = 0; i < n - 1; i++) {
		if (cnt0 == 0 || cnt1 == 0) {
			cout << "NO" << '\n';
			return;
		}
		if (t[i] == '1') cnt0--;
		else cnt1--;
	}
	cout << "YES" << '\n';
}

int main() {
	int T; cin >> T;
	while (T--) {
		solve();
	}
}
for _ in range(int(input())):
    n = int(input())
    s = input()
    one = s.count("1")
    zero = s.count("0")
    ans = "YES"
    for ti in input():
        if one == 0 or zero == 0:
            ans = "NO"
            break
        one -= 1
        zero -= 1
        if ti == "1":
            one += 1
        else:
            zero += 1
    print(ans)
 Amazing problem: 

    


67



 Good problem: 

    


221



 Average problem: 

    


26



 Bad problem: 

    


46



 Didn't solve: 

    


23



 
Hint 1Binary search. Hint 2Do something backward. SolutionFirst, do binary search on the answer. Suppose we're checking whether the answer can be ≥k≥k now.Let fifi be the current rating after participating in the 11-st to the ii-th contest (without skipping).Let gigi be the minimum rating before the ii-th contest to make sure that the final rating is ≥k≥k (without skipping).fifi-s can be calculated easily by simulating the process in the statement. For gigi-s, it can be shown that  gi={gi+1−1,gi+1+1,ai≥gi+1ai<gi+1gi={gi+1−1,ai≥gi+1gi+1+1,ai<gi+1where gn+1=kgn+1=k.Then, we should check if there exists an interval [l,r][l,r] (1≤l≤r≤n1≤l≤r≤n), such that fl−1≥gr+1fl−1≥gr+1. If so, we can choose to skip [l,r][l,r] and get a rating of ≥k≥k. Otherwise, it is impossible to make the rating ≥k≥k.We can enumerate on rr and use a prefix max to check whether valid ll exists.Time complexity: O(nlogn)O(nlog⁡n) per test case.
Binary search.
Do something backward.
First, do binary search on the answer. Suppose we're checking whether the answer can be ≥k≥k now.Let fifi be the current rating after participating in the 11-st to the ii-th contest (without skipping).Let gigi be the minimum rating before the ii-th contest to make sure that the final rating is ≥k≥k (without skipping).fifi-s can be calculated easily by simulating the process in the statement. For gigi-s, it can be shown that  gi={gi+1−1,gi+1+1,ai≥gi+1ai<gi+1gi={gi+1−1,ai≥gi+1gi+1+1,ai<gi+1where gn+1=kgn+1=k.Then, we should check if there exists an interval [l,r][l,r] (1≤l≤r≤n1≤l≤r≤n), such that fl−1≥gr+1fl−1≥gr+1. If so, we can choose to skip [l,r][l,r] and get a rating of ≥k≥k. Otherwise, it is impossible to make the rating ≥k≥k.We can enumerate on rr and use a prefix max to check whether valid ll exists.Time complexity: O(nlogn)O(nlog⁡n) per test case.
Hint 1Consider DP. Hint 2There are only three possible states for each contest: before, in, or after the skipped interval. SolutionConsider dpi,0/1/2=dpi,0/1/2= the maximum rating after the ii-th contest, where the ii-th contest is before/in/after the skipped interval.Let f(a,x)=f(a,x)= the result rating when current rating is aa and the performance rating is xx, then ⎧⎩⎨⎪⎪dpi,0=f(dpi−1,0,ai),dpi,1=max(dpi−1,1,dpi−1,0),dpi,2=max(f(dpi−1,1,ai),f(dpi−1,2,ai)).{dpi,0=f(dpi−1,0,ai),dpi,1=max(dpi−1,1,dpi−1,0),dpi,2=max(f(dpi−1,1,ai),f(dpi−1,2,ai)).And the final answer is max(dpn,1,dpn,2)max(dpn,1,dpn,2).Time complexity: O(n)O(n) per test case.
Consider DP.
There are only three possible states for each contest: before, in, or after the skipped interval.
Consider dpi,0/1/2=dpi,0/1/2= the maximum rating after the ii-th contest, where the ii-th contest is before/in/after the skipped interval.Let f(a,x)=f(a,x)= the result rating when current rating is aa and the performance rating is xx, then ⎧⎩⎨⎪⎪dpi,0=f(dpi−1,0,ai),dpi,1=max(dpi−1,1,dpi−1,0),dpi,2=max(f(dpi−1,1,ai),f(dpi−1,2,ai)).{dpi,0=f(dpi−1,0,ai),dpi,1=max(dpi−1,1,dpi−1,0),dpi,2=max(f(dpi−1,1,ai),f(dpi−1,2,ai)).And the final answer is max(dpn,1,dpn,2)max(dpn,1,dpn,2).Time complexity: O(n)O(n) per test case.
#include <bits/stdc++.h>
#define all(s) s.begin(), s.end()
using namespace std;
using ll = long long;
using ull = unsigned long long;

const int _N = 1e5 + 5;

int T;

void solve() {
	int n; cin >> n;
	vector<int> a(n + 1);
	for (int i = 1; i <= n; i++) cin >> a[i];
	vector<int> pre(n + 1);
	int curf = 0;
	for (int i = 1; i <= n; i++) {
		if (curf < a[i]) curf++;
		else if (curf > a[i]) curf--;
		pre[i] = max(pre[i - 1], curf);
	}
	auto check = [&](int k) {
		int curg = k;
		for (int i = n; i >= 1; i--) {
			if (pre[i - 1] >= curg) return true;
			if (a[i] < curg) curg++;
			else curg--;
		}
		return false;
	};
	int L = 0, R = n + 1;
	while (L < R) {
		int mid = (L + R + 1) >> 1;
		if (check(mid)) L = mid;
		else R = mid - 1;
	}
	cout << L << '\n';
	return;
}

int main() {
	ios::sync_with_stdio(false), cin.tie(0), cout.tie(0);
	cin >> T;
	while (T--) {
		solve();
	}
}
for _ in range(int(input())):
    n = int(input())
    
    def f(a, x):
        return a + (a < x) - (a > x)
    
    dp = [0, -n, -n]
    for x in map(int, input().split()):
        dp[2] = max(f(dp[1], x), f(dp[2], x))
        dp[1] = max(dp[1], dp[0])
        dp[0] = f(dp[0], x)

    print(max(dp[1], dp[2]))
 Amazing problem: 

    


373



 Good problem: 

    


91



 Average problem: 

    


20



 Bad problem: 

    


35



 Didn't solve: 

    


59



 
Try to make the graph into a forest first.
(degi≤1degi≤1 for every ii) ⟹⟹ (The graph is a forest).
Let didi be the degree of vertex ii. First, we keep doing the following until it is impossible:  Choose a vertex uu with du≥2du≥2, then find any two vertices v,wv,w adjacent to uu. Perform the operation on (u,v,w)(u,v,w). Since each operation decreases the number of edges by at least 11, at most mm operations will be performed. After these operations, di≤1di≤1 holds for every ii. Thus, the resulting graph consists only of components with size ≤2≤2.If there are no edges, the graph is already cool, and we don't need to do any more operations.Otherwise, let's pick an arbitrary edge (u,v)(u,v) as the base of the final tree, and then merge everything else to it.For a component with size =1=1 (i.e. it is a single vertex ww), perform the operation on (u,v,w)(u,v,w), and set (u,v)←(u,w)(u,v)←(u,w).For a component with size =2=2 (i.e. it is an edge connecting aa and bb), perform the operation on (u,a,b)(u,a,b).It is clear that the graph is transformed into a tree now.The total number of operations won't exceed n+m≤2⋅max(n,m)n+m≤2⋅max(n,m).In the author's solution, we used some data structures to maintain the edges, thus, the time complexity is O(n+mlogm)O(n+mlog⁡m) per test case.
#include <bits/stdc++.h>
using namespace std;
#ifdef DEBUG
#include "debug.hpp"
#else
#define debug(...) (void)0
#endif

using i64 = int64_t;
constexpr bool test = false;

int main() {
  cin.tie(nullptr)->sync_with_stdio(false);
  int t;
  cin >> t;
  for (int ti = 0; ti < t; ti += 1) {
    int n, m;
    cin >> n >> m;
    vector<set<int>> adj(n + 1);
    for (int i = 0, u, v; i < m; i += 1) {
      cin >> u >> v;
      adj[u].insert(v);
      adj[v].insert(u);
    }
    vector<tuple<int, int, int>> ans;
    for (int i = 1; i <= n; i += 1) {
      while (adj[i].size() >= 2) {
        int u = *adj[i].begin();
        adj[i].erase(adj[i].begin());
        int v = *adj[i].begin();
        adj[i].erase(adj[i].begin());
        adj[u].erase(i);
        adj[v].erase(i);
        ans.emplace_back(i, u, v);
        if (adj[u].contains(v)) {
          adj[u].erase(v);
          adj[v].erase(u);
        } else {
          adj[u].insert(v);
          adj[v].insert(u);
        }
      }
    }
    vector<int> s;
    vector<pair<int, int>> p;
    for (int i = 1; i <= n; i += 1) {
      if (adj[i].size() == 0) {
        s.push_back(i);
      } else if (*adj[i].begin() > i) {
        p.emplace_back(i, *adj[i].begin());
      }
    }
    if (not p.empty()) {
      auto [x, y] = p.back();
      p.pop_back();
      for (int u : s) {
        ans.emplace_back(x, y, u);
        tie(x, y) = pair(x, u);
      }
      for (auto [u, v] : p) {
        ans.emplace_back(y, u, v);
      }
    }
    println("{}", ans.size());
    for (auto [x, y, z] : ans) println("{} {} {}", x, y, z);
  }
}
 Amazing problem: 

    


212



 Good problem: 

    


50



 Average problem: 

    


16



 Bad problem: 

    


29



 Didn't solve: 

    


24



 
22 is powerful.
Consider primes.
How did you prove that 22 can generate every integer except odd primes? Can you generalize it?
In this problem, we do not take the integer 11 into consideration.Claim 1. 22 can generate every integer except odd primes.Proof. For a certain non-prime xx, let mind(x)mind⁡(x) be the minimum divisor of xx. Then x−mind(x)x−mind⁡(x) must be an even number, which is ≥2≥2. So x−mind(x)x−mind⁡(x) can be generated by 22, and xx can be generated by x−mind(x)x−mind⁡(x). Thus, 22 is a generator of xx.Claim 2. Primes can only be generated by themselves.According to the above two claims, we can first check if there exist primes in the array aa. If not, then 22 is a common generator. Otherwise, let the prime be pp, the only possible generator should be pp itself. So we only need to check whether pp is a generator of the rest integers.For an even integer xx, it is easy to see that, pp is a generator of xx if and only if x≥2⋅px≥2⋅p. Claim 3. For a prime pp and an odd integer xx, pp is a generator of xx if and only if x−mind(x)≥2⋅px−mind⁡(x)≥2⋅p.Proof. First, x−mind(x)x−mind⁡(x) is the largest integer other than xx itself that can generate xx. Moreover, only even numbers ≥2⋅p≥2⋅p can be generated by pp (x−mind(x)x−mind⁡(x) is even). That ends the proof.Thus, we have found a good way to check if a certain number can be generated from pp. We can use the linear sieve to pre-calculate all the mind(i)mind⁡(i)-s.Time complexity: O(∑n+V)O(∑n+V), where V=maxaiV=maxai.Some other solutions with worse time complexity can also pass, such as O(VlogV)O(Vlog⁡V) and O(tV−−√)O(tV).
#include <bits/stdc++.h>
#define all(s) s.begin(), s.end()
using namespace std;
using ll = long long;
using ull = unsigned long long;

const int _N = 4e5 + 5;

int vis[_N], pr[_N], cnt = 0;

void init(int n) {
	vis[1] = 1;
	for (int i = 2; i <= n; i++) {
		if (!vis[i]) {
			pr[++cnt] = i;
		}
		for (int j = 1; j <= cnt && i * pr[j] <= n; j++) {
			vis[i * pr[j]] = pr[j];
			if (i % pr[j] == 0) continue;
		}
	}
}

int T;

void solve() {
	int n; cin >> n;
	vector<int> a(n + 1);
	for (int i = 1; i <= n; i++) cin >> a[i];
	int p = 0;
	for (int i = 1; i <= n; i++) {
		if (!vis[a[i]]) p = a[i];
	}
	if (!p) {
		cout << 2 << '\n';
		return;
	}
	for (int i = 1; i <= n; i++) {
		if (a[i] == p) continue;
		if (vis[a[i]] == 0) {
			cout << -1 << '\n';
			return;
		}
		if (a[i] & 1) {
			if (a[i] - vis[a[i]] < 2 * p) {
				cout << -1 << '\n';
				return;
			}
		} else {
			if (a[i] < 2 * p) {
				cout << -1 << '\n';
				return;
			}
		}
	}
	cout << p << '\n';
	return;
}

int main() {
	ios::sync_with_stdio(false), cin.tie(0), cout.tie(0);
	init(400000);
	cin >> T;
	while (T--) {
		solve();
	}
}
 Amazing problem: 

    


137



 Good problem: 

    


71



 Average problem: 

    


18



 Bad problem: 

    


22



 Didn't solve: 

    


16



 
If there are both consecutive RR-s and BB-s, does the condition hold for all (i,j)(i,j)? Why? 
Suppose that there are only consecutive RR-s, check the parity of the number of RR-s in each consecutive segment of RR-s.
If for each consecutive segment of RR-s, the parity of the number of RR-s is odd, does the condition hold for all (i,j)(i,j)? Why? 
If for at least two of the consecutive segments of RR-s, the parity of the number of RR-s is even, does the condition hold for all (i,j)(i,j)? Why? 
Is this the necessary and sufficient condition? Why?
Don't forget some trivial cases like RRR...RBRRR...RB and RRR...RRRR...R.
For each k>nk>n or k≤0k≤0, let ckck be ckmodnckmodn.Lemma 1: If there are both consecutive RR-s and BB-s, the answer is NO.Proof 1: Suppose that ci−1=ci=Rci−1=ci=R and cj−1=cj=Bcj−1=cj=B, it's obvious that there doesn't exist a palindrome route between ii and jj.Imagine there are two persons on vertex ii and jj. They want to meet each other (they are on the same vertex or adjacent vertex) and can only travel through an edge of the same color.Lemma 2: Suppose that there are only consecutive RR-s, if for each consecutive segment of RR-s, the parity of the number of RR-s is odd, the answer is NO.Proof 2: Suppose that ci=cj=Bci=cj=B, i≢j(modn)i≢j(modn) and ci+1=ci+2=⋯=cj−1=Rci+1=ci+2=⋯=cj−1=R. The two persons on ii and jj have to "cross" BB simultaneously. As for each consecutive segment of RR-s, the parity of the number of RR-s is odd, they can only get to the same side of their current consecutive segment of RR-s. After "crossing" BB, they will still be on different consecutive segments of RR-s separated by exactly one BB and can only get to the same side. Thus, they will never meet.Lemma 3: Suppose that there are only consecutive RR-s, if, for at least two of the consecutive segments of RR-s, the parity of the number of RR-s is even, the answer is NO.Proof 3: Suppose that ci=cj=Bci=cj=B, i≢j(modn)i≢j(modn) and vertex ii and jj are both in a consecutive segment of RR-s with even number of RR-s. Let the starting point of two persons be ii and j−1j−1 and they won't be able to "cross" and BB. Thus, they will never meet.The only case left is that there is exactly one consecutive segment of RR-s with an even number of RR-s.Lemma 4: Suppose that there are only consecutive RR-s, if, for exactly one of the consecutive segments of RR-s, the parity of the number of RR-s is even, the answer is YES.Proof 4: Let the starting point of the two persons be i,ji,j. Consider the following cases:Case 1: If vertex ii and jj are in the same consecutive segment of RR-s, the two persons can meet each other by traveling through the RR-s between them.Case 2: If vertex ii and jj are in the different consecutive segment of RR-s and there are odd numbers of RR-s in both segments, the two person may cross BB-s in the way talked about in Proof 2. However, when one of them reaches a consecutive segment with an even number of RR-s, the only thing they can do is let the one in an even segment cross the whole segment and "cross" the next BB in the front, while letting the other one traveling back and forth and "cross" the BB he just "crossed". Thus, unlike the situation in Proof 2, we successfully changed the side they can both get to and thus they will be able to meet each other as they are traveling toward each other and there are only odd segments between them.Case 3: If vertex ii and jj are in the different consecutive segment of RR-s and there are an odd number of RR-s in exactly one of the segments, we can let both of them be in one side of there segments and change the situation to the one we've discussed about in Case 2 (when one of them reached a consecutive segment with even number of RR-s).As a result, the answer is YES if:  At least n−1n−1 of c1,c2,…,cnc1,c2,…,cn are the same (Hint 6), or Suppose that there are only consecutive RR-s, there's exactly one of the consecutive segments of RR-s such that the parity of the number of RR-s is even. And we can judge them in O(n)O(n) time complexity.
#include <bits/stdc++.h>
using namespace std;
void solve(){
	int n; cin>>n;
	string s; cin>>s;
	int visr=0,visb=0,ok=0; 
	for(int i=0;i<n;i++){
		if(s[i]==s[(i+1)%n]){
			if(s[i]=='R') visr=1;
			else visb=1;
			ok++;
		}
	}
	if(visr&visb){
		cout<<"NO\n";
		return ;
	}
	if(ok==n){
		cout<<"YES\n";
		return ;
	}
	if(visb) for(int i=0;i<n;i++) s[i]='R'+'B'-s[i];
	int st=0;
	for(int i=0;i<n;i++) if(s[i]=='B') st=(i+1)%n;
	vector<int> vc;
	int ntot=0,cnt=0;
	for(int i=0,j=st;i<n;i++,j=(j+1)%n){
		if(s[j]=='B') vc.push_back(ntot),cnt+=(ntot&1)^1,ntot=0;
		else ntot++;
	}
	if(vc.size()==1||cnt==1){
		cout<<"YES\n";
		return ;
	}
	cout<<"NO\n";
	return ;
}
signed main(){
	int t; cin>>t;
	while(t--) solve();
	return 0;
}
Count the number of strings of length nn satisfying the condition.
Solve the problem for ci∈{A,B,…,Z}ci∈{A,B,…,Z}, and solve the counting version.
 Amazing problem: 

    


31



 Good problem: 

    


41



 Average problem: 

    


11



 Bad problem: 

    


47



 Didn't solve: 

    


21



 
Hint 1The array aa is constructed with the operations. How can we use this property? Hint 2If we want to make all ai=xai=x, what is the minimum value of xx? Use the property mentioned in Hint 1. Hint 3(For the subproblem in Hint 2), try to find an algorithm related to the positions of L/RL/R-s directly. Hint 4(For the subproblem in Hint 2), the conclusion is that, the minimum xx equals # of L-s+# of R-s−# of adjacent LR-s# of L-s+# of R-s−# of adjacent LR-s. Think why. Hint 5Go for DP. SolutionRead the hints first.Then, note that there are only O(V)O(V) useful positions: If (after the initial operations) ai>Vai>V or ai=ai−1ai=ai−1, we can simply ignore aiai, or merge cici into ci−1ci−1.Now let dp(i,s)dp(i,s) denote the answer when we consider the prefix of length ii, and we have "saved" ss pairs of LRLR.Then, dp(i,s)=maxj<idp(j,s−|cntL(j,i−1)−cntR(j+1,i)|)+cidp(i,s)=maxj<idp(j,s−|cntL(j,i−1)−cntR(j+1,i)|)+ciWrite cntLcntL and cntRcntR as prefix sums: dp(i,s)=maxj<idp(j,s−|preL(i−1)−preR(i)+preR(j)−preL(j−1)|)+cidp(i,s)=maxj<idp(j,s−|preL(i−1)−preR(i)+preR(j)−preL(j−1)|)+ciDo casework on the sign of the things inside the absabs, and you can maintain both cases with 1D Fenwick trees.Thus, you solved the problem in O(V2logV)O(V2log⁡V).
The array aa is constructed with the operations. How can we use this property?
If we want to make all ai=xai=x, what is the minimum value of xx? Use the property mentioned in Hint 1.
(For the subproblem in Hint 2), try to find an algorithm related to the positions of L/RL/R-s directly.
(For the subproblem in Hint 2), the conclusion is that, the minimum xx equals # of L-s+# of R-s−# of adjacent LR-s# of L-s+# of R-s−# of adjacent LR-s. Think why.
Go for DP.
Read the hints first.Then, note that there are only O(V)O(V) useful positions: If (after the initial operations) ai>Vai>V or ai=ai−1ai=ai−1, we can simply ignore aiai, or merge cici into ci−1ci−1.Now let dp(i,s)dp(i,s) denote the answer when we consider the prefix of length ii, and we have "saved" ss pairs of LRLR.Then, dp(i,s)=maxj<idp(j,s−|cntL(j,i−1)−cntR(j+1,i)|)+cidp(i,s)=maxj<idp(j,s−|cntL(j,i−1)−cntR(j+1,i)|)+ciWrite cntLcntL and cntRcntR as prefix sums: dp(i,s)=maxj<idp(j,s−|preL(i−1)−preR(i)+preR(j)−preL(j−1)|)+cidp(i,s)=maxj<idp(j,s−|preL(i−1)−preR(i)+preR(j)−preL(j−1)|)+ciDo casework on the sign of the things inside the absabs, and you can maintain both cases with 1D Fenwick trees.Thus, you solved the problem in O(V2logV)O(V2log⁡V).
Hint 1Solve the problem for a single vv first. Hint 2Don't think too much, just go straight for a DP solution. Hint 3Does your time complexity in DP contain nn or mm? In fact, both nn and mm are useless. There are only O(V)O(V) useful positions. Hint 4Use some data structures to optimize your DP. Even O(v2log2v)O(v2log2⁡v) is acceptable. Hint 5Here is the final step: take a look at your DP carefully. Can you change the definition of states a little, so that it can get the answer for each 1≤v≤V1≤v≤V? SolutionFirst, note that there are only O(V)O(V) useful positions: If (after the initial operations) ai>Vai>V or ai=ai−1ai=ai−1, we can simply ignore aiai, or merge cici into ci−1ci−1.Now, let's solve the problem for a single vv.Denote dp(i,j,k)dp(i,j,k) as the maximum answer when considering the prefix of length ii, and there are jj prefix additions covering ii, kk suffix additions covering ii.Enumerate on ii, and it is easy to show that the state changes if and only if j+k+ai=vj+k+ai=v, and dp(i,j,k)=maxp≤j,q≥kdp(i−1,p,q)+cidp(i,j,k)=maxp≤j,q≥kdp(i−1,p,q)+ciYou can use a 2D Fenwick tree to get the 2D prefix max. Thus, you solved the single vv case in O(v2log2v)O(v2log2⁡v).In fact, we can process the DP in O(v2logv)O(v2log⁡v) by further optimization:  dp(i,j,k)=maxp≤i−1,q≥j,v−ap−q≤kdp(p,q,v−ap−q)+cidp(i,j,k)=maxp≤i−1,q≥j,v−ap−q≤kdp(p,q,v−ap−q)+ciThis only requires ap+q≥ai+jap+q≥ai+j when ap≤aiap≤ai, and q≤jq≤j when ap≥aiap≥ai. So you can use 1D Fenwick trees to process the dp in O(v2logv)O(v2log⁡v).Now, let's go for the whole solution.Let's modify the DP state a bit: now dp(i,j,k)dp(i,j,k) is the state when using v−kv−k suffix operations (note that vv is not a constant here). The transformation is similar.Then the answer for v=iv=i will be maxdp(∗,∗,i)maxdp(∗,∗,i).
Solve the problem for a single vv first.
Don't think too much, just go straight for a DP solution.
Does your time complexity in DP contain nn or mm? In fact, both nn and mm are useless. There are only O(V)O(V) useful positions.
Use some data structures to optimize your DP. Even O(v2log2v)O(v2log2⁡v) is acceptable.
Here is the final step: take a look at your DP carefully. Can you change the definition of states a little, so that it can get the answer for each 1≤v≤V1≤v≤V?
First, note that there are only O(V)O(V) useful positions: If (after the initial operations) ai>Vai>V or ai=ai−1ai=ai−1, we can simply ignore aiai, or merge cici into ci−1ci−1.Now, let's solve the problem for a single vv.Denote dp(i,j,k)dp(i,j,k) as the maximum answer when considering the prefix of length ii, and there are jj prefix additions covering ii, kk suffix additions covering ii.Enumerate on ii, and it is easy to show that the state changes if and only if j+k+ai=vj+k+ai=v, and dp(i,j,k)=maxp≤j,q≥kdp(i−1,p,q)+cidp(i,j,k)=maxp≤j,q≥kdp(i−1,p,q)+ciYou can use a 2D Fenwick tree to get the 2D prefix max. Thus, you solved the single vv case in O(v2log2v)O(v2log2⁡v).In fact, we can process the DP in O(v2logv)O(v2log⁡v) by further optimization:  dp(i,j,k)=maxp≤i−1,q≥j,v−ap−q≤kdp(p,q,v−ap−q)+cidp(i,j,k)=maxp≤i−1,q≥j,v−ap−q≤kdp(p,q,v−ap−q)+ciThis only requires ap+q≥ai+jap+q≥ai+j when ap≤aiap≤ai, and q≤jq≤j when ap≥aiap≥ai. So you can use 1D Fenwick trees to process the dp in O(v2logv)O(v2log⁡v).Now, let's go for the whole solution.Let's modify the DP state a bit: now dp(i,j,k)dp(i,j,k) is the state when using v−kv−k suffix operations (note that vv is not a constant here). The transformation is similar.Then the answer for v=iv=i will be maxdp(∗,∗,i)maxdp(∗,∗,i).
#include <bits/stdc++.h>
#define all(s) s.begin(), s.end()
using namespace std;
using ll = long long;
using ull = unsigned long long;
using ld = double;

const int _N = 4105;
const ld inf = 1e15;

int T;

struct fenwick {
	ll c[_N]; int N;
	int lowbit(int x) { return x & (-x); }
	void init(int n) {
		N = n;
		for (int i = 1; i <= N; i++) c[i] = -1e18;
	}
	void update(int x, ll v) {
		// assert(x != 0);
		while (x < N) {
			c[x] = max(c[x], v);
			x += lowbit(x);
		}
	}
	ll getmx(int x) {
		// assert(x != 0);
		ll res = -1e18;
		while (x > 0) {
			res = max(res, c[x]);
			x -= lowbit(x);
		}
		return res;
	}
} pre[4105], suf[4105];

void solve() {
	int n, o, m, k; cin >> n >> o >> m;
	k = 0;
	vector<ll> a(n + 3), c(n + 3), d(n + 3), L(n + 3), R(n + 3), L2(n + 3), R2(n + 3);
	for (int i = 1; i <= n; i++) cin >> c[i];
	for (int i = 1; i <= o; i++) {
		char op; int x; cin >> op >> x;
		if (op == 'L') L[x]++;
		else R[x]++;
	}
	vector<int> tL(n + 3), tR(n + 3);
	for (int i = 1; i <= n; i++) tR[i] = tR[i - 1] + R[i];
	for (int i = n; i >= 1; i--) tL[i] = tL[i + 1] + L[i];
	int q = 0, curL = 0, curR = 0;
	for (int i = 1; i <= n; i++) {
		a[i] = tL[i] + tR[i];
		if (a[i] <= m + k) {
		    if (a[i] == a[i - 1] && L[i] == 0 && R[i] == 0) {
		        if (q == 0) q++;
		        d[q] += c[i];
		        continue;
		    }
			q++;
			L2[q] += L[i];
			R2[q] += R[i] + curR;
			L2[q - 1] += curL;
			d[q] += c[i];
			curL = curR = 0;
		} else {
			curL += L[i];
			curR += R[i];
		}
	}
	L2[0] = 0; L2[q] += curL;
	for (int i = 1; i <= q; i++) L2[i] += L2[i - 1], R2[i] += R2[i - 1];
    m += k;
    vector<ll> dp(2 * m + 2, -1e18);
	for (int i = 0; i <= 2 * m; i++) {
		pre[i].init(2 * m + 2);
		suf[i].init(2 * m + 2);
	}
	vector<ll> ans(m + 1);
	for (int i = 1; i <= q; i++) {
        dp.resize(2 * m + 2, -1e18);
		dp[L2[i - 1]] = d[i];
		for (int s = 0; s <= m; s++) {
			ll res1 = pre[s - L2[i - 1] + m].getmx(R2[i] - L2[i - 1] + m + 1);
			ll res2 = suf[s - R2[i] + m].getmx(m + 1 - R2[i] + L2[i - 1]);
			dp[s] = max({ dp[s], res1 + d[i], res2 + d[i] });
			if (L2[q] + R2[i] - s >= 0 && L2[q] + R2[i] - s <= m) ans[L2[q] + R2[i] - s] = max(ans[L2[q] + R2[i] - s], dp[s]);
		}
		for (int s = 0; s <= m; s++) {
			if (dp[s] <= -1e12) continue;
			pre[s - L2[i - 1] + m].update(R2[i] - L2[i - 1] + m + 1, dp[s]);
			suf[s - R2[i] + m].update(m + 1 - R2[i] + L2[i - 1], dp[s]);
		}
	}
	for (int i = 1; i <= m; i++) {
		ans[i] = max(ans[i - 1], ans[i]);
		cout << ans[i] << " \n"[i == m];
	}
	return;
}

int main() {
	ios::sync_with_stdio(false), cin.tie(0), cout.tie(0);
	cin >> T;
	while (T--) {
		solve();
	}
}
#include <bits/stdc++.h>
using namespace std;
typedef long long ll;
#define pb push_back
#define pii pair<int, int>
#define all(a) a.begin(), a.end()
const int mod = 1e9 + 7, N = 5005;

void solve() {
    int n, m, V;
    cin >> n >> m >> V;
    vector <int> c(n);
    for (int i = 0; i < n; ++i) {
        cin >> c[i];
    }
    vector <int> pre(n + 1);
    for (int i = 0; i < m; ++i) {
        char x; int v; cin >> x >> v, --v;
        if (x == 'L') {
            pre[0]++, pre[v + 1]--;
        } else {
            pre[v]++;
        }
    }
    for (int i = 0; i < n; ++i) {
        pre[i + 1] += pre[i];
    }
    vector <pair <ll, int>> vec;
    for (int i = 0, j = 0; i < n; i = j) {
        ll tot = 0;
        while (j < n && pre[i] == pre[j]) {
            tot += c[j], j++;
        }
        if (pre[i] <= V) {
            vec.emplace_back(tot, pre[i]);
        }
    }

    vector bit(V + 5, vector <ll>(V + 5, -1ll << 60));
    auto upd = [&](int x, int y, ll v) {
        for (int i = x + 1; i < V + 5; i += i & (-i)) {
            for (int j = y + 1; j < V + 5; j += j & (-j)) {
                bit[i][j] = max(bit[i][j], v);
            }
        }
    };
    auto query = [&](int x, int y) {
        ll ans = -1ll << 60;
        for (int i = x + 1; i > 0; i -= i & (-i)) {
            for (int j = y + 1; j > 0; j -= j & (-j)) {
                ans = max(ans, bit[i][j]);
            }
        }
        return ans;
    };

    upd(0, 0, 0);
    vector <ll> tmp(V + 1);
    for (auto [val, diff] : vec) {
        for (int i = 0; i + diff <= V; ++i) {
            tmp[i] = query(i, i + diff);
        }
        for (int i = 0; i + diff <= V; ++i) {
            upd(i, i + diff, tmp[i] + val);
        }
    }

    for (int i = 1; i <= V; ++i) {
        cout << query(i, i) << " \n"[i == V];
    }
}

int main() {
    ios::sync_with_stdio(false), cin.tie(0);
    int t;
    cin >> t;
    while (t--) {
        solve();
    }
}
 Amazing problem: 

    


20



 Good problem: 

    


8



 Average problem: 

    


4



 Bad problem: 

    


2



 Didn't solve: 

    


23



 
Solve the problem in O(V2)O(V2).
It's hard to calculate the expected number. Try to change it to the probability.
Consider a O(3n)O(3n) dp first.
Use inclusion and exclusion.
Write out the transformation. Try to optimize it.
Let dpSdpS be the probability such that exactly the points in SS have the message.The answer is ∑dpS⋅trS∑dpS⋅trS, where trStrS is the expected number of days before at least one vertex out of SS to have the message (counting from the day that exactly the points in SS have the message).For transformation, enumerate S,TS,T such that S∩T=∅S∩T=∅. Transfer dpSdpS to dpS∪TdpS∪T. It's easy to precalculate the coefficient, and the time complexity differs from O(3n)O(3n), O(n⋅3n)O(n⋅3n) to O(n2⋅3n)O(n2⋅3n), according to the implementation.The transformation is hard to optimize. Enumerate TT and calculate the probability such that vertices in SS is only connected with vertices in TT, which means that the real status RR satisfies S⊆R⊆(S∪T)S⊆R⊆(S∪T). Use inclusion and exclusion to calculate the real probability.List out the coefficient: ∏e∈{1,2,3,…,n}(1−we)⋅∏e∈(S∪T)11−we⋅∏e∈{1,2,…,n}∖S11−we⋅∏e∈T(1−we)1−∏e∈{1,2,3,…,n}(1−we)⋅∏e∈S11−we⋅∏e∈{1,2,3,…,n}∖S11−we∏e∈{1,2,3,…,n}(1−we)⋅∏e∈(S∪T)11−we⋅∏e∈{1,2,…,n}∖S11−we⋅∏e∈T(1−we)1−∏e∈{1,2,3,…,n}(1−we)⋅∏e∈S11−we⋅∏e∈{1,2,3,…,n}∖S11−we(Note that wewe denotes the probability of the appearance of the edge ee)We can express it as Const⋅fS∪T⋅gS⋅hTConst⋅fS∪T⋅gS⋅hT. Use a subset convolution to optimize it. The total time complexity is O(2n⋅n2)O(2n⋅n2).It's easy to see that all dpS≠0dpS≠0 satisfies 1∈S1∈S, so the time complexity can be O(2n−1⋅n2)O(2n−1⋅n2) if well implemented.
#include <bits/stdc++.h>
#define int long long 
using namespace std;
const int N=(1<<21),mod=998244353;
const int Lim=8e18;
inline void add(signed &i,int j){
	i+=j;
	if(i>=mod) i-=mod;
}
int qp(int a,int b){
	int ans=1;
	while(b){
		if(b&1) (ans*=a)%=mod;
		(a*=a)%=mod;
		b>>=1;
	}
	return ans;
}
int dp[N],f[N],g[N],h[N];
int s1[N],s2[N];
signed pre[22][N/2],t[22][N/2],pdp[N][22];
int p[N],q[N],totp,totq;
signed main(){
	int n,m; cin>>n>>m;
	int totprod=1;
	for(int i=0;i<(1<<n);i++) s1[i]=s2[i]=1;
	for(int i=1;i<=m;i++){
		int u,v,p,q; cin>>u>>v>>p>>q;
		int w=p*qp(q,mod-2)%mod;
		(s1[(1<<(u-1))+(1<<(v-1))]*=(mod+1-w))%=mod;
		(s2[(1<<(u-1))+(1<<(v-1))]*=qp(mod+1-w,mod-2))%=mod;
		(totprod*=(mod+1-w))%=mod;
	}
	for(int j=1;j<=n;j++) for(int i=0;i<(1<<n);i++) if((i>>(j-1))&1) (s1[i]*=s1[i^(1<<(j-1))])%=mod,(s2[i]*=s2[i^(1<<(j-1))])%=mod;
	for(int i=0;i<(1<<n);i++) f[i]=s2[i],g[i]=totprod*s2[((1<<n)-1)^i]%mod*qp(mod+1-totprod*s2[i]%mod*s2[((1<<n)-1)^i]%mod,mod-2)%mod,h[i]=s1[i];
	for(int i=1;i<(1<<n);i++) pre[__builtin_popcount(i)][i>>1]=h[i];
	dp[1]=1;
	for(int j=1;j<=n;j++){
		if(!((1>>(j-1))&1)) add(pdp[1|(1<<(j-1))][j],mod-(dp[1]*g[1]%mod*f[1]%mod));
	}
	t[0][0]=dp[1]*g[1]%mod;
	for(int k=1;k<=n;k++) for(int j=1;j<n;j++) for(int i=0;i<(1<<(n-1));i++) if((i>>(j-1))&1) add(pre[k][i],pre[k][i^(1<<(j-1))]);
	for(int j=1;j<n;j++) for(int i=0;i<(1<<(n-1));i++) if((i>>(j-1))&1) add(t[0][i],t[0][i^(1<<(j-1))]);
	for(int k=1;k<n;k++){
		totp=totq=0;
		for(int i=0;i<(1<<(n-1));i++) if(__builtin_popcount(i)<=k) p[++totp]=i; else q[++totq]=i;
		for(int l=1,i=p[l];l<=totp;l++,i=p[l]) for(int j=0;j<k;j++) add(t[k][i],1ll*t[j][i]*pre[k-j][i]%mod);
		for(int i=0;i<(1<<(n-1));i++) t[k][i]%=mod;
		for(int j=1;j<n;j++) for(int l=1,i=p[l];l<=totp;l++,i=p[l]) if((i>>(j-1))&1) add(t[k][i],mod-t[k][i^(1<<(j-1))]);
		for(int i=0;i<(1<<(n-1));i++){
			if(__builtin_popcount(i)==k){
				add(pdp[(i<<1)|1][0],t[k][i]*f[(i<<1)|1]%mod);
				int pre=0;
				for(int j=1;j<=n;j++){
					(pre+=pdp[(i<<1)|1][j-1])%=mod;
					if(!((((i<<1)|1)>>(j-1))&1)) add(pdp[(i<<1)|1|(1<<(j-1))][j],mod-pre);
				}
				(pre+=pdp[(i<<1)|1][n])%=mod;
				dp[(i<<1)|1]=pre;
				for(int j=1;j<=n;j++){
					if(!((((i<<1)|1)>>(j-1))&1)) add(pdp[(i<<1)|1|(1<<(j-1))][j],mod-(dp[(i<<1)|1]*g[(i<<1)|1]%mod*f[(i<<1)|1]%mod));
				}
				t[k][i]=pre*g[(i<<1)|1]%mod;
			}
			else t[k][i]=0;
		}
		for(int j=1;j<n;j++) for(int l=1,i=q[l];l<=totq;l++,i=q[l]) if((i>>(j-1))&1) add(t[k][i],t[k][i^(1<<(j-1))]);
	}
	int ans=0;
	for(int i=1;i<(1<<n)-1;i+=2) (ans+=dp[i]*qp(mod+1-totprod*s2[i]%mod*s2[((1<<n)-1)^i]%mod,mod-2)%mod)%=mod;
	cout<<ans;
	return 0;
}
 Amazing problem: 

    


10



 Good problem: 

    


3



 Average problem: 

    


1



 Bad problem: 

    


3



 Didn't solve: 

    


19



 
The intended solution has nothing to do with dynamic programming.
This is the key observation of the problem. Suppose we have an array bb and a function f(x)=∑(bi−x)2f(x)=∑(bi−x)2, then the minimum value of f(x)f(x) is the variance of bb.
Using the observation mentioned in Hint 2, we can reduce the problem to minimizing ∑(ai−x)2∑(ai−x)2 for a given xx. There are only O(n⋅m)O(n⋅m) possible xx-s.
The rest of the problem is somehow easy. Try flows, or just find a greedy algorithm!
If you are trying flows: the quadratic function is always convex. 
Key Observation. Suppose we have an array bb and a function f(x)=∑(bi−x)2f(x)=∑(bi−x)2, then the minimum value of f(x)f(x) is the variance of bb.Proof. This is a quadratic function of xx, and the its symmetry axis is x=1n∑bix=1n∑bi. So the minimum value is f(1n∑bi)f(1n∑bi). That is exactly the definition of variance.Thus, we can enumerate all possible xx-s, and find the minimum ∑(ai−x)2∑(ai−x)2 after the operations, then take the minimum across them. That will give the correct answer to the original problem. Note that there are only O(n⋅m)O(n⋅m) possible xx-s.More formally, let kx,ckx,c be the minimum value of ∑(ai−x)2∑(ai−x)2 after exactly cc operations. Then ansi=minany possible xkx,iansi=minany possible xkx,i.So we only need to solve the following (reduced) problem:  Given a (maybe non-integer) number xx. For each 1≤i≤m1≤i≤m, find the minimum value of ∑(ai−x)2∑(ai−x)2 after exactly ii operations. To solve this, we can use the MCMF model:  Set a source node ss and a target node tt. For each 1≤i≤n1≤i≤n, add an edge from ss to ii with cost 00. For each 1≤i≤n1≤i≤n, add an edge from ii to tt with cost 00. For each 1≤i<n1≤i<n, add an edge from ii to i+1i+1 with cost being a function cost(f)=(ai+f−x)2−(ai−x)2cost(f)=(ai+f−x)2−(ai−x)2, where ff is the flow on this edge. Note that the costcost function is convex, so this model is correct, as you can split an edge into some edges with cost of cost(1)cost(1), cost(2)−cost(1)cost(2)−cost(1), cost(3)−cost(2)cost(3)−cost(2), and so on. Take a look at the model again. We don't need to run MCMF. We can see that it is just a process of regret greedy. So you only need to find the LIS (Largest Interval Sum :) ) for each operation.Thus, we solved the reduced problem in O(n⋅m)O(n⋅m).Overall time complexity: O((n⋅m)2)O((n⋅m)2) per test case.Reminder: don't forget to use __int128 if you didn't handle the numbers carefully!
#include <bits/stdc++.h>
#define all(s) s.begin(), s.end()
using namespace std;
using ll = long long;
using ull = unsigned long long;

const int _N = 1e5 + 5;

int T;

void solve() {
	ll n, m, k; cin >> n >> m >> k;
	vector<ll> a(n + 1);
	for (int i = 1; i <= n; i++) cin >> a[i];
	vector<ll> kans(m + 1, LLONG_MAX);
	vector<__int128> f(n + 1), g(n + 1), v(n + 1);
	vector<int> vis(n + 1), L(n + 1), L2(n + 1);
	ll sum = 0;
	for (int i = 1; i <= n; i++) sum += a[i];
	__int128 pans = 0;
	for (int i = 1; i <= n; i++) pans += n * a[i] * a[i];
	auto work = [&](ll s) {
		__int128 ans = pans;
		ans += s * s - 2ll * sum * s;
		f.assign(n + 1, LLONG_MAX);
		g.assign(n + 1, LLONG_MAX);
		for (int i = 1; i <= n; i++) {
			v[i] = n * (2 * a[i] * k + k * k) - 2ll * s * k;
			vis[i] = 0;
		}
		for (int i = 1; i <= m; i++) {
			for (int j = 1; j <= n; j++) {
				L[j] = L2[j] = j;
				if (f[j - 1] < 0) f[j] = f[j - 1] + v[j], L[j] = L[j - 1];
				else f[j] = v[j];
				if (!vis[j]) {
					g[j] = LLONG_MAX;
					continue;
				}
				if (g[j - 1] < 0) g[j] = g[j - 1] + 2ll * n * k * k - v[j], L2[j] = L2[j - 1];
				else g[j] = 2ll * n * k * k - v[j];
			}
			__int128 min_sum = LLONG_MAX;
			int l = 1, r = n, type = 0;
			for (int j = 1; j <= n; j++) {
				if (f[j] < min_sum) {
					min_sum = f[j], r = j, l = L[j];
				}
			}
			for (int j = 1; j <= n; j++) {
				if (g[j] < min_sum) {
					min_sum = g[j], r = j, l = L2[j];
					type = 1;
				}
			}
			ans += min_sum;
			if (type == 0) {
				for (int j = l; j <= r; j++) vis[j]++, v[j] += 2 * n * k * k;
			} else {
				for (int j = l; j <= r; j++) vis[j]--, v[j] -= 2 * n * k * k;
			}
			kans[i] = min((__int128)kans[i], ans);
		}
	};
	
	for (ll x = sum; x <= sum + n * m * k; x += k) {
		work(x);
	}
	for (int i = 1; i <= m; i++) cout << kans[i] << " \n"[i == m];
	return;
}

int main() {
	ios::sync_with_stdio(false), cin.tie(0), cout.tie(0);
	cin >> T;
	while (T--) {
		solve();
	}
}
 Amazing problem: 

    


11



 Good problem: 

    


2



 Average problem: 

    


1



 Bad problem: 

    


2



 Didn't solve: 

    


44



 

